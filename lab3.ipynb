{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import PIL\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "NUM_FEATURES = 1\n",
    "NUM_CLASSES = 2 * NUM_FEATURES\n",
    "\n",
    "HOST_NAME = \"gpu-host\"\n",
    "VERSION_STR = \"1.0\"\n",
    "\n",
    "n_epochs = 10000\n",
    "batch_size = 128\n",
    "IMAGE_SHAPE = 128 # Images will be reshaped to IMAGE_SHAPE x IMAGE_SHAPE\n",
    "NUM_PIXEL_CHANNELS = 3\n",
    "INPUT_SHAPE = (IMAGE_SHAPE, IMAGE_SHAPE, NUM_PIXEL_CHANNELS)\n",
    "LATENT_DIM = 100\n",
    "\n",
    "\n",
    "if False:\n",
    "    # Set seeds for reproducibility\n",
    "    SEED = 2024\n",
    "    random.seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    tf.random.set_seed(SEED)\n",
    "\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "if len(gpus) > 0:\n",
    "    tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    print(f\"{len(tf.config.list_physical_devices('GPU'))} GPU(s) available.\")\n",
    "else:\n",
    "    print(\"No GPU(s) available.\")\n",
    "\n",
    "PLOT_SETTINGS = {\"text.usetex\": True,\n",
    "                 \"font.family\": \"serif\",\n",
    "                 \"figure.figsize\": (8.0, 6.0),\n",
    "                 \"font.size\": 16,\n",
    "                 \"axes.labelsize\": 16,\n",
    "                 \"legend.fontsize\": 14,\n",
    "                 \"xtick.labelsize\": 14,\n",
    "                 \"ytick.labelsize\": 14,\n",
    "                 \"axes.titlesize\": 24,\n",
    "                 \"lines.linewidth\": 2.0,\n",
    "                 }\n",
    "plt.rcParams.update(PLOT_SETTINGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CelebADataLoader(keras.utils.Sequence):\n",
    "    \"\"\"\n",
    "        Data loader based on the given data loader for\n",
    "        assignment 1 but modified to load the CelebA data set.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 data_path,\n",
    "                 labels_path,\n",
    "                 batch_size=32,\n",
    "                 num_images = 1000,\n",
    "                 cache=True,\n",
    "                 random_state=None,\n",
    "                 dtype=np.uint8,\n",
    "                 ):\n",
    "\n",
    "        self.data_path = data_path\n",
    "        self.labels_path = labels_path\n",
    "        self.batch_size = max(1, int(batch_size))\n",
    "        self.cache = bool(cache)\n",
    "        if random_state is None:\n",
    "            self.random_state = np.random\n",
    "        elif isinstance(random_state, np.random.RandomState):\n",
    "            self.random_state = random_state\n",
    "        else:\n",
    "            self.random_state = np.random.RandomState(random_state)\n",
    "        self.dtype = dtype\n",
    "\n",
    "        if self.data_path is None:\n",
    "            raise ValueError('The data path is not defined.')\n",
    "\n",
    "        if not os.path.isdir(self.data_path):\n",
    "            raise ValueError('The data path is incorrectly defined.')\n",
    "\n",
    "        self.labels_df = pd.read_csv(self.labels_path)\n",
    "        self.labels_df = self.labels_df[['image_id', 'Male']]\n",
    "        self._file_idx = 0\n",
    "        self._images = self.labels_df['image_id'].tolist() # Get all image names in list\n",
    "        self._labels = self.labels_df.drop(columns=['image_id']).values\n",
    "        female_indices = self._labels == -1\n",
    "        self._labels[female_indices] = 0\n",
    "        if len(self._images) > num_images:\n",
    "            self._images = self._images[:num_images]\n",
    "            self._labels = self._labels[:num_images]\n",
    "\n",
    "        self._image_cache = dict()\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Get the number of mini-batches per epoch.\"\"\"\n",
    "        return int(np.ceil(len(self._images) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Get one batch of data.\"\"\"\n",
    "        # Generate indices of the batch\n",
    "        indices = self._indices[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "\n",
    "        # Find the next set of file indices\n",
    "        minibatch_files = [self._images[k] for k in indices]\n",
    "        minibatch_labels = [self._labels[k] for k in indices]\n",
    "\n",
    "        # Load up the corresponding minibatch\n",
    "        minibatch = self.__load_minibatch(minibatch_files)\n",
    "\n",
    "        return np.array(minibatch), np.array(minibatch_labels)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        \"\"\"Update indices after each epoch.\"\"\"\n",
    "        self._indices = np.arange(len(self._images))\n",
    "        self.random_state.shuffle(self._indices)\n",
    "\n",
    "    def __load_image(self, file):\n",
    "        \"\"\"Load a single image from file.\"\"\"\n",
    "        im = Image.open(os.path.join(self.data_path, file))\n",
    "        if im.mode != \"RGB\":\n",
    "            im = im.convert(\"RGB\")\n",
    "        \n",
    "        im = im.resize((IMAGE_SHAPE, IMAGE_SHAPE), PIL.Image.Resampling.LANCZOS)\n",
    "        im = (np.asarray(im, dtype=self.dtype) / 255.0) * 2.0 - 1.0\n",
    "        \n",
    "        return im\n",
    "\n",
    "    def __load_minibatch(self, minibatch_files):\n",
    "        \"\"\"Load the next minibatch of samples.\"\"\"\n",
    "\n",
    "        minibatch = [None] * len(minibatch_files)\n",
    "        for i, file in enumerate(minibatch_files):\n",
    "            if self.cache:\n",
    "                if file in self._image_cache:\n",
    "                    im = self._image_cache[file]\n",
    "                else:\n",
    "                    im = self.__load_image(file)\n",
    "                    self._image_cache[file] = im\n",
    "            else:\n",
    "                im = self.__load_image(file)\n",
    "\n",
    "            minibatch[i] = im\n",
    "\n",
    "        return minibatch\n",
    "\n",
    "# Example usage:\n",
    "data_dir = \"./img_align_celeba/img_align_celeba/\"\n",
    "labels_path = \"./list_attr_celeba.csv\"\n",
    "\n",
    "# Create the data loaders\n",
    "train_ds = CelebADataLoader(data_dir, labels_path, num_images = 1024*40, batch_size=batch_size)\n",
    "\n",
    "# A quick summary of the data:\n",
    "print(f\"Number of training mini-batches: {len(train_ds)}\")\n",
    "print(f\"Number of training images      : {len(train_ds._indices)}\")\n",
    "print(f\"\\nImage shape: {np.array(train_ds[0][0][0]).shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of images to plot\n",
    "num_images = 16\n",
    "\n",
    "# Get a batch of images and labels\n",
    "images, labels = train_ds[0]  # Get the first batch, adjust index if needed\n",
    "\n",
    "selected_images = images[:num_images]\n",
    "selected_labels = labels[:num_images]\n",
    "\n",
    "fig, axes = plt.subplots(4, 4, figsize=(10, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for img, ax in zip(selected_images, axes):\n",
    "    ax.imshow(((img + 1) / 2 * 255).astype(np.uint8))  # Rescale image back to [0, 255] and convert to uint8\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def discriminator():\n",
    "    in_label = tf.keras.layers.Input(shape=(NUM_FEATURES,))\n",
    "    li = tf.keras.layers.Embedding(NUM_CLASSES, 50)(in_label)\n",
    "    li = tf.keras.layers.Dense(IMAGE_SHAPE * IMAGE_SHAPE * NUM_PIXEL_CHANNELS)(li)\n",
    "    li = tf.keras.layers.Reshape(INPUT_SHAPE)(li)\n",
    "    \n",
    "    in_image = tf.keras.layers.Input(shape=INPUT_SHAPE)\n",
    "    merge = tf.keras.layers.Concatenate()([in_image, li])\n",
    "\n",
    "    x = tf.keras.layers.Conv2D(64, (3,3), strides=(2,2), padding='same')(merge)\n",
    "    x = tf.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    x = tf.keras.layers.Conv2D(128, (3,3), strides=(2,2), padding='same')(x)\n",
    "    x = tf.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
    "    \n",
    "    x = tf.keras.layers.Conv2D(256, (3,3), strides=(2,2), padding='same')(x)\n",
    "    x = tf.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
    "    \n",
    "    x = tf.keras.layers.Conv2D(512, (3,3), strides=(2,2), padding='same')(x)\n",
    "    x = tf.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
    "    \n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    x = tf.keras.layers.Dropout(0.5)(x)\n",
    "    out_layer = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    model = tf.keras.models.Model([in_image, in_label], out_layer)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5), metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def generator():\n",
    "    in_label = tf.keras.layers.Input(shape=(NUM_FEATURES,))\n",
    "\n",
    "    foundation_dim = 8\n",
    "    li = tf.keras.layers.Embedding(NUM_CLASSES, 50)(in_label)\n",
    "    li = tf.keras.layers.Dense(foundation_dim*foundation_dim*NUM_PIXEL_CHANNELS)(li)\n",
    "    li = tf.keras.layers.Reshape((foundation_dim, foundation_dim, NUM_PIXEL_CHANNELS))(li)\n",
    "    \n",
    "    in_lat = tf.keras.layers.Input(shape=(LATENT_DIM,))\n",
    "    \n",
    "    # foundation for 8x8\n",
    "    x = tf.keras.layers.Dense(128 * foundation_dim * foundation_dim)(in_lat)\n",
    "    x = tf.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
    "    x = tf.keras.layers.Reshape((foundation_dim, foundation_dim, 128))(x)\n",
    "\n",
    "    merge = tf.keras.layers.Concatenate()([x, li])\n",
    "\n",
    "    # upsample to 16x16\n",
    "    x = tf.keras.layers.Conv2DTranspose(1024, (5,5), strides=(2,2), padding='same')(merge)\n",
    "    x = tf.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    # upsample to 32x32\n",
    "    x = tf.keras.layers.Conv2DTranspose(512, (5,5), strides=(2,2), padding='same')(x)\n",
    "    x = tf.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    # upsample to 64x64\n",
    "    x = tf.keras.layers.Conv2DTranspose(256, (5,5), strides=(2,2), padding='same')(x)\n",
    "    x = tf.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
    "    \n",
    "    # upsample to 128x128\n",
    "    x = tf.keras.layers.Conv2DTranspose(128, (5,5), strides=(2,2), padding='same')(x)\n",
    "    x = tf.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    out_layer = tf.keras.layers.Conv2DTranspose(NUM_PIXEL_CHANNELS, (5,5), activation='tanh', padding='same')(x)\n",
    "    model = tf.keras.models.Model([in_lat, in_label], out_layer)\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def gan(generator_model, discriminator_model):\n",
    "    discriminator_model.trainable = False # freez discirminator\n",
    "\n",
    "    # get noise and label inputs from generator model\n",
    "    gen_noise, gen_label = generator_model.input\n",
    "    # get image output from the generator model\n",
    "    gen_output = generator_model.output\n",
    "\n",
    "    gan_output = discriminator_model([gen_output, gen_label])\n",
    "    \n",
    "    model = tf.keras.models.Model([gen_noise, gen_label], gan_output)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5))\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_latent_batch(number_of_samples):\n",
    "    return [np.random.randn(number_of_samples, LATENT_DIM).reshape(number_of_samples, LATENT_DIM), np.random.choice([0, 1], size=number_of_samples)]\n",
    "\n",
    "\n",
    "def generate_fake_batch(generator_model, number_of_samples):\n",
    "    x_input, x_labels = get_latent_batch(number_of_samples)\n",
    "    X = generator_model.predict([x_input, x_labels])\n",
    "    y = np.zeros((number_of_samples, 1))\n",
    "    return [X, x_labels], y\n",
    "\n",
    "\n",
    "def save_plot(images, epoch, n=8):\n",
    "    plt.figure(figsize=(30, 30))\n",
    "    for i in range(n * n):\n",
    "        plt.subplot(n, n, 1 + i)\n",
    "        plt.axis('off')\n",
    "        image = images[i, :, :, :]\n",
    "        image = (image + 1) / 2.0\n",
    "        plt.imshow(image)\n",
    "    # save plot to file\n",
    "    file_path = f\"./imgs/{VERSION_STR}_{HOST_NAME}_cGAN_generated_plot_{epoch:03d}.png\"\n",
    "    plt.savefig(file_path)\n",
    "    plt.close()\n",
    " \n",
    "\n",
    "def summarize_performance(epoch, gen_model, disc_model, gan_model, X_real, y_real):\n",
    "    _, acc_real = disc_model.evaluate([np.array(X_real), np.array(y_real)], np.ones((batch_size, 1)), verbose=0)\n",
    "    \n",
    "    [X_fake, X_fake_labels], y_fake = generate_fake_batch(gen_model, batch_size)\n",
    "\n",
    "    _, acc_fake = disc_model.evaluate([X_fake, X_fake_labels], y_fake, verbose=0)\n",
    "    \n",
    "    print(f\"Accuracy real: {acc_real*100:.0f}%, fake: {acc_fake*100:.0f}%\")\n",
    "    \n",
    "    start_epoch = 200\n",
    "    save_plot(X_fake, epoch+start_epoch)\n",
    "    if True:\n",
    "        # Save model and waights\n",
    "        gen_model.save(f\"./models/{VERSION_STR}_{HOST_NAME}_cGAN_generator_model_{epoch+start_epoch}.h5\")\n",
    "        \n",
    "        gen_model.save_weights(f\"./checkpoints/{VERSION_STR}_{HOST_NAME}_cGAN_generator_checkpoint_{epoch+start_epoch}.h5\")\n",
    "        disc_model.save_weights(f\"./checkpoints/{VERSION_STR}_{HOST_NAME}_cGAN_discriminator_checkpoint_{epoch+start_epoch}.h5\")\n",
    "        gan_model.save_weights(f\"./checkpoints/{VERSION_STR}_{HOST_NAME}_cGAN_gan_checkpoint_{epoch+start_epoch}.h5\")\n",
    "\n",
    "\n",
    "################################################################################################\n",
    "########################################### TRAINING ###########################################\n",
    "################################################################################################\n",
    "\n",
    "\n",
    "VERBOSE_LEVEL = 1\n",
    "LOAD_MODEL = False\n",
    "SAVE_INTERVAL = 1\n",
    "\n",
    "\n",
    "gen_model = generator()\n",
    "disc_model = discriminator()\n",
    "gan_model = gan(gen_model, disc_model)\n",
    "\n",
    "if LOAD_MODEL:\n",
    "    try:\n",
    "        checkpoint_num = 12\n",
    "        gen_model.load_weights(f\"./checkpoints/{VERSION_STR}_{HOST_NAME}_cGAN_generator_checkpoint_{checkpoint_num}.h5\")\n",
    "        disc_model.load_weights(f\"./checkpoints/{VERSION_STR}_{HOST_NAME}_cGAN_discriminator_checkpoint_{checkpoint_num}.h5\")\n",
    "        gan_model.load_weights(f\"./checkpoints/{VERSION_STR}_{HOST_NAME}_cGAN_gan_checkpoint_{checkpoint_num}.h5\")\n",
    "        print(\"Weights loaded successfully\")\n",
    "    except Exception as e:\n",
    "        print(\"Error loading weights:\", e)\n",
    "\n",
    "if VERBOSE_LEVEL > 0:\n",
    "    gen_model.summary()\n",
    "    disc_model.summary()\n",
    "    gan_model.summary()\n",
    "\n",
    "\n",
    "batch_per_epoch = len(train_ds)\n",
    "for epoch in range(n_epochs):\n",
    "    for batch_number, (X_real, y_real) in enumerate(train_ds):\n",
    "        # Train discriminator on real images\n",
    "        disc_loss_real, _ = disc_model.train_on_batch([np.array(X_real), np.array(y_real)], np.ones((batch_size, 1)))\n",
    "        # Train discriminator on fake images\n",
    "        [X_fake, X_fake_labels], y_fake = generate_fake_batch(gen_model, batch_size)\n",
    "        d_loss_fake, _ = disc_model.train_on_batch([np.array(X_fake), np.array(X_fake_labels)], np.zeros((batch_size, 1)))\n",
    "        \n",
    "        # Train cGAN model with latent points\n",
    "        [X_gan, X_gan_labels] = get_latent_batch(batch_size)\n",
    "        g_loss = gan_model.train_on_batch([X_gan, X_gan_labels], np.ones((batch_size, 1)))\n",
    "    \n",
    "        print(f\"Epoch: {epoch+1}/{n_epochs}, Batch: {batch_number+1}/{batch_per_epoch}, Discriminator loss: {(disc_loss_real+d_loss_fake)*0.5}, Generator loss: {g_loss}\")\n",
    "    \n",
    "    train_ds.on_epoch_end()\n",
    "\n",
    "    if (epoch+1) % SAVE_INTERVAL == 0:\n",
    "        summarize_performance(epoch+1, gen_model, disc_model, gan_model, X_real, y_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"./models/1.0_gpu-host_cGAN_generator_model_259.h5\"\n",
    "gen_model = load_model(model_path)\n",
    "\n",
    "\n",
    "def plot_batch(images, n):\n",
    "    plt.figure(figsize=(30, 30))\n",
    "    for i in range(n):\n",
    "        plt.subplot(1, n, 1 + i)\n",
    "        plt.axis('off')\n",
    "        image = images[i, :, :, :]\n",
    "        image = (image + 1) / 2.0\n",
    "        plt.imshow(image)\n",
    "    plt.show()  # Display the plot\n",
    "\n",
    "num_images = 3\n",
    "x_input, x_labels = get_latent_batch(num_images)\n",
    "x_labels[0] = 0\n",
    "\n",
    "X = gen_model.predict([x_input, x_labels])\n",
    "plot_batch(X, num_images)\n",
    "\n",
    "gen_model = None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
