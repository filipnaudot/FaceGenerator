{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from /import/software/5dv236/vt24/AffectNet/\n",
      "GPU(s) available. Training will be lightning fast!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "SEED = 2024\n",
    "class_map = {\"Happy\": 0,\n",
    "             \"Sad\": 1,\n",
    "             \"Surprised\": 2,\n",
    "             \"Mad\": 3}\n",
    "cache = True\n",
    "\n",
    "# You may have to change these two\n",
    "n_epochs = 40\n",
    "batch_size = 128\n",
    "#BATCH_SIZE = 128\n",
    "IMAGE_SHAPE = 32 # Images will be reshaped to IMAGE_SHAPE x IMAGE_SHAPE\n",
    "NUM_PIXEL_CHANNELS = 3\n",
    "INPUT_SHAPE = (IMAGE_SHAPE, IMAGE_SHAPE, NUM_PIXEL_CHANNELS)\n",
    "LATENT_DIM = 100\n",
    "\n",
    "# Directory where the data are\n",
    "data_dir = \"/import/software/5dv236/vt24/AffectNet/\"\n",
    "print(f\"Loading data from {data_dir}\")\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "if len(gpus) > 0:\n",
    "    tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    print(\"GPU(s) available. Training will be lightning fast!\")\n",
    "else:\n",
    "    print(\"No GPU(s) available. Training will be very slow ...\")\n",
    "\n",
    "PLOT_SETTINGS = {\"text.usetex\": True,\n",
    "                 \"font.family\": \"serif\",\n",
    "                 \"figure.figsize\": (8.0, 6.0),\n",
    "                 \"font.size\": 16,\n",
    "                 \"axes.labelsize\": 16,\n",
    "                 \"legend.fontsize\": 14,\n",
    "                 \"xtick.labelsize\": 14,\n",
    "                 \"ytick.labelsize\": 14,\n",
    "                 \"axes.titlesize\": 24,\n",
    "                 \"lines.linewidth\": 2.0,\n",
    "                 }\n",
    "plt.rcParams.update(PLOT_SETTINGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training mini-batches: 62\n",
      "Number of training images      : 8000\n",
      "Number of validation images    : 1000\n",
      "Number of test images          : 1000\n",
      "\n",
      "Image shape: (32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "class DataLoader(keras.utils.Sequence):\n",
    "    \"\"\"A simple data loader for Assignment 1.\n",
    "\n",
    "    Note: Do not make changes to the data loader!\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 data_path,\n",
    "                 class_map,\n",
    "                 batch_size=32,\n",
    "                 cache=True,\n",
    "                 random_state=None,\n",
    "                 dtype=np.uint8,\n",
    "                 ):\n",
    "\n",
    "        self.data_path = data_path\n",
    "        self.class_map = class_map\n",
    "        self.batch_size = max(1, int(batch_size))\n",
    "        self.cache = bool(cache)\n",
    "        if random_state is None:\n",
    "            self.random_state = np.random\n",
    "        elif isinstance(random_state, np.random.RandomState):\n",
    "            self.random_state = random_state\n",
    "        else:\n",
    "            self.random_state = np.random.RandomState(random_state)\n",
    "        self.dtype = dtype\n",
    "\n",
    "        if self.data_path is None:\n",
    "            raise ValueError('The data path is not defined.')\n",
    "\n",
    "        if not os.path.isdir(self.data_path):\n",
    "            raise ValueError('The data path is incorrectly defined.')\n",
    "\n",
    "        if not isinstance(self.class_map, dict):\n",
    "            raise ValueError('The folder map is not a dictionary.')\n",
    "\n",
    "        # Read the files in all subfolders\n",
    "        self._file_idx = 0\n",
    "        self._images = []\n",
    "        self._labels = []\n",
    "        for folder in self.class_map:\n",
    "            path = os.path.join(self.data_path, folder)\n",
    "            for file in os.listdir(path):\n",
    "                file_path = os.path.join(path, file)\n",
    "                self._images.append(file_path)\n",
    "                self._labels.append(folder)\n",
    "\n",
    "        self._image_cache = dict()\n",
    "\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Get the number of mini-batches per epoch.\"\"\"\n",
    "        return int(len(self._images) / self.batch_size)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Get one batch of data.\"\"\"\n",
    "        # Generate indices of the batch\n",
    "        indices = self._indices[\n",
    "            index * self.batch_size:(index + 1) * self.batch_size]\n",
    "\n",
    "        # Find the next set of file indices\n",
    "        minibatch_files = [self._images[k] for k in indices]\n",
    "        minibatch_labels = [self.class_map[self._labels[k]] for k in indices]\n",
    "\n",
    "        # Load up the corresponding minibatch\n",
    "        minibatch = self.__load_minibatch(minibatch_files)\n",
    "\n",
    "        return minibatch, minibatch_labels\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        \"\"\"Update indices after each epoch.\"\"\"\n",
    "        self._indices = np.arange(len(self._images))\n",
    "        self.random_state.shuffle(self._indices)\n",
    "\n",
    "    def __load_image(self, file):\n",
    "        \"\"\"Load a single image from file.\"\"\"\n",
    "        im = Image.open(file)\n",
    "        if im.mode != \"RGB\":\n",
    "            im = im.convert(\"RGB\")\n",
    "        \n",
    "        im = im.resize((IMAGE_SHAPE, IMAGE_SHAPE), Image.ANTIALIAS)\n",
    "        im = np.asarray(im, dtype=self.dtype) / 255.0\n",
    "        \n",
    "\n",
    "        return im\n",
    "\n",
    "    def __load_minibatch(self, minibatch_files):\n",
    "        \"\"\"Load the next minibatch of samples.\"\"\"\n",
    "\n",
    "        try:\n",
    "            assert self.batch_size == len(minibatch_files)\n",
    "        except AssertionError:\n",
    "            print(self.batch_size)\n",
    "            print(len(minibatch_files))\n",
    "\n",
    "        minibatch = [None] * self.batch_size\n",
    "        for i, file in enumerate(minibatch_files):\n",
    "            if self.cache:\n",
    "                if file in self._image_cache:\n",
    "                    im = self._image_cache[file]\n",
    "                else:\n",
    "                    im = np.asarray(Image.open(file))\n",
    "                    im = self.__load_image(file)\n",
    "                    self._image_cache[file] = im\n",
    "            else:\n",
    "                im = self.__load_image(file)\n",
    "\n",
    "            minibatch[i] = im\n",
    "\n",
    "        return minibatch\n",
    "    \n",
    "\n",
    "\n",
    "# Create the data loaders\n",
    "train_ds = DataLoader(os.path.join(data_dir, \"train/\"),\n",
    "                      class_map=class_map,\n",
    "                      batch_size=batch_size,\n",
    "                      cache=cache,\n",
    "                      )\n",
    "val_ds = DataLoader(os.path.join(data_dir, \"val/\"),\n",
    "                    class_map=class_map,\n",
    "                    batch_size=batch_size,\n",
    "                    cache=cache,\n",
    "                    )\n",
    "# Do not use the test data in any way until the very end, when you fill in the\n",
    "# values in your report just before handing it in!\n",
    "test_ds = DataLoader(os.path.join(data_dir, \"test/\"),\n",
    "                     class_map=class_map,\n",
    "                     batch_size=batch_size,\n",
    "                     cache=cache,\n",
    "                     )\n",
    "\n",
    "# A quick summary of the data:\n",
    "print(f\"Number of training mini-batches: {len(train_ds)}\")\n",
    "print(f\"Number of training images      : {len(train_ds._indices)}\")\n",
    "print(f\"Number of validation images    : {len(val_ds._indices)}\")\n",
    "print(f\"Number of test images          : {len(test_ds._indices)}\")\n",
    "\n",
    "\n",
    "print(f\"\\nImage shape: {np.array(train_ds[0][0][0]).shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x360 with 40 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot a few of the training images\n",
    "fig = plt.figure(figsize=(12, 5))\n",
    "fig.subplots_adjust(top=0.995,\n",
    "                    bottom=0.005,\n",
    "                    left=0.025,\n",
    "                    right=0.995,\n",
    "                    wspace=0.05,\n",
    "                    hspace=0.0125)\n",
    "M, N = 4, 10\n",
    "axs = []\n",
    "for m in range(M):\n",
    "    axs.append([])\n",
    "    for n in range(N):\n",
    "        ax = plt.subplot2grid((M, N), (m, n), rowspan=1, colspan=1)\n",
    "        ax.xaxis.set_ticklabels([])\n",
    "        ax.xaxis.set_ticks([])\n",
    "        ax.yaxis.set_ticklabels([])\n",
    "        ax.yaxis.set_ticks([])\n",
    "        axs[m].append(ax)\n",
    "\n",
    "imgs = []\n",
    "lbls = []\n",
    "for i in range(3):\n",
    "    imgs.extend(train_ds[i][0])\n",
    "    lbls.extend(train_ds[i][1])\n",
    "indices = [0] * 4\n",
    "for i in range(len(imgs)):\n",
    "    y = lbls[i]\n",
    "    if indices[y] < N:\n",
    "        axs[y][indices[y]].imshow(imgs[i].astype(int))  # int [0,...,255]\n",
    "        indices[y] += 1\n",
    "for m in range(M):\n",
    "    label = list(train_ds.class_map.keys())[\n",
    "        list(train_ds.class_map.values()).index(m)]\n",
    "    axs[m][0].set_ylabel(f\"{label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">1 real=53% fake=27%\n",
      ">2 real=63% fake=36%\n",
      ">3 real=65% fake=33%\n",
      ">4 real=66% fake=42%\n",
      ">5 real=62% fake=45%\n",
      ">6 real=68% fake=47%\n",
      ">7 real=71% fake=48%\n",
      ">8 real=64% fake=50%\n",
      ">9 real=62% fake=57%\n",
      ">10 real=63% fake=66%\n",
      ">11 real=73% fake=68%\n",
      ">12 real=73% fake=68%\n",
      ">13 real=73% fake=73%\n",
      ">14 real=69% fake=75%\n",
      ">15 real=70% fake=75%\n",
      ">16 real=71% fake=78%\n",
      ">17 real=73% fake=84%\n",
      ">18 real=73% fake=84%\n",
      ">19 real=77% fake=86%\n",
      ">20 real=79% fake=91%\n",
      ">21 real=77% fake=86%\n",
      ">22 real=79% fake=89%\n",
      ">23 real=84% fake=87%\n",
      ">24 real=73% fake=97%\n",
      ">25 real=86% fake=95%\n",
      ">26 real=76% fake=96%\n",
      ">27 real=82% fake=92%\n",
      ">28 real=86% fake=95%\n",
      ">29 real=87% fake=95%\n",
      ">30 real=84% fake=98%\n",
      ">31 real=84% fake=99%\n",
      ">32 real=82% fake=97%\n",
      ">33 real=83% fake=98%\n",
      ">34 real=84% fake=98%\n",
      ">35 real=86% fake=99%\n",
      ">36 real=84% fake=100%\n",
      ">37 real=85% fake=100%\n",
      ">38 real=91% fake=100%\n",
      ">39 real=87% fake=99%\n",
      ">40 real=92% fake=100%\n",
      ">41 real=88% fake=100%\n",
      ">42 real=83% fake=100%\n",
      ">43 real=91% fake=99%\n",
      ">44 real=87% fake=100%\n",
      ">45 real=93% fake=100%\n",
      ">46 real=88% fake=100%\n",
      ">47 real=89% fake=100%\n",
      ">48 real=90% fake=100%\n",
      ">49 real=86% fake=100%\n",
      ">50 real=84% fake=100%\n",
      ">51 real=88% fake=100%\n",
      ">52 real=91% fake=100%\n",
      ">53 real=91% fake=100%\n",
      ">54 real=89% fake=100%\n",
      ">55 real=89% fake=100%\n",
      ">56 real=93% fake=100%\n",
      ">57 real=88% fake=100%\n",
      ">58 real=87% fake=100%\n",
      ">59 real=88% fake=100%\n",
      ">60 real=93% fake=100%\n",
      ">61 real=87% fake=100%\n",
      ">62 real=89% fake=100%\n",
      "Epoch: 1/40, Batch: 1/62, Discriminator loss: -0.08959352225065231, Generator loss: 1.4305813312530518\n",
      "Epoch: 1/40, Batch: 2/62, Discriminator loss: -0.23907360434532166, Generator loss: 1.0461236238479614\n",
      "Epoch: 1/40, Batch: 3/62, Discriminator loss: -0.6672962307929993, Generator loss: 0.6499660015106201\n",
      "Epoch: 1/40, Batch: 4/62, Discriminator loss: -0.125274196267128, Generator loss: 0.4786069691181183\n",
      "Epoch: 1/40, Batch: 5/62, Discriminator loss: 0.007272124290466309, Generator loss: 0.48248055577278137\n",
      "Epoch: 1/40, Batch: 6/62, Discriminator loss: -0.04513894021511078, Generator loss: 0.48012852668762207\n",
      "Epoch: 1/40, Batch: 7/62, Discriminator loss: 0.062208324670791626, Generator loss: 0.4870511293411255\n",
      "Epoch: 1/40, Batch: 8/62, Discriminator loss: -0.00905945897102356, Generator loss: 0.3802335262298584\n",
      "Epoch: 1/40, Batch: 9/62, Discriminator loss: 0.5661360621452332, Generator loss: 0.27920886874198914\n",
      "Epoch: 1/40, Batch: 10/62, Discriminator loss: 0.8432506918907166, Generator loss: 0.19852961599826813\n",
      "Epoch: 1/40, Batch: 11/62, Discriminator loss: 1.418888807296753, Generator loss: 0.14301230013370514\n",
      "Epoch: 1/40, Batch: 12/62, Discriminator loss: 1.7805237770080566, Generator loss: 0.09287384897470474\n",
      "Epoch: 1/40, Batch: 13/62, Discriminator loss: 2.091263771057129, Generator loss: 0.08697587996721268\n",
      "Epoch: 1/40, Batch: 14/62, Discriminator loss: 2.0828940868377686, Generator loss: 0.08068536967039108\n",
      "Epoch: 1/40, Batch: 15/62, Discriminator loss: 2.040257453918457, Generator loss: 0.09680584818124771\n",
      "Epoch: 1/40, Batch: 16/62, Discriminator loss: 1.8972277641296387, Generator loss: 0.10719556361436844\n",
      "Epoch: 1/40, Batch: 17/62, Discriminator loss: 1.6504074335098267, Generator loss: 0.1428624838590622\n",
      "Epoch: 1/40, Batch: 18/62, Discriminator loss: 1.6037836074829102, Generator loss: 0.15749555826187134\n",
      "Epoch: 1/40, Batch: 19/62, Discriminator loss: 1.431810975074768, Generator loss: 0.20108844339847565\n",
      "Epoch: 1/40, Batch: 20/62, Discriminator loss: 1.2482702732086182, Generator loss: 0.22523091733455658\n",
      "Epoch: 1/40, Batch: 21/62, Discriminator loss: 1.1392247676849365, Generator loss: 0.25604215264320374\n",
      "Epoch: 1/40, Batch: 22/62, Discriminator loss: 1.0136334896087646, Generator loss: 0.30122312903404236\n",
      "Epoch: 1/40, Batch: 23/62, Discriminator loss: 0.8508614301681519, Generator loss: 0.35117220878601074\n",
      "Epoch: 1/40, Batch: 24/62, Discriminator loss: 0.7892164587974548, Generator loss: 0.41001152992248535\n",
      "Epoch: 1/40, Batch: 25/62, Discriminator loss: 0.7764835953712463, Generator loss: 0.4548591077327728\n",
      "Epoch: 1/40, Batch: 26/62, Discriminator loss: 0.6019775867462158, Generator loss: 0.48692989349365234\n",
      "Epoch: 1/40, Batch: 27/62, Discriminator loss: 0.554079532623291, Generator loss: 0.5525768399238586\n",
      "Epoch: 1/40, Batch: 28/62, Discriminator loss: 0.49955129623413086, Generator loss: 0.6058727502822876\n",
      "Epoch: 1/40, Batch: 29/62, Discriminator loss: 0.3838925063610077, Generator loss: 0.6340006589889526\n",
      "Epoch: 1/40, Batch: 30/62, Discriminator loss: 0.34795689582824707, Generator loss: 0.5232645273208618\n",
      "Epoch: 1/40, Batch: 31/62, Discriminator loss: 0.40098005533218384, Generator loss: 0.4699716567993164\n",
      "Epoch: 1/40, Batch: 32/62, Discriminator loss: 0.5358685255050659, Generator loss: 0.4309069812297821\n",
      "Epoch: 1/40, Batch: 33/62, Discriminator loss: 0.4435623288154602, Generator loss: 0.5154798626899719\n",
      "Epoch: 1/40, Batch: 34/62, Discriminator loss: 0.5663852691650391, Generator loss: 0.66522216796875\n",
      "Epoch: 1/40, Batch: 35/62, Discriminator loss: 0.4239240288734436, Generator loss: 0.8533856272697449\n",
      "Epoch: 1/40, Batch: 36/62, Discriminator loss: 0.43114739656448364, Generator loss: 0.8833943009376526\n",
      "Epoch: 1/40, Batch: 37/62, Discriminator loss: 0.3210190534591675, Generator loss: 0.934388279914856\n",
      "Epoch: 1/40, Batch: 38/62, Discriminator loss: 0.3180333375930786, Generator loss: 0.8376744389533997\n",
      "Epoch: 1/40, Batch: 39/62, Discriminator loss: 0.22340208292007446, Generator loss: 0.7463212609291077\n",
      "Epoch: 1/40, Batch: 40/62, Discriminator loss: 0.37413614988327026, Generator loss: 0.6789740324020386\n",
      "Epoch: 1/40, Batch: 41/62, Discriminator loss: 0.37132132053375244, Generator loss: 0.747823178768158\n",
      "Epoch: 1/40, Batch: 42/62, Discriminator loss: 0.22757433354854584, Generator loss: 0.6763687133789062\n",
      "Epoch: 1/40, Batch: 43/62, Discriminator loss: 0.261085569858551, Generator loss: 0.7255078554153442\n",
      "Epoch: 1/40, Batch: 44/62, Discriminator loss: 0.037673816084861755, Generator loss: 0.6912751197814941\n",
      "Epoch: 1/40, Batch: 45/62, Discriminator loss: 0.1890486180782318, Generator loss: 0.6748806834220886\n",
      "Epoch: 1/40, Batch: 46/62, Discriminator loss: 0.018434271216392517, Generator loss: 0.7141898274421692\n",
      "Epoch: 1/40, Batch: 47/62, Discriminator loss: -0.0931558907032013, Generator loss: 0.7319904565811157\n",
      "Epoch: 1/40, Batch: 48/62, Discriminator loss: 0.09699948132038116, Generator loss: 0.6804584264755249\n",
      "Epoch: 1/40, Batch: 49/62, Discriminator loss: -0.1577526330947876, Generator loss: 0.5621170401573181\n",
      "Epoch: 1/40, Batch: 50/62, Discriminator loss: -0.001094132661819458, Generator loss: 0.3970630466938019\n",
      "Epoch: 1/40, Batch: 51/62, Discriminator loss: 0.22733846306800842, Generator loss: 0.33010950684547424\n",
      "Epoch: 1/40, Batch: 52/62, Discriminator loss: 0.2237342894077301, Generator loss: 0.3225801885128021\n",
      "Epoch: 1/40, Batch: 53/62, Discriminator loss: 0.41883254051208496, Generator loss: 0.3905802071094513\n",
      "Epoch: 1/40, Batch: 54/62, Discriminator loss: 0.29395219683647156, Generator loss: 0.4154578745365143\n",
      "Epoch: 1/40, Batch: 55/62, Discriminator loss: 0.44354182481765747, Generator loss: 0.47743096947669983\n",
      "Epoch: 1/40, Batch: 56/62, Discriminator loss: 0.30659276247024536, Generator loss: 0.5168375372886658\n",
      "Epoch: 1/40, Batch: 57/62, Discriminator loss: 0.2644840180873871, Generator loss: 0.5384596586227417\n",
      "Epoch: 1/40, Batch: 58/62, Discriminator loss: 0.4565950334072113, Generator loss: 0.539091169834137\n",
      "Epoch: 1/40, Batch: 59/62, Discriminator loss: 0.39654773473739624, Generator loss: 0.5444747805595398\n",
      "Epoch: 1/40, Batch: 60/62, Discriminator loss: 0.4605499505996704, Generator loss: 0.6584717631340027\n",
      "Epoch: 1/40, Batch: 61/62, Discriminator loss: 0.3984370827674866, Generator loss: 0.6310468912124634\n",
      "Epoch: 1/40, Batch: 62/62, Discriminator loss: 0.3399151861667633, Generator loss: 0.5408720374107361\n",
      "Epoch: 2/40, Batch: 1/62, Discriminator loss: 0.42834827303886414, Generator loss: 0.5673861503601074\n",
      "Epoch: 2/40, Batch: 2/62, Discriminator loss: 0.45921701192855835, Generator loss: 0.48930272459983826\n",
      "Epoch: 2/40, Batch: 3/62, Discriminator loss: 0.30457818508148193, Generator loss: 0.4642258286476135\n",
      "Epoch: 2/40, Batch: 4/62, Discriminator loss: 0.5092325210571289, Generator loss: 0.5550788044929504\n",
      "Epoch: 2/40, Batch: 5/62, Discriminator loss: 0.4829580783843994, Generator loss: 0.6469314098358154\n",
      "Epoch: 2/40, Batch: 6/62, Discriminator loss: 0.4436984360218048, Generator loss: 0.759793758392334\n",
      "Epoch: 2/40, Batch: 7/62, Discriminator loss: 0.24069419503211975, Generator loss: 0.6944764852523804\n",
      "Epoch: 2/40, Batch: 8/62, Discriminator loss: 0.2212705910205841, Generator loss: 0.6960931420326233\n",
      "Epoch: 2/40, Batch: 9/62, Discriminator loss: 0.3305603265762329, Generator loss: 0.6260469555854797\n",
      "Epoch: 2/40, Batch: 10/62, Discriminator loss: 0.2937440872192383, Generator loss: 0.6654013395309448\n",
      "Epoch: 2/40, Batch: 11/62, Discriminator loss: 0.3062162399291992, Generator loss: 0.7125853896141052\n",
      "Epoch: 2/40, Batch: 12/62, Discriminator loss: 0.14292161166667938, Generator loss: 0.5556644797325134\n",
      "Epoch: 2/40, Batch: 13/62, Discriminator loss: 0.36897364258766174, Generator loss: 0.5624805688858032\n",
      "Epoch: 2/40, Batch: 14/62, Discriminator loss: 0.23028607666492462, Generator loss: 0.46207672357559204\n",
      "Epoch: 2/40, Batch: 15/62, Discriminator loss: 0.23720408976078033, Generator loss: 0.45987197756767273\n",
      "Epoch: 2/40, Batch: 16/62, Discriminator loss: 0.1776719093322754, Generator loss: 0.4212186932563782\n",
      "Epoch: 2/40, Batch: 17/62, Discriminator loss: 0.4367053806781769, Generator loss: 0.5123916268348694\n",
      "Epoch: 2/40, Batch: 18/62, Discriminator loss: 0.24484135210514069, Generator loss: 0.5435645580291748\n",
      "Epoch: 2/40, Batch: 19/62, Discriminator loss: 0.11204005777835846, Generator loss: 0.5834076404571533\n",
      "Epoch: 2/40, Batch: 20/62, Discriminator loss: 0.12724393606185913, Generator loss: 0.6200973391532898\n",
      "Epoch: 2/40, Batch: 21/62, Discriminator loss: 0.11990641802549362, Generator loss: 0.6420255899429321\n",
      "Epoch: 2/40, Batch: 22/62, Discriminator loss: 0.09213290363550186, Generator loss: 0.6953619122505188\n",
      "Epoch: 2/40, Batch: 23/62, Discriminator loss: -0.040783628821372986, Generator loss: 0.7509454488754272\n",
      "Epoch: 2/40, Batch: 24/62, Discriminator loss: -0.06778658181428909, Generator loss: 0.6326510310173035\n",
      "Epoch: 2/40, Batch: 25/62, Discriminator loss: 0.30485597252845764, Generator loss: 0.7078471779823303\n",
      "Epoch: 2/40, Batch: 26/62, Discriminator loss: -0.05544346570968628, Generator loss: 0.7865456938743591\n",
      "Epoch: 2/40, Batch: 27/62, Discriminator loss: 0.06429451704025269, Generator loss: 0.7295547127723694\n",
      "Epoch: 2/40, Batch: 28/62, Discriminator loss: 0.10083295404911041, Generator loss: 0.8841904997825623\n",
      "Epoch: 2/40, Batch: 29/62, Discriminator loss: -0.04655000567436218, Generator loss: 0.7652963399887085\n",
      "Epoch: 2/40, Batch: 30/62, Discriminator loss: -0.28941792249679565, Generator loss: 0.6709136962890625\n",
      "Epoch: 2/40, Batch: 31/62, Discriminator loss: -0.33795398473739624, Generator loss: 0.619434118270874\n",
      "Epoch: 2/40, Batch: 32/62, Discriminator loss: -0.1271338015794754, Generator loss: 0.6501058340072632\n",
      "Epoch: 2/40, Batch: 33/62, Discriminator loss: -0.49192845821380615, Generator loss: 0.44104310870170593\n",
      "Epoch: 2/40, Batch: 34/62, Discriminator loss: 0.4393223524093628, Generator loss: 0.46263566613197327\n",
      "Epoch: 2/40, Batch: 35/62, Discriminator loss: 0.17970864474773407, Generator loss: 0.35284584760665894\n",
      "Epoch: 2/40, Batch: 36/62, Discriminator loss: 0.4384130537509918, Generator loss: 0.4386095106601715\n",
      "Epoch: 2/40, Batch: 37/62, Discriminator loss: 0.12522226572036743, Generator loss: 0.5418732762336731\n",
      "Epoch: 2/40, Batch: 38/62, Discriminator loss: 0.08060711622238159, Generator loss: 0.49291765689849854\n",
      "Epoch: 2/40, Batch: 39/62, Discriminator loss: -0.08462804555892944, Generator loss: 0.5118072032928467\n",
      "Epoch: 2/40, Batch: 40/62, Discriminator loss: 0.19371536374092102, Generator loss: 0.5702471137046814\n",
      "Epoch: 2/40, Batch: 41/62, Discriminator loss: 0.09776962548494339, Generator loss: 0.5517385005950928\n",
      "Epoch: 2/40, Batch: 42/62, Discriminator loss: -0.2626825273036957, Generator loss: 0.5289333462715149\n",
      "Epoch: 2/40, Batch: 43/62, Discriminator loss: -0.12106212973594666, Generator loss: 0.4491579532623291\n",
      "Epoch: 2/40, Batch: 44/62, Discriminator loss: -0.3030274510383606, Generator loss: 0.3296545147895813\n",
      "Epoch: 2/40, Batch: 45/62, Discriminator loss: 0.6156599521636963, Generator loss: 0.19236385822296143\n",
      "Epoch: 2/40, Batch: 46/62, Discriminator loss: 0.8350674510002136, Generator loss: 0.15351150929927826\n",
      "Epoch: 2/40, Batch: 47/62, Discriminator loss: 0.5343255400657654, Generator loss: 0.5378424525260925\n",
      "Epoch: 2/40, Batch: 48/62, Discriminator loss: 0.4976370930671692, Generator loss: 0.8605173826217651\n",
      "Epoch: 2/40, Batch: 49/62, Discriminator loss: 0.34354323148727417, Generator loss: 0.8371185660362244\n",
      "Epoch: 2/40, Batch: 50/62, Discriminator loss: 0.40301114320755005, Generator loss: 0.5889010429382324\n",
      "Epoch: 2/40, Batch: 51/62, Discriminator loss: 0.25889724493026733, Generator loss: 0.6109755635261536\n",
      "Epoch: 2/40, Batch: 52/62, Discriminator loss: 0.17596721649169922, Generator loss: 0.5964740514755249\n",
      "Epoch: 2/40, Batch: 53/62, Discriminator loss: 0.2692321538925171, Generator loss: 0.7170443534851074\n",
      "Epoch: 2/40, Batch: 54/62, Discriminator loss: 0.028132915496826172, Generator loss: 0.7646141052246094\n",
      "Epoch: 2/40, Batch: 55/62, Discriminator loss: 0.22438600659370422, Generator loss: 0.7262089848518372\n",
      "Epoch: 2/40, Batch: 56/62, Discriminator loss: 0.16779091954231262, Generator loss: 0.7065920829772949\n",
      "Epoch: 2/40, Batch: 57/62, Discriminator loss: -0.03829920291900635, Generator loss: 0.6478927135467529\n",
      "Epoch: 2/40, Batch: 58/62, Discriminator loss: 0.32316628098487854, Generator loss: 0.6797224879264832\n",
      "Epoch: 2/40, Batch: 59/62, Discriminator loss: 0.230598583817482, Generator loss: 0.5857571959495544\n",
      "Epoch: 2/40, Batch: 60/62, Discriminator loss: 0.5082435011863708, Generator loss: 0.6974651217460632\n",
      "Epoch: 2/40, Batch: 61/62, Discriminator loss: 0.423683226108551, Generator loss: 0.6424087285995483\n",
      "Epoch: 2/40, Batch: 62/62, Discriminator loss: 0.5498844385147095, Generator loss: 0.3902241587638855\n",
      "Epoch: 3/40, Batch: 1/62, Discriminator loss: 0.8437246680259705, Generator loss: 0.3105376958847046\n",
      "Epoch: 3/40, Batch: 2/62, Discriminator loss: 0.9302520751953125, Generator loss: 0.3777526617050171\n",
      "Epoch: 3/40, Batch: 3/62, Discriminator loss: 0.5925279259681702, Generator loss: 0.3297000229358673\n",
      "Epoch: 3/40, Batch: 4/62, Discriminator loss: 0.791914165019989, Generator loss: 0.4878491163253784\n",
      "Epoch: 3/40, Batch: 5/62, Discriminator loss: 0.8166817426681519, Generator loss: 0.46502581238746643\n",
      "Epoch: 3/40, Batch: 6/62, Discriminator loss: 0.8729965686798096, Generator loss: 0.4711984097957611\n",
      "Epoch: 3/40, Batch: 7/62, Discriminator loss: 0.6771578192710876, Generator loss: 0.4589765667915344\n",
      "Epoch: 3/40, Batch: 8/62, Discriminator loss: 0.6928706765174866, Generator loss: 0.3522309958934784\n",
      "Epoch: 3/40, Batch: 9/62, Discriminator loss: 0.8292224407196045, Generator loss: 0.3528558611869812\n",
      "Epoch: 3/40, Batch: 10/62, Discriminator loss: 0.8281294107437134, Generator loss: 0.3221507668495178\n",
      "Epoch: 3/40, Batch: 11/62, Discriminator loss: 0.7942157983779907, Generator loss: 0.44943758845329285\n",
      "Epoch: 3/40, Batch: 12/62, Discriminator loss: 0.47568610310554504, Generator loss: 0.36699000000953674\n",
      "Epoch: 3/40, Batch: 13/62, Discriminator loss: 0.7869473695755005, Generator loss: 0.35893961787223816\n",
      "Epoch: 3/40, Batch: 14/62, Discriminator loss: 0.717520534992218, Generator loss: 0.3850780129432678\n",
      "Epoch: 3/40, Batch: 15/62, Discriminator loss: 0.6493892669677734, Generator loss: 0.3427436947822571\n",
      "Epoch: 3/40, Batch: 16/62, Discriminator loss: 0.504126787185669, Generator loss: 0.299673467874527\n",
      "Epoch: 3/40, Batch: 17/62, Discriminator loss: 0.6250834465026855, Generator loss: 0.4088633060455322\n",
      "Epoch: 3/40, Batch: 18/62, Discriminator loss: 0.48529118299484253, Generator loss: 0.4760878086090088\n",
      "Epoch: 3/40, Batch: 19/62, Discriminator loss: 0.49989449977874756, Generator loss: 0.4349674880504608\n",
      "Epoch: 3/40, Batch: 20/62, Discriminator loss: 0.6055054068565369, Generator loss: 0.5406138896942139\n",
      "Epoch: 3/40, Batch: 21/62, Discriminator loss: 0.6747108101844788, Generator loss: 0.4724693298339844\n",
      "Epoch: 3/40, Batch: 22/62, Discriminator loss: 0.6841179728507996, Generator loss: 0.5423328876495361\n",
      "Epoch: 3/40, Batch: 23/62, Discriminator loss: 0.7116384506225586, Generator loss: 0.5294793248176575\n",
      "Epoch: 3/40, Batch: 24/62, Discriminator loss: 0.7313448190689087, Generator loss: 0.36679384112358093\n",
      "Epoch: 3/40, Batch: 25/62, Discriminator loss: 0.844985842704773, Generator loss: 0.3431292474269867\n",
      "Epoch: 3/40, Batch: 26/62, Discriminator loss: 0.5662525296211243, Generator loss: 0.5032586455345154\n",
      "Epoch: 3/40, Batch: 27/62, Discriminator loss: 0.7251415252685547, Generator loss: 0.532644510269165\n",
      "Epoch: 3/40, Batch: 28/62, Discriminator loss: 0.6898256540298462, Generator loss: 0.5028376579284668\n",
      "Epoch: 3/40, Batch: 29/62, Discriminator loss: 0.8378502130508423, Generator loss: 0.39749857783317566\n",
      "Epoch: 3/40, Batch: 30/62, Discriminator loss: 0.6669070720672607, Generator loss: 0.36329615116119385\n",
      "Epoch: 3/40, Batch: 31/62, Discriminator loss: 0.6601883769035339, Generator loss: 0.3329697251319885\n",
      "Epoch: 3/40, Batch: 32/62, Discriminator loss: 0.7266189455986023, Generator loss: 0.36048588156700134\n",
      "Epoch: 3/40, Batch: 33/62, Discriminator loss: 0.6491482257843018, Generator loss: 0.3399098217487335\n",
      "Epoch: 3/40, Batch: 34/62, Discriminator loss: 0.7926739454269409, Generator loss: 0.37197232246398926\n",
      "Epoch: 3/40, Batch: 35/62, Discriminator loss: 0.6964978575706482, Generator loss: 0.41542449593544006\n",
      "Epoch: 3/40, Batch: 36/62, Discriminator loss: 0.6940561532974243, Generator loss: 0.45895037055015564\n",
      "Epoch: 3/40, Batch: 37/62, Discriminator loss: 0.6458015441894531, Generator loss: 0.3799670338630676\n",
      "Epoch: 3/40, Batch: 38/62, Discriminator loss: 0.8493369817733765, Generator loss: 0.33392438292503357\n",
      "Epoch: 3/40, Batch: 39/62, Discriminator loss: 0.7135411500930786, Generator loss: 0.2696021795272827\n",
      "Epoch: 3/40, Batch: 40/62, Discriminator loss: 0.7995153665542603, Generator loss: 0.3563464283943176\n",
      "Epoch: 3/40, Batch: 41/62, Discriminator loss: 0.8159084320068359, Generator loss: 0.38662615418434143\n",
      "Epoch: 3/40, Batch: 42/62, Discriminator loss: 0.7273333072662354, Generator loss: 0.35885539650917053\n",
      "Epoch: 3/40, Batch: 43/62, Discriminator loss: 0.6845649480819702, Generator loss: 0.4106210768222809\n",
      "Epoch: 3/40, Batch: 44/62, Discriminator loss: 0.7603992819786072, Generator loss: 0.3370805084705353\n",
      "Epoch: 3/40, Batch: 45/62, Discriminator loss: 0.69921875, Generator loss: 0.35651564598083496\n",
      "Epoch: 3/40, Batch: 46/62, Discriminator loss: 0.8597770929336548, Generator loss: 0.3498428165912628\n",
      "Epoch: 3/40, Batch: 47/62, Discriminator loss: 0.7991200685501099, Generator loss: 0.4468018412590027\n",
      "Epoch: 3/40, Batch: 48/62, Discriminator loss: 0.9002342224121094, Generator loss: 0.4329884946346283\n",
      "Epoch: 3/40, Batch: 49/62, Discriminator loss: 0.8300004005432129, Generator loss: 0.40400540828704834\n",
      "Epoch: 3/40, Batch: 50/62, Discriminator loss: 1.0254446268081665, Generator loss: 0.33486682176589966\n",
      "Epoch: 3/40, Batch: 51/62, Discriminator loss: 0.7279402017593384, Generator loss: 0.3580150008201599\n",
      "Epoch: 3/40, Batch: 52/62, Discriminator loss: 0.7365283966064453, Generator loss: 0.33668166399002075\n",
      "Epoch: 3/40, Batch: 53/62, Discriminator loss: 0.891926109790802, Generator loss: 0.30207473039627075\n",
      "Epoch: 3/40, Batch: 54/62, Discriminator loss: 0.7598810195922852, Generator loss: 0.37288719415664673\n",
      "Epoch: 3/40, Batch: 55/62, Discriminator loss: 0.9767389297485352, Generator loss: 0.34390658140182495\n",
      "Epoch: 3/40, Batch: 56/62, Discriminator loss: 0.8601751327514648, Generator loss: 0.38032588362693787\n",
      "Epoch: 3/40, Batch: 57/62, Discriminator loss: 0.7003175616264343, Generator loss: 0.3532807230949402\n",
      "Epoch: 3/40, Batch: 58/62, Discriminator loss: 0.8275951743125916, Generator loss: 0.41240665316581726\n",
      "Epoch: 3/40, Batch: 59/62, Discriminator loss: 0.8508378863334656, Generator loss: 0.4836318790912628\n",
      "Epoch: 3/40, Batch: 60/62, Discriminator loss: 0.9810237884521484, Generator loss: 0.4789976477622986\n",
      "Epoch: 3/40, Batch: 61/62, Discriminator loss: 0.7539957165718079, Generator loss: 0.4721483290195465\n",
      "Epoch: 3/40, Batch: 62/62, Discriminator loss: 0.7770724296569824, Generator loss: 0.4410863220691681\n",
      "Epoch: 4/40, Batch: 1/62, Discriminator loss: 0.8201406598091125, Generator loss: 0.4675866961479187\n",
      "Epoch: 4/40, Batch: 2/62, Discriminator loss: 0.7212653160095215, Generator loss: 0.448527067899704\n",
      "Epoch: 4/40, Batch: 3/62, Discriminator loss: 0.5983403921127319, Generator loss: 0.3242420554161072\n",
      "Epoch: 4/40, Batch: 4/62, Discriminator loss: 0.6937258243560791, Generator loss: 0.3782685101032257\n",
      "Epoch: 4/40, Batch: 5/62, Discriminator loss: 0.7778675556182861, Generator loss: 0.39855441451072693\n",
      "Epoch: 4/40, Batch: 6/62, Discriminator loss: 0.804558515548706, Generator loss: 0.43379753828048706\n",
      "Epoch: 4/40, Batch: 7/62, Discriminator loss: 0.6654547452926636, Generator loss: 0.4317310154438019\n",
      "Epoch: 4/40, Batch: 8/62, Discriminator loss: 0.6456283330917358, Generator loss: 0.42819735407829285\n",
      "Epoch: 4/40, Batch: 9/62, Discriminator loss: 0.6456257104873657, Generator loss: 0.42784008383750916\n",
      "Epoch: 4/40, Batch: 10/62, Discriminator loss: 0.7952674031257629, Generator loss: 0.36814042925834656\n",
      "Epoch: 4/40, Batch: 11/62, Discriminator loss: 0.7086813449859619, Generator loss: 0.4485190212726593\n",
      "Epoch: 4/40, Batch: 12/62, Discriminator loss: 0.5667680501937866, Generator loss: 0.3542446494102478\n",
      "Epoch: 4/40, Batch: 13/62, Discriminator loss: 0.7575936913490295, Generator loss: 0.35738280415534973\n",
      "Epoch: 4/40, Batch: 14/62, Discriminator loss: 0.6518710851669312, Generator loss: 0.3347785472869873\n",
      "Epoch: 4/40, Batch: 15/62, Discriminator loss: 0.700012743473053, Generator loss: 0.32925570011138916\n",
      "Epoch: 4/40, Batch: 16/62, Discriminator loss: 0.5689924955368042, Generator loss: 0.30949389934539795\n",
      "Epoch: 4/40, Batch: 17/62, Discriminator loss: 0.7999364137649536, Generator loss: 0.30190643668174744\n",
      "Epoch: 4/40, Batch: 18/62, Discriminator loss: 0.7374069690704346, Generator loss: 0.35856691002845764\n",
      "Epoch: 4/40, Batch: 19/62, Discriminator loss: 0.7168084383010864, Generator loss: 0.3089519739151001\n",
      "Epoch: 4/40, Batch: 20/62, Discriminator loss: 0.8431953191757202, Generator loss: 0.3373996913433075\n",
      "Epoch: 4/40, Batch: 21/62, Discriminator loss: 0.7838945388793945, Generator loss: 0.3639860451221466\n",
      "Epoch: 4/40, Batch: 22/62, Discriminator loss: 0.7553087472915649, Generator loss: 0.35501614212989807\n",
      "Epoch: 4/40, Batch: 23/62, Discriminator loss: 0.8031622171401978, Generator loss: 0.3252786695957184\n",
      "Epoch: 4/40, Batch: 24/62, Discriminator loss: 0.8643255233764648, Generator loss: 0.2455909550189972\n",
      "Epoch: 4/40, Batch: 25/62, Discriminator loss: 0.9743219017982483, Generator loss: 0.30057358741760254\n",
      "Epoch: 4/40, Batch: 26/62, Discriminator loss: 0.8309283256530762, Generator loss: 0.28202977776527405\n",
      "Epoch: 4/40, Batch: 27/62, Discriminator loss: 0.8239749073982239, Generator loss: 0.3316897749900818\n",
      "Epoch: 4/40, Batch: 28/62, Discriminator loss: 0.8757131099700928, Generator loss: 0.3328489363193512\n",
      "Epoch: 4/40, Batch: 29/62, Discriminator loss: 0.9049240946769714, Generator loss: 0.3650778532028198\n",
      "Epoch: 4/40, Batch: 30/62, Discriminator loss: 0.6634235382080078, Generator loss: 0.313381552696228\n",
      "Epoch: 4/40, Batch: 31/62, Discriminator loss: 0.6993824243545532, Generator loss: 0.2826875150203705\n",
      "Epoch: 4/40, Batch: 32/62, Discriminator loss: 0.790603756904602, Generator loss: 0.306465208530426\n",
      "Epoch: 4/40, Batch: 33/62, Discriminator loss: 0.6743078231811523, Generator loss: 0.24855880439281464\n",
      "Epoch: 4/40, Batch: 34/62, Discriminator loss: 0.8940266370773315, Generator loss: 0.3016708195209503\n",
      "Epoch: 4/40, Batch: 35/62, Discriminator loss: 0.7115879058837891, Generator loss: 0.34118571877479553\n",
      "Epoch: 4/40, Batch: 36/62, Discriminator loss: 0.7396591901779175, Generator loss: 0.35400810837745667\n",
      "Epoch: 4/40, Batch: 37/62, Discriminator loss: 0.6194195747375488, Generator loss: 0.3758885860443115\n",
      "Epoch: 4/40, Batch: 38/62, Discriminator loss: 0.614006757736206, Generator loss: 0.35760176181793213\n",
      "Epoch: 4/40, Batch: 39/62, Discriminator loss: 0.5905222296714783, Generator loss: 0.4182296395301819\n",
      "Epoch: 4/40, Batch: 40/62, Discriminator loss: 0.6483203172683716, Generator loss: 0.43257826566696167\n",
      "Epoch: 4/40, Batch: 41/62, Discriminator loss: 0.6101653575897217, Generator loss: 0.43818750977516174\n",
      "Epoch: 4/40, Batch: 42/62, Discriminator loss: 0.5545932650566101, Generator loss: 0.45562827587127686\n",
      "Epoch: 4/40, Batch: 43/62, Discriminator loss: 0.6194742918014526, Generator loss: 0.4460223317146301\n",
      "Epoch: 4/40, Batch: 44/62, Discriminator loss: 0.5392656922340393, Generator loss: 0.4377160966396332\n",
      "Epoch: 4/40, Batch: 45/62, Discriminator loss: 0.687710702419281, Generator loss: 0.48853668570518494\n",
      "Epoch: 4/40, Batch: 46/62, Discriminator loss: 0.672243058681488, Generator loss: 0.5399672985076904\n",
      "Epoch: 4/40, Batch: 47/62, Discriminator loss: 0.5566261410713196, Generator loss: 0.5647938847541809\n",
      "Epoch: 4/40, Batch: 48/62, Discriminator loss: 0.6866055727005005, Generator loss: 0.5496843457221985\n",
      "Epoch: 4/40, Batch: 49/62, Discriminator loss: 0.6008750796318054, Generator loss: 0.5720613598823547\n",
      "Epoch: 4/40, Batch: 50/62, Discriminator loss: 0.7104724645614624, Generator loss: 0.5413984656333923\n",
      "Epoch: 4/40, Batch: 51/62, Discriminator loss: 0.6678215861320496, Generator loss: 0.5502088069915771\n",
      "Epoch: 4/40, Batch: 52/62, Discriminator loss: 0.6145910024642944, Generator loss: 0.4925209879875183\n",
      "Epoch: 4/40, Batch: 53/62, Discriminator loss: 0.8091438412666321, Generator loss: 0.6140146851539612\n",
      "Epoch: 4/40, Batch: 54/62, Discriminator loss: 0.7140825986862183, Generator loss: 0.5334195494651794\n",
      "Epoch: 4/40, Batch: 55/62, Discriminator loss: 0.7753315567970276, Generator loss: 0.5598448514938354\n",
      "Epoch: 4/40, Batch: 56/62, Discriminator loss: 0.6976410150527954, Generator loss: 0.5358341336250305\n",
      "Epoch: 4/40, Batch: 57/62, Discriminator loss: 0.7573555111885071, Generator loss: 0.519985020160675\n",
      "Epoch: 4/40, Batch: 58/62, Discriminator loss: 0.7026185989379883, Generator loss: 0.4448135197162628\n",
      "Epoch: 4/40, Batch: 59/62, Discriminator loss: 0.7708570957183838, Generator loss: 0.4903586804866791\n",
      "Epoch: 4/40, Batch: 60/62, Discriminator loss: 0.7673805952072144, Generator loss: 0.4975278377532959\n",
      "Epoch: 4/40, Batch: 61/62, Discriminator loss: 0.7296448349952698, Generator loss: 0.5200594663619995\n",
      "Epoch: 4/40, Batch: 62/62, Discriminator loss: 0.7276349067687988, Generator loss: 0.4504314661026001\n",
      "Epoch: 5/40, Batch: 1/62, Discriminator loss: 0.7733895182609558, Generator loss: 0.44033586978912354\n",
      "Epoch: 5/40, Batch: 2/62, Discriminator loss: 0.8068555593490601, Generator loss: 0.42568066716194153\n",
      "Epoch: 5/40, Batch: 3/62, Discriminator loss: 0.6460617780685425, Generator loss: 0.3608279824256897\n",
      "Epoch: 5/40, Batch: 4/62, Discriminator loss: 0.7952191829681396, Generator loss: 0.3914757966995239\n",
      "Epoch: 5/40, Batch: 5/62, Discriminator loss: 0.7930638194084167, Generator loss: 0.4559551179409027\n",
      "Epoch: 5/40, Batch: 6/62, Discriminator loss: 0.6753134727478027, Generator loss: 0.46387454867362976\n",
      "Epoch: 5/40, Batch: 7/62, Discriminator loss: 0.7294982671737671, Generator loss: 0.489798367023468\n",
      "Epoch: 5/40, Batch: 8/62, Discriminator loss: 0.7254196405410767, Generator loss: 0.4866703450679779\n",
      "Epoch: 5/40, Batch: 9/62, Discriminator loss: 0.6400043964385986, Generator loss: 0.4856536090373993\n",
      "Epoch: 5/40, Batch: 10/62, Discriminator loss: 0.6052531003952026, Generator loss: 0.46999114751815796\n",
      "Epoch: 5/40, Batch: 11/62, Discriminator loss: 0.6330645680427551, Generator loss: 0.5023054480552673\n",
      "Epoch: 5/40, Batch: 12/62, Discriminator loss: 0.5731797218322754, Generator loss: 0.45082080364227295\n",
      "Epoch: 5/40, Batch: 13/62, Discriminator loss: 0.6316561698913574, Generator loss: 0.4458698630332947\n",
      "Epoch: 5/40, Batch: 14/62, Discriminator loss: 0.6048077344894409, Generator loss: 0.47688767313957214\n",
      "Epoch: 5/40, Batch: 15/62, Discriminator loss: 0.5870974659919739, Generator loss: 0.45221278071403503\n",
      "Epoch: 5/40, Batch: 16/62, Discriminator loss: 0.5506821870803833, Generator loss: 0.43402591347694397\n",
      "Epoch: 5/40, Batch: 17/62, Discriminator loss: 0.7189263105392456, Generator loss: 0.4649466574192047\n",
      "Epoch: 5/40, Batch: 18/62, Discriminator loss: 0.6413064002990723, Generator loss: 0.5106258988380432\n",
      "Epoch: 5/40, Batch: 19/62, Discriminator loss: 0.6571229100227356, Generator loss: 0.47431570291519165\n",
      "Epoch: 5/40, Batch: 20/62, Discriminator loss: 0.616774320602417, Generator loss: 0.5119636058807373\n",
      "Epoch: 5/40, Batch: 21/62, Discriminator loss: 0.5936692953109741, Generator loss: 0.48236626386642456\n",
      "Epoch: 5/40, Batch: 22/62, Discriminator loss: 0.5851057767868042, Generator loss: 0.5085786581039429\n",
      "Epoch: 5/40, Batch: 23/62, Discriminator loss: 0.5701249837875366, Generator loss: 0.5312366485595703\n",
      "Epoch: 5/40, Batch: 24/62, Discriminator loss: 0.5258548855781555, Generator loss: 0.49799051880836487\n",
      "Epoch: 5/40, Batch: 25/62, Discriminator loss: 0.6627219319343567, Generator loss: 0.4342797100543976\n",
      "Epoch: 5/40, Batch: 26/62, Discriminator loss: 0.6378272771835327, Generator loss: 0.5345380902290344\n",
      "Epoch: 5/40, Batch: 27/62, Discriminator loss: 0.6571551561355591, Generator loss: 0.5490565896034241\n",
      "Epoch: 5/40, Batch: 28/62, Discriminator loss: 0.6817020773887634, Generator loss: 0.5496206879615784\n",
      "Epoch: 5/40, Batch: 29/62, Discriminator loss: 0.6307603120803833, Generator loss: 0.5061209201812744\n",
      "Epoch: 5/40, Batch: 30/62, Discriminator loss: 0.6420786380767822, Generator loss: 0.44954079389572144\n",
      "Epoch: 5/40, Batch: 31/62, Discriminator loss: 0.6831454038619995, Generator loss: 0.4355350732803345\n",
      "Epoch: 5/40, Batch: 32/62, Discriminator loss: 0.6272666454315186, Generator loss: 0.3916042149066925\n",
      "Epoch: 5/40, Batch: 33/62, Discriminator loss: 0.5703113079071045, Generator loss: 0.3404523730278015\n",
      "Epoch: 5/40, Batch: 34/62, Discriminator loss: 0.7309809923171997, Generator loss: 0.4058639705181122\n",
      "Epoch: 5/40, Batch: 35/62, Discriminator loss: 0.5249510407447815, Generator loss: 0.43867212533950806\n",
      "Epoch: 5/40, Batch: 36/62, Discriminator loss: 0.7405483722686768, Generator loss: 0.44691938161849976\n",
      "Epoch: 5/40, Batch: 37/62, Discriminator loss: 0.656592607498169, Generator loss: 0.43747615814208984\n",
      "Epoch: 5/40, Batch: 38/62, Discriminator loss: 0.6411470770835876, Generator loss: 0.40548667311668396\n",
      "Epoch: 5/40, Batch: 39/62, Discriminator loss: 0.6721782088279724, Generator loss: 0.4305027425289154\n",
      "Epoch: 5/40, Batch: 40/62, Discriminator loss: 0.7111009359359741, Generator loss: 0.39707711338996887\n",
      "Epoch: 5/40, Batch: 41/62, Discriminator loss: 0.7223756313323975, Generator loss: 0.4410998821258545\n",
      "Epoch: 5/40, Batch: 42/62, Discriminator loss: 0.6394283771514893, Generator loss: 0.38719362020492554\n",
      "Epoch: 5/40, Batch: 43/62, Discriminator loss: 0.6672612428665161, Generator loss: 0.4061927795410156\n",
      "Epoch: 5/40, Batch: 44/62, Discriminator loss: 0.6495335102081299, Generator loss: 0.4474753737449646\n",
      "Epoch: 5/40, Batch: 45/62, Discriminator loss: 0.6548670530319214, Generator loss: 0.4693746566772461\n",
      "Epoch: 5/40, Batch: 46/62, Discriminator loss: 0.6167868375778198, Generator loss: 0.46294552087783813\n",
      "Epoch: 5/40, Batch: 47/62, Discriminator loss: 0.6533148884773254, Generator loss: 0.4996570348739624\n",
      "Epoch: 5/40, Batch: 48/62, Discriminator loss: 0.7063673138618469, Generator loss: 0.4898625612258911\n",
      "Epoch: 5/40, Batch: 49/62, Discriminator loss: 0.6249499917030334, Generator loss: 0.4978274703025818\n",
      "Epoch: 5/40, Batch: 50/62, Discriminator loss: 0.5557277202606201, Generator loss: 0.4417796730995178\n",
      "Epoch: 5/40, Batch: 51/62, Discriminator loss: 0.6634035110473633, Generator loss: 0.4437198042869568\n",
      "Epoch: 5/40, Batch: 52/62, Discriminator loss: 0.6512799263000488, Generator loss: 0.4125158190727234\n",
      "Epoch: 5/40, Batch: 53/62, Discriminator loss: 0.6281369924545288, Generator loss: 0.44715994596481323\n",
      "Epoch: 5/40, Batch: 54/62, Discriminator loss: 0.6980966329574585, Generator loss: 0.4947536587715149\n",
      "Epoch: 5/40, Batch: 55/62, Discriminator loss: 0.7175583839416504, Generator loss: 0.49300679564476013\n",
      "Epoch: 5/40, Batch: 56/62, Discriminator loss: 0.6314392685890198, Generator loss: 0.48923879861831665\n",
      "Epoch: 5/40, Batch: 57/62, Discriminator loss: 0.6241251230239868, Generator loss: 0.49106165766716003\n",
      "Epoch: 5/40, Batch: 58/62, Discriminator loss: 0.7015546560287476, Generator loss: 0.4761165380477905\n",
      "Epoch: 5/40, Batch: 59/62, Discriminator loss: 0.68648362159729, Generator loss: 0.4846307337284088\n",
      "Epoch: 5/40, Batch: 60/62, Discriminator loss: 0.6655592918395996, Generator loss: 0.5405534505844116\n",
      "Epoch: 5/40, Batch: 61/62, Discriminator loss: 0.6509286761283875, Generator loss: 0.5983139872550964\n",
      "Epoch: 5/40, Batch: 62/62, Discriminator loss: 0.6213839054107666, Generator loss: 0.5591525435447693\n",
      "Accuracy real: 24%, fake: 0%\n",
      "Epoch: 6/40, Batch: 1/62, Discriminator loss: 0.7341147065162659, Generator loss: 0.5450109243392944\n",
      "Epoch: 6/40, Batch: 2/62, Discriminator loss: 0.6327335834503174, Generator loss: 0.48422327637672424\n",
      "Epoch: 6/40, Batch: 3/62, Discriminator loss: 0.5271167755126953, Generator loss: 0.44721728563308716\n",
      "Epoch: 6/40, Batch: 4/62, Discriminator loss: 0.6011655330657959, Generator loss: 0.4528788626194\n",
      "Epoch: 6/40, Batch: 5/62, Discriminator loss: 0.5767544507980347, Generator loss: 0.4971283972263336\n",
      "Epoch: 6/40, Batch: 6/62, Discriminator loss: 0.554589033126831, Generator loss: 0.5648911595344543\n",
      "Epoch: 6/40, Batch: 7/62, Discriminator loss: 0.5203806161880493, Generator loss: 0.629509449005127\n",
      "Epoch: 6/40, Batch: 8/62, Discriminator loss: 0.5233449935913086, Generator loss: 0.5877912044525146\n",
      "Epoch: 6/40, Batch: 9/62, Discriminator loss: 0.5549531579017639, Generator loss: 0.6163800358772278\n",
      "Epoch: 6/40, Batch: 10/62, Discriminator loss: 0.5342915058135986, Generator loss: 0.6837997436523438\n",
      "Epoch: 6/40, Batch: 11/62, Discriminator loss: 0.5400891900062561, Generator loss: 0.7214176058769226\n",
      "Epoch: 6/40, Batch: 12/62, Discriminator loss: 0.43462198972702026, Generator loss: 0.6244754791259766\n",
      "Epoch: 6/40, Batch: 13/62, Discriminator loss: 0.506619393825531, Generator loss: 0.6072894334793091\n",
      "Epoch: 6/40, Batch: 14/62, Discriminator loss: 0.558763325214386, Generator loss: 0.5807909965515137\n",
      "Epoch: 6/40, Batch: 15/62, Discriminator loss: 0.5699883699417114, Generator loss: 0.561438798904419\n",
      "Epoch: 6/40, Batch: 16/62, Discriminator loss: 0.3758326470851898, Generator loss: 0.47260382771492004\n",
      "Epoch: 6/40, Batch: 17/62, Discriminator loss: 0.5258163213729858, Generator loss: 0.4881274998188019\n",
      "Epoch: 6/40, Batch: 18/62, Discriminator loss: 0.5289520025253296, Generator loss: 0.544450581073761\n",
      "Epoch: 6/40, Batch: 19/62, Discriminator loss: 0.5232093930244446, Generator loss: 0.5443187355995178\n",
      "Epoch: 6/40, Batch: 20/62, Discriminator loss: 0.6195571422576904, Generator loss: 0.49106496572494507\n",
      "Epoch: 6/40, Batch: 21/62, Discriminator loss: 0.6149001121520996, Generator loss: 0.4169316589832306\n",
      "Epoch: 6/40, Batch: 22/62, Discriminator loss: 0.6712357997894287, Generator loss: 0.3580070734024048\n",
      "Epoch: 6/40, Batch: 23/62, Discriminator loss: 0.6566505432128906, Generator loss: 0.3481375277042389\n",
      "Epoch: 6/40, Batch: 24/62, Discriminator loss: 0.5086165070533752, Generator loss: 0.2853944003582001\n",
      "Epoch: 6/40, Batch: 25/62, Discriminator loss: 0.7239918112754822, Generator loss: 0.2782461643218994\n",
      "Epoch: 6/40, Batch: 26/62, Discriminator loss: 0.5771983861923218, Generator loss: 0.27699440717697144\n",
      "Epoch: 6/40, Batch: 27/62, Discriminator loss: 0.5721153020858765, Generator loss: 0.2685188055038452\n",
      "Epoch: 6/40, Batch: 28/62, Discriminator loss: 0.6287189722061157, Generator loss: 0.2495597004890442\n",
      "Epoch: 6/40, Batch: 29/62, Discriminator loss: 0.5675608515739441, Generator loss: 0.27814966440200806\n",
      "Epoch: 6/40, Batch: 30/62, Discriminator loss: 0.49431276321411133, Generator loss: 0.2388254851102829\n",
      "Epoch: 6/40, Batch: 31/62, Discriminator loss: 0.5759315490722656, Generator loss: 0.24435003101825714\n",
      "Epoch: 6/40, Batch: 32/62, Discriminator loss: 0.614427924156189, Generator loss: 0.27732110023498535\n",
      "Epoch: 6/40, Batch: 33/62, Discriminator loss: 0.45560044050216675, Generator loss: 0.27080222964286804\n",
      "Epoch: 6/40, Batch: 34/62, Discriminator loss: 0.736099123954773, Generator loss: 0.3158542215824127\n",
      "Epoch: 6/40, Batch: 35/62, Discriminator loss: 0.5266128182411194, Generator loss: 0.36782392859458923\n",
      "Epoch: 6/40, Batch: 36/62, Discriminator loss: 0.6077512502670288, Generator loss: 0.4055308699607849\n",
      "Epoch: 6/40, Batch: 37/62, Discriminator loss: 0.5658940672874451, Generator loss: 0.40830400586128235\n",
      "Epoch: 6/40, Batch: 38/62, Discriminator loss: 0.5806483030319214, Generator loss: 0.4076797366142273\n",
      "Epoch: 6/40, Batch: 39/62, Discriminator loss: 0.5477018356323242, Generator loss: 0.40166231989860535\n",
      "Epoch: 6/40, Batch: 40/62, Discriminator loss: 0.6261164546012878, Generator loss: 0.42230120301246643\n",
      "Epoch: 6/40, Batch: 41/62, Discriminator loss: 0.6060826778411865, Generator loss: 0.4007168412208557\n",
      "Epoch: 6/40, Batch: 42/62, Discriminator loss: 0.5002532005310059, Generator loss: 0.3873768448829651\n",
      "Epoch: 6/40, Batch: 43/62, Discriminator loss: 0.5411832332611084, Generator loss: 0.3893910050392151\n",
      "Epoch: 6/40, Batch: 44/62, Discriminator loss: 0.4464605450630188, Generator loss: 0.3542048931121826\n",
      "Epoch: 6/40, Batch: 45/62, Discriminator loss: 0.5575672388076782, Generator loss: 0.3518361747264862\n",
      "Epoch: 6/40, Batch: 46/62, Discriminator loss: 0.5038567781448364, Generator loss: 0.3548925220966339\n",
      "Epoch: 6/40, Batch: 47/62, Discriminator loss: 0.4183492064476013, Generator loss: 0.39373722672462463\n",
      "Epoch: 6/40, Batch: 48/62, Discriminator loss: 0.5829299688339233, Generator loss: 0.399181604385376\n",
      "Epoch: 6/40, Batch: 49/62, Discriminator loss: 0.3799138069152832, Generator loss: 0.37690645456314087\n",
      "Epoch: 6/40, Batch: 50/62, Discriminator loss: 0.4496653079986572, Generator loss: 0.4199405908584595\n",
      "Epoch: 6/40, Batch: 51/62, Discriminator loss: 0.4709963798522949, Generator loss: 0.38142725825309753\n",
      "Epoch: 6/40, Batch: 52/62, Discriminator loss: 0.3853868246078491, Generator loss: 0.4055746793746948\n",
      "Epoch: 6/40, Batch: 53/62, Discriminator loss: 0.44604331254959106, Generator loss: 0.4046350419521332\n",
      "Epoch: 6/40, Batch: 54/62, Discriminator loss: 0.44007760286331177, Generator loss: 0.4186885952949524\n",
      "Epoch: 6/40, Batch: 55/62, Discriminator loss: 0.5023074150085449, Generator loss: 0.4374554455280304\n",
      "Epoch: 6/40, Batch: 56/62, Discriminator loss: 0.4841487407684326, Generator loss: 0.45250460505485535\n",
      "Epoch: 6/40, Batch: 57/62, Discriminator loss: 0.4123309254646301, Generator loss: 0.423419326543808\n",
      "Epoch: 6/40, Batch: 58/62, Discriminator loss: 0.5371100902557373, Generator loss: 0.4240584075450897\n",
      "Epoch: 6/40, Batch: 59/62, Discriminator loss: 0.5254121422767639, Generator loss: 0.5052955150604248\n",
      "Epoch: 6/40, Batch: 60/62, Discriminator loss: 0.5990809798240662, Generator loss: 0.6001837849617004\n",
      "Epoch: 6/40, Batch: 61/62, Discriminator loss: 0.5793102979660034, Generator loss: 0.6109488606452942\n",
      "Epoch: 6/40, Batch: 62/62, Discriminator loss: 0.5369698405265808, Generator loss: 0.5351614952087402\n",
      "Epoch: 7/40, Batch: 1/62, Discriminator loss: 0.5674465298652649, Generator loss: 0.5214807391166687\n",
      "Epoch: 7/40, Batch: 2/62, Discriminator loss: 0.5932879447937012, Generator loss: 0.4678329825401306\n",
      "Epoch: 7/40, Batch: 3/62, Discriminator loss: 0.4582691788673401, Generator loss: 0.39046651124954224\n",
      "Epoch: 7/40, Batch: 4/62, Discriminator loss: 0.6529607176780701, Generator loss: 0.3712858557701111\n",
      "Epoch: 7/40, Batch: 5/62, Discriminator loss: 0.6485322713851929, Generator loss: 0.41805869340896606\n",
      "Epoch: 7/40, Batch: 6/62, Discriminator loss: 0.6767663955688477, Generator loss: 0.4192444384098053\n",
      "Epoch: 7/40, Batch: 7/62, Discriminator loss: 0.661247968673706, Generator loss: 0.3813018798828125\n",
      "Epoch: 7/40, Batch: 8/62, Discriminator loss: 0.5979049205780029, Generator loss: 0.338168740272522\n",
      "Epoch: 7/40, Batch: 9/62, Discriminator loss: 0.6962505578994751, Generator loss: 0.31393125653266907\n",
      "Epoch: 7/40, Batch: 10/62, Discriminator loss: 0.6862984299659729, Generator loss: 0.3119547367095947\n",
      "Epoch: 7/40, Batch: 11/62, Discriminator loss: 0.6560415029525757, Generator loss: 0.3335116505622864\n",
      "Epoch: 7/40, Batch: 12/62, Discriminator loss: 0.4495294988155365, Generator loss: 0.2956235408782959\n",
      "Epoch: 7/40, Batch: 13/62, Discriminator loss: 0.5559692978858948, Generator loss: 0.3089422881603241\n",
      "Epoch: 7/40, Batch: 14/62, Discriminator loss: 0.5188232660293579, Generator loss: 0.3073004484176636\n",
      "Epoch: 7/40, Batch: 15/62, Discriminator loss: 0.3920469284057617, Generator loss: 0.30630308389663696\n",
      "Epoch: 7/40, Batch: 16/62, Discriminator loss: 0.3180961608886719, Generator loss: 0.28047487139701843\n",
      "Epoch: 7/40, Batch: 17/62, Discriminator loss: 0.5053908824920654, Generator loss: 0.3078373372554779\n",
      "Epoch: 7/40, Batch: 18/62, Discriminator loss: 0.48941296339035034, Generator loss: 0.3558272123336792\n",
      "Epoch: 7/40, Batch: 19/62, Discriminator loss: 0.44693100452423096, Generator loss: 0.36234375834465027\n",
      "Epoch: 7/40, Batch: 20/62, Discriminator loss: 0.5215282440185547, Generator loss: 0.37306511402130127\n",
      "Epoch: 7/40, Batch: 21/62, Discriminator loss: 0.4383234977722168, Generator loss: 0.39160794019699097\n",
      "Epoch: 7/40, Batch: 22/62, Discriminator loss: 0.5316274166107178, Generator loss: 0.41022250056266785\n",
      "Epoch: 7/40, Batch: 23/62, Discriminator loss: 0.4881328344345093, Generator loss: 0.5041128396987915\n",
      "Epoch: 7/40, Batch: 24/62, Discriminator loss: 0.4277759790420532, Generator loss: 0.44488272070884705\n",
      "Epoch: 7/40, Batch: 25/62, Discriminator loss: 0.635424017906189, Generator loss: 0.4564632177352905\n",
      "Epoch: 7/40, Batch: 26/62, Discriminator loss: 0.5195645093917847, Generator loss: 0.5053974390029907\n",
      "Epoch: 7/40, Batch: 27/62, Discriminator loss: 0.5754912495613098, Generator loss: 0.49770984053611755\n",
      "Epoch: 7/40, Batch: 28/62, Discriminator loss: 0.6072349548339844, Generator loss: 0.5470006465911865\n",
      "Epoch: 7/40, Batch: 29/62, Discriminator loss: 0.5869864821434021, Generator loss: 0.50856614112854\n",
      "Epoch: 7/40, Batch: 30/62, Discriminator loss: 0.6136602163314819, Generator loss: 0.42515119910240173\n",
      "Epoch: 7/40, Batch: 31/62, Discriminator loss: 0.637637734413147, Generator loss: 0.3685700297355652\n",
      "Epoch: 7/40, Batch: 32/62, Discriminator loss: 0.6492247581481934, Generator loss: 0.3733612895011902\n",
      "Epoch: 7/40, Batch: 33/62, Discriminator loss: 0.6018655896186829, Generator loss: 0.31432098150253296\n",
      "Epoch: 7/40, Batch: 34/62, Discriminator loss: 0.7794767618179321, Generator loss: 0.32821735739707947\n",
      "Epoch: 7/40, Batch: 35/62, Discriminator loss: 0.6549043655395508, Generator loss: 0.31961411237716675\n",
      "Epoch: 7/40, Batch: 36/62, Discriminator loss: 0.6989747285842896, Generator loss: 0.31880855560302734\n",
      "Epoch: 7/40, Batch: 37/62, Discriminator loss: 0.6834144592285156, Generator loss: 0.3507467806339264\n",
      "Epoch: 7/40, Batch: 38/62, Discriminator loss: 0.6364374160766602, Generator loss: 0.34137770533561707\n",
      "Epoch: 7/40, Batch: 39/62, Discriminator loss: 0.6177470684051514, Generator loss: 0.3068027198314667\n",
      "Epoch: 7/40, Batch: 40/62, Discriminator loss: 0.6872236728668213, Generator loss: 0.3634112477302551\n",
      "Epoch: 7/40, Batch: 41/62, Discriminator loss: 0.6521708965301514, Generator loss: 0.37733712792396545\n",
      "Epoch: 7/40, Batch: 42/62, Discriminator loss: 0.597432017326355, Generator loss: 0.33235853910446167\n",
      "Epoch: 7/40, Batch: 43/62, Discriminator loss: 0.6559111475944519, Generator loss: 0.36123234033584595\n",
      "Epoch: 7/40, Batch: 44/62, Discriminator loss: 0.5921996235847473, Generator loss: 0.33097100257873535\n",
      "Epoch: 7/40, Batch: 45/62, Discriminator loss: 0.5993102192878723, Generator loss: 0.3641754686832428\n",
      "Epoch: 7/40, Batch: 46/62, Discriminator loss: 0.6420811414718628, Generator loss: 0.3895217478275299\n",
      "Epoch: 7/40, Batch: 47/62, Discriminator loss: 0.5869559049606323, Generator loss: 0.38388583064079285\n",
      "Epoch: 7/40, Batch: 48/62, Discriminator loss: 0.6807538270950317, Generator loss: 0.3957531452178955\n",
      "Epoch: 7/40, Batch: 49/62, Discriminator loss: 0.6618726849555969, Generator loss: 0.37787142395973206\n",
      "Epoch: 7/40, Batch: 50/62, Discriminator loss: 0.641377329826355, Generator loss: 0.33004653453826904\n",
      "Epoch: 7/40, Batch: 51/62, Discriminator loss: 0.638594925403595, Generator loss: 0.33173540234565735\n",
      "Epoch: 7/40, Batch: 52/62, Discriminator loss: 0.5659897923469543, Generator loss: 0.3348265588283539\n",
      "Epoch: 7/40, Batch: 53/62, Discriminator loss: 0.6455814242362976, Generator loss: 0.36351048946380615\n",
      "Epoch: 7/40, Batch: 54/62, Discriminator loss: 0.6233351826667786, Generator loss: 0.38281333446502686\n",
      "Epoch: 7/40, Batch: 55/62, Discriminator loss: 0.6449056267738342, Generator loss: 0.3770695924758911\n",
      "Epoch: 7/40, Batch: 56/62, Discriminator loss: 0.5942679643630981, Generator loss: 0.4049634635448456\n",
      "Epoch: 7/40, Batch: 57/62, Discriminator loss: 0.5814045667648315, Generator loss: 0.38301560282707214\n",
      "Epoch: 7/40, Batch: 58/62, Discriminator loss: 0.6585951447486877, Generator loss: 0.38377583026885986\n",
      "Epoch: 7/40, Batch: 59/62, Discriminator loss: 0.5903224945068359, Generator loss: 0.39119040966033936\n",
      "Epoch: 7/40, Batch: 60/62, Discriminator loss: 0.6468830704689026, Generator loss: 0.39865878224372864\n",
      "Epoch: 7/40, Batch: 61/62, Discriminator loss: 0.6319599747657776, Generator loss: 0.3878936171531677\n",
      "Epoch: 7/40, Batch: 62/62, Discriminator loss: 0.5583410859107971, Generator loss: 0.3821507394313812\n",
      "Epoch: 8/40, Batch: 1/62, Discriminator loss: 0.5849997997283936, Generator loss: 0.3667536675930023\n",
      "Epoch: 8/40, Batch: 2/62, Discriminator loss: 0.5467027425765991, Generator loss: 0.3306814730167389\n",
      "Epoch: 8/40, Batch: 3/62, Discriminator loss: 0.479412704706192, Generator loss: 0.3004278242588043\n",
      "Epoch: 8/40, Batch: 4/62, Discriminator loss: 0.624873697757721, Generator loss: 0.2872414290904999\n",
      "Epoch: 8/40, Batch: 5/62, Discriminator loss: 0.6210050582885742, Generator loss: 0.3008058965206146\n",
      "Epoch: 8/40, Batch: 6/62, Discriminator loss: 0.598964273929596, Generator loss: 0.30259475111961365\n",
      "Epoch: 8/40, Batch: 7/62, Discriminator loss: 0.507681131362915, Generator loss: 0.31476619839668274\n",
      "Epoch: 8/40, Batch: 8/62, Discriminator loss: 0.45163410902023315, Generator loss: 0.3101968467235565\n",
      "Epoch: 8/40, Batch: 9/62, Discriminator loss: 0.5426996350288391, Generator loss: 0.33254677057266235\n",
      "Epoch: 8/40, Batch: 10/62, Discriminator loss: 0.48353493213653564, Generator loss: 0.3466314375400543\n",
      "Epoch: 8/40, Batch: 11/62, Discriminator loss: 0.5879346132278442, Generator loss: 0.3635743260383606\n",
      "Epoch: 8/40, Batch: 12/62, Discriminator loss: 0.3590833246707916, Generator loss: 0.34712520241737366\n",
      "Epoch: 8/40, Batch: 13/62, Discriminator loss: 0.530563235282898, Generator loss: 0.3552285432815552\n",
      "Epoch: 8/40, Batch: 14/62, Discriminator loss: 0.5220304131507874, Generator loss: 0.3874562084674835\n",
      "Epoch: 8/40, Batch: 15/62, Discriminator loss: 0.4724721312522888, Generator loss: 0.351471871137619\n",
      "Epoch: 8/40, Batch: 16/62, Discriminator loss: 0.44211798906326294, Generator loss: 0.33106422424316406\n",
      "Epoch: 8/40, Batch: 17/62, Discriminator loss: 0.5459360480308533, Generator loss: 0.3611033856868744\n",
      "Epoch: 8/40, Batch: 18/62, Discriminator loss: 0.552237868309021, Generator loss: 0.3925999104976654\n",
      "Epoch: 8/40, Batch: 19/62, Discriminator loss: 0.48847082257270813, Generator loss: 0.3756721317768097\n",
      "Epoch: 8/40, Batch: 20/62, Discriminator loss: 0.5379364490509033, Generator loss: 0.4357036054134369\n",
      "Epoch: 8/40, Batch: 21/62, Discriminator loss: 0.5346238613128662, Generator loss: 0.4834222197532654\n",
      "Epoch: 8/40, Batch: 22/62, Discriminator loss: 0.5287965536117554, Generator loss: 0.4691002368927002\n",
      "Epoch: 8/40, Batch: 23/62, Discriminator loss: 0.4914584755897522, Generator loss: 0.4900115132331848\n",
      "Epoch: 8/40, Batch: 24/62, Discriminator loss: 0.3999467194080353, Generator loss: 0.4051766097545624\n",
      "Epoch: 8/40, Batch: 25/62, Discriminator loss: 0.5988417267799377, Generator loss: 0.4313339591026306\n",
      "Epoch: 8/40, Batch: 26/62, Discriminator loss: 0.5389478206634521, Generator loss: 0.47910183668136597\n",
      "Epoch: 8/40, Batch: 27/62, Discriminator loss: 0.48895448446273804, Generator loss: 0.4786311686038971\n",
      "Epoch: 8/40, Batch: 28/62, Discriminator loss: 0.534465491771698, Generator loss: 0.51920086145401\n",
      "Epoch: 8/40, Batch: 29/62, Discriminator loss: 0.58043372631073, Generator loss: 0.4142787754535675\n",
      "Epoch: 8/40, Batch: 30/62, Discriminator loss: 0.5100424289703369, Generator loss: 0.32997697591781616\n",
      "Epoch: 8/40, Batch: 31/62, Discriminator loss: 0.5846648216247559, Generator loss: 0.3080099821090698\n",
      "Epoch: 8/40, Batch: 32/62, Discriminator loss: 0.5539523363113403, Generator loss: 0.28271958231925964\n",
      "Epoch: 8/40, Batch: 33/62, Discriminator loss: 0.4901747703552246, Generator loss: 0.24516290426254272\n",
      "Epoch: 8/40, Batch: 34/62, Discriminator loss: 0.6892346143722534, Generator loss: 0.2669021487236023\n",
      "Epoch: 8/40, Batch: 35/62, Discriminator loss: 0.5632662773132324, Generator loss: 0.245625838637352\n",
      "Epoch: 8/40, Batch: 36/62, Discriminator loss: 0.6349779963493347, Generator loss: 0.2529829144477844\n",
      "Epoch: 8/40, Batch: 37/62, Discriminator loss: 0.5316020250320435, Generator loss: 0.24456487596035004\n",
      "Epoch: 8/40, Batch: 38/62, Discriminator loss: 0.5170352458953857, Generator loss: 0.23365430533885956\n",
      "Epoch: 8/40, Batch: 39/62, Discriminator loss: 0.4850243628025055, Generator loss: 0.2137114405632019\n",
      "Epoch: 8/40, Batch: 40/62, Discriminator loss: 0.6864763498306274, Generator loss: 0.22780756652355194\n",
      "Epoch: 8/40, Batch: 41/62, Discriminator loss: 0.5510734915733337, Generator loss: 0.22919277846813202\n",
      "Epoch: 8/40, Batch: 42/62, Discriminator loss: 0.4042973518371582, Generator loss: 0.23041881620883942\n",
      "Epoch: 8/40, Batch: 43/62, Discriminator loss: 0.518531322479248, Generator loss: 0.2200947105884552\n",
      "Epoch: 8/40, Batch: 44/62, Discriminator loss: 0.37991440296173096, Generator loss: 0.21746453642845154\n",
      "Epoch: 8/40, Batch: 45/62, Discriminator loss: 0.5176181793212891, Generator loss: 0.2020195722579956\n",
      "Epoch: 8/40, Batch: 46/62, Discriminator loss: 0.5446768999099731, Generator loss: 0.21945245563983917\n",
      "Epoch: 8/40, Batch: 47/62, Discriminator loss: 0.4274832606315613, Generator loss: 0.21624331176280975\n",
      "Epoch: 8/40, Batch: 48/62, Discriminator loss: 0.6435655355453491, Generator loss: 0.24040311574935913\n",
      "Epoch: 8/40, Batch: 49/62, Discriminator loss: 0.36411675810813904, Generator loss: 0.22886116802692413\n",
      "Epoch: 8/40, Batch: 50/62, Discriminator loss: 0.49451780319213867, Generator loss: 0.24178700149059296\n",
      "Epoch: 8/40, Batch: 51/62, Discriminator loss: 0.5687453746795654, Generator loss: 0.25260162353515625\n",
      "Epoch: 8/40, Batch: 52/62, Discriminator loss: 0.46165719628334045, Generator loss: 0.2711420953273773\n",
      "Epoch: 8/40, Batch: 53/62, Discriminator loss: 0.585303544998169, Generator loss: 0.309016615152359\n",
      "Epoch: 8/40, Batch: 54/62, Discriminator loss: 0.5753750801086426, Generator loss: 0.32526132464408875\n",
      "Epoch: 8/40, Batch: 55/62, Discriminator loss: 0.634422779083252, Generator loss: 0.34358295798301697\n",
      "Epoch: 8/40, Batch: 56/62, Discriminator loss: 0.5841811299324036, Generator loss: 0.3675207197666168\n",
      "Epoch: 8/40, Batch: 57/62, Discriminator loss: 0.6276769638061523, Generator loss: 0.3767577111721039\n",
      "Epoch: 8/40, Batch: 58/62, Discriminator loss: 0.6581854820251465, Generator loss: 0.38876181840896606\n",
      "Epoch: 8/40, Batch: 59/62, Discriminator loss: 0.5907926559448242, Generator loss: 0.3883326053619385\n",
      "Epoch: 8/40, Batch: 60/62, Discriminator loss: 0.6661736369132996, Generator loss: 0.4340750575065613\n",
      "Epoch: 8/40, Batch: 61/62, Discriminator loss: 0.6897793412208557, Generator loss: 0.445745050907135\n",
      "Epoch: 8/40, Batch: 62/62, Discriminator loss: 0.5967383980751038, Generator loss: 0.4128503203392029\n",
      "Epoch: 9/40, Batch: 1/62, Discriminator loss: 0.5902755260467529, Generator loss: 0.3783438801765442\n",
      "Epoch: 9/40, Batch: 2/62, Discriminator loss: 0.6428120732307434, Generator loss: 0.36191850900650024\n",
      "Epoch: 9/40, Batch: 3/62, Discriminator loss: 0.4725560247898102, Generator loss: 0.31670039892196655\n",
      "Epoch: 9/40, Batch: 4/62, Discriminator loss: 0.618849515914917, Generator loss: 0.31506022810935974\n",
      "Epoch: 9/40, Batch: 5/62, Discriminator loss: 0.6004940271377563, Generator loss: 0.33015453815460205\n",
      "Epoch: 9/40, Batch: 6/62, Discriminator loss: 0.6471811532974243, Generator loss: 0.3359038531780243\n",
      "Epoch: 9/40, Batch: 7/62, Discriminator loss: 0.5451091527938843, Generator loss: 0.3522392809391022\n",
      "Epoch: 9/40, Batch: 8/62, Discriminator loss: 0.5378193855285645, Generator loss: 0.34061211347579956\n",
      "Epoch: 9/40, Batch: 9/62, Discriminator loss: 0.5468761920928955, Generator loss: 0.33414226770401\n",
      "Epoch: 9/40, Batch: 10/62, Discriminator loss: 0.5919142365455627, Generator loss: 0.34049689769744873\n",
      "Epoch: 9/40, Batch: 11/62, Discriminator loss: 0.6296145915985107, Generator loss: 0.3444463610649109\n",
      "Epoch: 9/40, Batch: 12/62, Discriminator loss: 0.4747644364833832, Generator loss: 0.3412071764469147\n",
      "Epoch: 9/40, Batch: 13/62, Discriminator loss: 0.5912177562713623, Generator loss: 0.3159886598587036\n",
      "Epoch: 9/40, Batch: 14/62, Discriminator loss: 0.5727951526641846, Generator loss: 0.3360026478767395\n",
      "Epoch: 9/40, Batch: 15/62, Discriminator loss: 0.5215106010437012, Generator loss: 0.29979121685028076\n",
      "Epoch: 9/40, Batch: 16/62, Discriminator loss: 0.4234551191329956, Generator loss: 0.28730136156082153\n",
      "Epoch: 9/40, Batch: 17/62, Discriminator loss: 0.5928520560264587, Generator loss: 0.28926387429237366\n",
      "Epoch: 9/40, Batch: 18/62, Discriminator loss: 0.5512653589248657, Generator loss: 0.27634575963020325\n",
      "Epoch: 9/40, Batch: 19/62, Discriminator loss: 0.5145889520645142, Generator loss: 0.3108377158641815\n",
      "Epoch: 9/40, Batch: 20/62, Discriminator loss: 0.5849730968475342, Generator loss: 0.31525689363479614\n",
      "Epoch: 9/40, Batch: 21/62, Discriminator loss: 0.5405735969543457, Generator loss: 0.301331102848053\n",
      "Epoch: 9/40, Batch: 22/62, Discriminator loss: 0.6069660186767578, Generator loss: 0.31402119994163513\n",
      "Epoch: 9/40, Batch: 23/62, Discriminator loss: 0.5384637713432312, Generator loss: 0.3132195770740509\n",
      "Epoch: 9/40, Batch: 24/62, Discriminator loss: 0.3973218500614166, Generator loss: 0.27712953090667725\n",
      "Epoch: 9/40, Batch: 25/62, Discriminator loss: 0.6692764759063721, Generator loss: 0.2687656581401825\n",
      "Epoch: 9/40, Batch: 26/62, Discriminator loss: 0.5652442574501038, Generator loss: 0.28841301798820496\n",
      "Epoch: 9/40, Batch: 27/62, Discriminator loss: 0.5370656847953796, Generator loss: 0.2937556207180023\n",
      "Epoch: 9/40, Batch: 28/62, Discriminator loss: 0.5952233672142029, Generator loss: 0.30739104747772217\n",
      "Epoch: 9/40, Batch: 29/62, Discriminator loss: 0.5233849287033081, Generator loss: 0.29928675293922424\n",
      "Epoch: 9/40, Batch: 30/62, Discriminator loss: 0.4511365294456482, Generator loss: 0.28062212467193604\n",
      "Epoch: 9/40, Batch: 31/62, Discriminator loss: 0.4666476249694824, Generator loss: 0.2672695517539978\n",
      "Epoch: 9/40, Batch: 32/62, Discriminator loss: 0.5022971630096436, Generator loss: 0.2637818157672882\n",
      "Epoch: 9/40, Batch: 33/62, Discriminator loss: 0.31866806745529175, Generator loss: 0.24345876276493073\n",
      "Epoch: 9/40, Batch: 34/62, Discriminator loss: 0.6063182950019836, Generator loss: 0.25562694668769836\n",
      "Epoch: 9/40, Batch: 35/62, Discriminator loss: 0.5155945420265198, Generator loss: 0.2524031400680542\n",
      "Epoch: 9/40, Batch: 36/62, Discriminator loss: 0.5793471336364746, Generator loss: 0.2704208195209503\n",
      "Epoch: 9/40, Batch: 37/62, Discriminator loss: 0.4706748425960541, Generator loss: 0.25787222385406494\n",
      "Epoch: 9/40, Batch: 38/62, Discriminator loss: 0.4532366693019867, Generator loss: 0.2632289230823517\n",
      "Epoch: 9/40, Batch: 39/62, Discriminator loss: 0.46185100078582764, Generator loss: 0.2516023814678192\n",
      "Epoch: 9/40, Batch: 40/62, Discriminator loss: 0.6170175075531006, Generator loss: 0.2677924931049347\n",
      "Epoch: 9/40, Batch: 41/62, Discriminator loss: 0.5247907638549805, Generator loss: 0.2621275782585144\n",
      "Epoch: 9/40, Batch: 42/62, Discriminator loss: 0.44779646396636963, Generator loss: 0.26208388805389404\n",
      "Epoch: 9/40, Batch: 43/62, Discriminator loss: 0.5167463421821594, Generator loss: 0.2602529227733612\n",
      "Epoch: 9/40, Batch: 44/62, Discriminator loss: 0.3939743638038635, Generator loss: 0.24817615747451782\n",
      "Epoch: 9/40, Batch: 45/62, Discriminator loss: 0.5559542775154114, Generator loss: 0.25712770223617554\n",
      "Epoch: 9/40, Batch: 46/62, Discriminator loss: 0.50657057762146, Generator loss: 0.25201737880706787\n",
      "Epoch: 9/40, Batch: 47/62, Discriminator loss: 0.4356573224067688, Generator loss: 0.25774917006492615\n",
      "Epoch: 9/40, Batch: 48/62, Discriminator loss: 0.5848888158798218, Generator loss: 0.27600497007369995\n",
      "Epoch: 9/40, Batch: 49/62, Discriminator loss: 0.423555850982666, Generator loss: 0.2652141749858856\n",
      "Epoch: 9/40, Batch: 50/62, Discriminator loss: 0.4658138155937195, Generator loss: 0.2745109498500824\n",
      "Epoch: 9/40, Batch: 51/62, Discriminator loss: 0.5818346738815308, Generator loss: 0.2663339376449585\n",
      "Epoch: 9/40, Batch: 52/62, Discriminator loss: 0.45632973313331604, Generator loss: 0.25184065103530884\n",
      "Epoch: 9/40, Batch: 53/62, Discriminator loss: 0.5759475231170654, Generator loss: 0.2581672966480255\n",
      "Epoch: 9/40, Batch: 54/62, Discriminator loss: 0.5008898973464966, Generator loss: 0.2650131583213806\n",
      "Epoch: 9/40, Batch: 55/62, Discriminator loss: 0.6060364246368408, Generator loss: 0.26351672410964966\n",
      "Epoch: 9/40, Batch: 56/62, Discriminator loss: 0.49882885813713074, Generator loss: 0.2746585011482239\n",
      "Epoch: 9/40, Batch: 57/62, Discriminator loss: 0.4900240898132324, Generator loss: 0.2670934200286865\n",
      "Epoch: 9/40, Batch: 58/62, Discriminator loss: 0.5875247716903687, Generator loss: 0.27773481607437134\n",
      "Epoch: 9/40, Batch: 59/62, Discriminator loss: 0.5431473255157471, Generator loss: 0.285394549369812\n",
      "Epoch: 9/40, Batch: 60/62, Discriminator loss: 0.6125451922416687, Generator loss: 0.3079424500465393\n",
      "Epoch: 9/40, Batch: 61/62, Discriminator loss: 0.5422816872596741, Generator loss: 0.30694180727005005\n",
      "Epoch: 9/40, Batch: 62/62, Discriminator loss: 0.41266578435897827, Generator loss: 0.29745200276374817\n",
      "Epoch: 10/40, Batch: 1/62, Discriminator loss: 0.48171746730804443, Generator loss: 0.2868175506591797\n",
      "Epoch: 10/40, Batch: 2/62, Discriminator loss: 0.5684181451797485, Generator loss: 0.27735739946365356\n",
      "Epoch: 10/40, Batch: 3/62, Discriminator loss: 0.4016309976577759, Generator loss: 0.24781076610088348\n",
      "Epoch: 10/40, Batch: 4/62, Discriminator loss: 0.5580967664718628, Generator loss: 0.23889178037643433\n",
      "Epoch: 10/40, Batch: 5/62, Discriminator loss: 0.6154454946517944, Generator loss: 0.24084125459194183\n",
      "Epoch: 10/40, Batch: 6/62, Discriminator loss: 0.604243814945221, Generator loss: 0.23107698559761047\n",
      "Epoch: 10/40, Batch: 7/62, Discriminator loss: 0.45533597469329834, Generator loss: 0.2120063751935959\n",
      "Epoch: 10/40, Batch: 8/62, Discriminator loss: 0.4514016807079315, Generator loss: 0.20989446341991425\n",
      "Epoch: 10/40, Batch: 9/62, Discriminator loss: 0.55422043800354, Generator loss: 0.213454470038414\n",
      "Epoch: 10/40, Batch: 10/62, Discriminator loss: 0.6153265237808228, Generator loss: 0.21824443340301514\n",
      "Epoch: 10/40, Batch: 11/62, Discriminator loss: 0.6244449615478516, Generator loss: 0.22637596726417542\n",
      "Epoch: 10/40, Batch: 12/62, Discriminator loss: 0.36873385310173035, Generator loss: 0.2162470817565918\n",
      "Epoch: 10/40, Batch: 13/62, Discriminator loss: 0.5948898792266846, Generator loss: 0.2056063413619995\n",
      "Epoch: 10/40, Batch: 14/62, Discriminator loss: 0.5562533140182495, Generator loss: 0.2034781128168106\n",
      "Epoch: 10/40, Batch: 15/62, Discriminator loss: 0.46672290563583374, Generator loss: 0.21029235422611237\n",
      "Epoch: 10/40, Batch: 16/62, Discriminator loss: 0.37995055317878723, Generator loss: 0.19781841337680817\n",
      "Epoch: 10/40, Batch: 17/62, Discriminator loss: 0.6441612243652344, Generator loss: 0.19602341949939728\n",
      "Epoch: 10/40, Batch: 18/62, Discriminator loss: 0.5796266198158264, Generator loss: 0.20138856768608093\n",
      "Epoch: 10/40, Batch: 19/62, Discriminator loss: 0.542591392993927, Generator loss: 0.19929324090480804\n",
      "Epoch: 10/40, Batch: 20/62, Discriminator loss: 0.6555638909339905, Generator loss: 0.21513985097408295\n",
      "Epoch: 10/40, Batch: 21/62, Discriminator loss: 0.5720573663711548, Generator loss: 0.21137884259223938\n",
      "Epoch: 10/40, Batch: 22/62, Discriminator loss: 0.6728951334953308, Generator loss: 0.24241860210895538\n",
      "Epoch: 10/40, Batch: 23/62, Discriminator loss: 0.5695031881332397, Generator loss: 0.2347823977470398\n",
      "Epoch: 10/40, Batch: 24/62, Discriminator loss: 0.45349156856536865, Generator loss: 0.2268076092004776\n",
      "Epoch: 10/40, Batch: 25/62, Discriminator loss: 0.7476944327354431, Generator loss: 0.2417936772108078\n",
      "Epoch: 10/40, Batch: 26/62, Discriminator loss: 0.5975279808044434, Generator loss: 0.26015782356262207\n",
      "Epoch: 10/40, Batch: 27/62, Discriminator loss: 0.5902552604675293, Generator loss: 0.26962289214134216\n",
      "Epoch: 10/40, Batch: 28/62, Discriminator loss: 0.6651626825332642, Generator loss: 0.28858789801597595\n",
      "Epoch: 10/40, Batch: 29/62, Discriminator loss: 0.6153411865234375, Generator loss: 0.29600265622138977\n",
      "Epoch: 10/40, Batch: 30/62, Discriminator loss: 0.484911173582077, Generator loss: 0.2937014102935791\n",
      "Epoch: 10/40, Batch: 31/62, Discriminator loss: 0.5507294535636902, Generator loss: 0.28850066661834717\n",
      "Epoch: 10/40, Batch: 32/62, Discriminator loss: 0.562546968460083, Generator loss: 0.27723589539527893\n",
      "Epoch: 10/40, Batch: 33/62, Discriminator loss: 0.47418394684791565, Generator loss: 0.2647360861301422\n",
      "Epoch: 10/40, Batch: 34/62, Discriminator loss: 0.6901478171348572, Generator loss: 0.26492807269096375\n",
      "Epoch: 10/40, Batch: 35/62, Discriminator loss: 0.5905628204345703, Generator loss: 0.2655923366546631\n",
      "Epoch: 10/40, Batch: 36/62, Discriminator loss: 0.6325660943984985, Generator loss: 0.2889695465564728\n",
      "Epoch: 10/40, Batch: 37/62, Discriminator loss: 0.5481280088424683, Generator loss: 0.2916843295097351\n",
      "Epoch: 10/40, Batch: 38/62, Discriminator loss: 0.5436127781867981, Generator loss: 0.2772603929042816\n",
      "Epoch: 10/40, Batch: 39/62, Discriminator loss: 0.49487537145614624, Generator loss: 0.27273449301719666\n",
      "Epoch: 10/40, Batch: 40/62, Discriminator loss: 0.6438320875167847, Generator loss: 0.2709626853466034\n",
      "Epoch: 10/40, Batch: 41/62, Discriminator loss: 0.5820413827896118, Generator loss: 0.2851974070072174\n",
      "Epoch: 10/40, Batch: 42/62, Discriminator loss: 0.49605417251586914, Generator loss: 0.28483882546424866\n",
      "Epoch: 10/40, Batch: 43/62, Discriminator loss: 0.5329843759536743, Generator loss: 0.2736748158931732\n",
      "Epoch: 10/40, Batch: 44/62, Discriminator loss: 0.4292607009410858, Generator loss: 0.28280553221702576\n",
      "Epoch: 10/40, Batch: 45/62, Discriminator loss: 0.5542231202125549, Generator loss: 0.2735178768634796\n",
      "Epoch: 10/40, Batch: 46/62, Discriminator loss: 0.5057581663131714, Generator loss: 0.2834246754646301\n",
      "Epoch: 10/40, Batch: 47/62, Discriminator loss: 0.4421461224555969, Generator loss: 0.2858161926269531\n",
      "Epoch: 10/40, Batch: 48/62, Discriminator loss: 0.5892609357833862, Generator loss: 0.3211086392402649\n",
      "Epoch: 10/40, Batch: 49/62, Discriminator loss: 0.4124109148979187, Generator loss: 0.31048718094825745\n",
      "Epoch: 10/40, Batch: 50/62, Discriminator loss: 0.45809611678123474, Generator loss: 0.3179704546928406\n",
      "Epoch: 10/40, Batch: 51/62, Discriminator loss: 0.46069854497909546, Generator loss: 0.3372991681098938\n",
      "Epoch: 10/40, Batch: 52/62, Discriminator loss: 0.42469197511672974, Generator loss: 0.3464924693107605\n",
      "Epoch: 10/40, Batch: 53/62, Discriminator loss: 0.5050770044326782, Generator loss: 0.3597998321056366\n",
      "Epoch: 10/40, Batch: 54/62, Discriminator loss: 0.4819481074810028, Generator loss: 0.400612473487854\n",
      "Epoch: 10/40, Batch: 55/62, Discriminator loss: 0.47275403141975403, Generator loss: 0.45505061745643616\n",
      "Epoch: 10/40, Batch: 56/62, Discriminator loss: 0.46992266178131104, Generator loss: 0.4770418107509613\n",
      "Epoch: 10/40, Batch: 57/62, Discriminator loss: 0.4630624055862427, Generator loss: 0.47510772943496704\n",
      "Epoch: 10/40, Batch: 58/62, Discriminator loss: 0.502458930015564, Generator loss: 0.5050486326217651\n",
      "Epoch: 10/40, Batch: 59/62, Discriminator loss: 0.46161097288131714, Generator loss: 0.5654621720314026\n",
      "Epoch: 10/40, Batch: 60/62, Discriminator loss: 0.5541169047355652, Generator loss: 0.5895159244537354\n",
      "Epoch: 10/40, Batch: 61/62, Discriminator loss: 0.49241071939468384, Generator loss: 0.5709580779075623\n",
      "Epoch: 10/40, Batch: 62/62, Discriminator loss: 0.47446492314338684, Generator loss: 0.5963718891143799\n",
      "Accuracy real: 25%, fake: 0%\n",
      "Epoch: 11/40, Batch: 1/62, Discriminator loss: 0.6243129372596741, Generator loss: 0.5463454723358154\n",
      "Epoch: 11/40, Batch: 2/62, Discriminator loss: 0.5340994596481323, Generator loss: 0.48809391260147095\n",
      "Epoch: 11/40, Batch: 3/62, Discriminator loss: 0.46914178133010864, Generator loss: 0.47715336084365845\n",
      "Epoch: 11/40, Batch: 4/62, Discriminator loss: 0.5898817777633667, Generator loss: 0.461101770401001\n",
      "Epoch: 11/40, Batch: 5/62, Discriminator loss: 0.5714040994644165, Generator loss: 0.44740086793899536\n",
      "Epoch: 11/40, Batch: 6/62, Discriminator loss: 0.530136227607727, Generator loss: 0.47967082262039185\n",
      "Epoch: 11/40, Batch: 7/62, Discriminator loss: 0.5097470879554749, Generator loss: 0.5217159986495972\n",
      "Epoch: 11/40, Batch: 8/62, Discriminator loss: 0.4779798686504364, Generator loss: 0.48213595151901245\n",
      "Epoch: 11/40, Batch: 9/62, Discriminator loss: 0.5470315217971802, Generator loss: 0.4663901925086975\n",
      "Epoch: 11/40, Batch: 10/62, Discriminator loss: 0.5131795406341553, Generator loss: 0.46378573775291443\n",
      "Epoch: 11/40, Batch: 11/62, Discriminator loss: 0.5119996666908264, Generator loss: 0.5248109102249146\n",
      "Epoch: 11/40, Batch: 12/62, Discriminator loss: 0.39528197050094604, Generator loss: 0.475671648979187\n",
      "Epoch: 11/40, Batch: 13/62, Discriminator loss: 0.4631819725036621, Generator loss: 0.44987982511520386\n",
      "Epoch: 11/40, Batch: 14/62, Discriminator loss: 0.4767128825187683, Generator loss: 0.45332810282707214\n",
      "Epoch: 11/40, Batch: 15/62, Discriminator loss: 0.4647270441055298, Generator loss: 0.4261750876903534\n",
      "Epoch: 11/40, Batch: 16/62, Discriminator loss: 0.4011690616607666, Generator loss: 0.40084266662597656\n",
      "Epoch: 11/40, Batch: 17/62, Discriminator loss: 0.49700960516929626, Generator loss: 0.4540764093399048\n",
      "Epoch: 11/40, Batch: 18/62, Discriminator loss: 0.4554428458213806, Generator loss: 0.45034947991371155\n",
      "Epoch: 11/40, Batch: 19/62, Discriminator loss: 0.47437769174575806, Generator loss: 0.4741777777671814\n",
      "Epoch: 11/40, Batch: 20/62, Discriminator loss: 0.5354173183441162, Generator loss: 0.4941185712814331\n",
      "Epoch: 11/40, Batch: 21/62, Discriminator loss: 0.4749130606651306, Generator loss: 0.45240262150764465\n",
      "Epoch: 11/40, Batch: 22/62, Discriminator loss: 0.49695897102355957, Generator loss: 0.4736425280570984\n",
      "Epoch: 11/40, Batch: 23/62, Discriminator loss: 0.4395935535430908, Generator loss: 0.4376632571220398\n",
      "Epoch: 11/40, Batch: 24/62, Discriminator loss: 0.35780149698257446, Generator loss: 0.3891720175743103\n",
      "Epoch: 11/40, Batch: 25/62, Discriminator loss: 0.5947501063346863, Generator loss: 0.3856322765350342\n",
      "Epoch: 11/40, Batch: 26/62, Discriminator loss: 0.46255016326904297, Generator loss: 0.39292606711387634\n",
      "Epoch: 11/40, Batch: 27/62, Discriminator loss: 0.4226970970630646, Generator loss: 0.3956645131111145\n",
      "Epoch: 11/40, Batch: 28/62, Discriminator loss: 0.5475583076477051, Generator loss: 0.3798293173313141\n",
      "Epoch: 11/40, Batch: 29/62, Discriminator loss: 0.49970579147338867, Generator loss: 0.3183896243572235\n",
      "Epoch: 11/40, Batch: 30/62, Discriminator loss: 0.47838976979255676, Generator loss: 0.2976614534854889\n",
      "Epoch: 11/40, Batch: 31/62, Discriminator loss: 0.5604132413864136, Generator loss: 0.24636349081993103\n",
      "Epoch: 11/40, Batch: 32/62, Discriminator loss: 0.620563268661499, Generator loss: 0.19779254496097565\n",
      "Epoch: 11/40, Batch: 33/62, Discriminator loss: 0.4917008578777313, Generator loss: 0.16871243715286255\n",
      "Epoch: 11/40, Batch: 34/62, Discriminator loss: 0.8169946670532227, Generator loss: 0.1673848181962967\n",
      "Epoch: 11/40, Batch: 35/62, Discriminator loss: 0.6220390796661377, Generator loss: 0.1527826189994812\n",
      "Epoch: 11/40, Batch: 36/62, Discriminator loss: 0.740058422088623, Generator loss: 0.1482936143875122\n",
      "Epoch: 11/40, Batch: 37/62, Discriminator loss: 0.6453486680984497, Generator loss: 0.1465422511100769\n",
      "Epoch: 11/40, Batch: 38/62, Discriminator loss: 0.5547819137573242, Generator loss: 0.14332588016986847\n",
      "Epoch: 11/40, Batch: 39/62, Discriminator loss: 0.5183792114257812, Generator loss: 0.142069011926651\n",
      "Epoch: 11/40, Batch: 40/62, Discriminator loss: 0.6852521300315857, Generator loss: 0.15089312195777893\n",
      "Epoch: 11/40, Batch: 41/62, Discriminator loss: 0.5021954774856567, Generator loss: 0.15638671815395355\n",
      "Epoch: 11/40, Batch: 42/62, Discriminator loss: 0.29996514320373535, Generator loss: 0.15384338796138763\n",
      "Epoch: 11/40, Batch: 43/62, Discriminator loss: 0.4674947261810303, Generator loss: 0.15602369606494904\n",
      "Epoch: 11/40, Batch: 44/62, Discriminator loss: 0.18586485087871552, Generator loss: 0.145712748169899\n",
      "Epoch: 11/40, Batch: 45/62, Discriminator loss: 0.45397353172302246, Generator loss: 0.14976057410240173\n",
      "Epoch: 11/40, Batch: 46/62, Discriminator loss: 0.3216880261898041, Generator loss: 0.14119215309619904\n",
      "Epoch: 11/40, Batch: 47/62, Discriminator loss: 0.2276352047920227, Generator loss: 0.13305160403251648\n",
      "Epoch: 11/40, Batch: 48/62, Discriminator loss: 0.5262131690979004, Generator loss: 0.1293170303106308\n",
      "Epoch: 11/40, Batch: 49/62, Discriminator loss: 0.10067951679229736, Generator loss: 0.11278339475393295\n",
      "Epoch: 11/40, Batch: 50/62, Discriminator loss: 0.2486230731010437, Generator loss: 0.1125016063451767\n",
      "Epoch: 11/40, Batch: 51/62, Discriminator loss: 0.42655014991760254, Generator loss: 0.10010950267314911\n",
      "Epoch: 11/40, Batch: 52/62, Discriminator loss: 0.3548390567302704, Generator loss: 0.09866701066493988\n",
      "Epoch: 11/40, Batch: 53/62, Discriminator loss: 0.5647627115249634, Generator loss: 0.09942719340324402\n",
      "Epoch: 11/40, Batch: 54/62, Discriminator loss: 0.4893939793109894, Generator loss: 0.10183054208755493\n",
      "Epoch: 11/40, Batch: 55/62, Discriminator loss: 0.595806896686554, Generator loss: 0.11262448877096176\n",
      "Epoch: 11/40, Batch: 56/62, Discriminator loss: 0.5381449460983276, Generator loss: 0.11707639694213867\n",
      "Epoch: 11/40, Batch: 57/62, Discriminator loss: 0.46564045548439026, Generator loss: 0.13303060829639435\n",
      "Epoch: 11/40, Batch: 58/62, Discriminator loss: 0.6217092871665955, Generator loss: 0.148800790309906\n",
      "Epoch: 11/40, Batch: 59/62, Discriminator loss: 0.6567784547805786, Generator loss: 0.17284072935581207\n",
      "Epoch: 11/40, Batch: 60/62, Discriminator loss: 0.683739185333252, Generator loss: 0.19500750303268433\n",
      "Epoch: 11/40, Batch: 61/62, Discriminator loss: 0.575532853603363, Generator loss: 0.24770000576972961\n",
      "Epoch: 11/40, Batch: 62/62, Discriminator loss: 0.4587051570415497, Generator loss: 0.2730866074562073\n",
      "Epoch: 12/40, Batch: 1/62, Discriminator loss: 0.5027697086334229, Generator loss: 0.28629881143569946\n",
      "Epoch: 12/40, Batch: 2/62, Discriminator loss: 0.5055774450302124, Generator loss: 0.32492342591285706\n",
      "Epoch: 12/40, Batch: 3/62, Discriminator loss: 0.3479383587837219, Generator loss: 0.29074960947036743\n",
      "Epoch: 12/40, Batch: 4/62, Discriminator loss: 0.5824708938598633, Generator loss: 0.3358924984931946\n",
      "Epoch: 12/40, Batch: 5/62, Discriminator loss: 0.5354008674621582, Generator loss: 0.3521755039691925\n",
      "Epoch: 12/40, Batch: 6/62, Discriminator loss: 0.5198846459388733, Generator loss: 0.3602069616317749\n",
      "Epoch: 12/40, Batch: 7/62, Discriminator loss: 0.43351301550865173, Generator loss: 0.3729371726512909\n",
      "Epoch: 12/40, Batch: 8/62, Discriminator loss: 0.46017906069755554, Generator loss: 0.3754954934120178\n",
      "Epoch: 12/40, Batch: 9/62, Discriminator loss: 0.5194385051727295, Generator loss: 0.4114117920398712\n",
      "Epoch: 12/40, Batch: 10/62, Discriminator loss: 0.5042357444763184, Generator loss: 0.3956074118614197\n",
      "Epoch: 12/40, Batch: 11/62, Discriminator loss: 0.5305712223052979, Generator loss: 0.4359634816646576\n",
      "Epoch: 12/40, Batch: 12/62, Discriminator loss: 0.38815051317214966, Generator loss: 0.3892447352409363\n",
      "Epoch: 12/40, Batch: 13/62, Discriminator loss: 0.5521348714828491, Generator loss: 0.38453224301338196\n",
      "Epoch: 12/40, Batch: 14/62, Discriminator loss: 0.48774072527885437, Generator loss: 0.3787662088871002\n",
      "Epoch: 12/40, Batch: 15/62, Discriminator loss: 0.49390730261802673, Generator loss: 0.3862449526786804\n",
      "Epoch: 12/40, Batch: 16/62, Discriminator loss: 0.42056354880332947, Generator loss: 0.33862200379371643\n",
      "Epoch: 12/40, Batch: 17/62, Discriminator loss: 0.5810036659240723, Generator loss: 0.3558456599712372\n",
      "Epoch: 12/40, Batch: 18/62, Discriminator loss: 0.5369089245796204, Generator loss: 0.35826191306114197\n",
      "Epoch: 12/40, Batch: 19/62, Discriminator loss: 0.5315514802932739, Generator loss: 0.35272088646888733\n",
      "Epoch: 12/40, Batch: 20/62, Discriminator loss: 0.6096320748329163, Generator loss: 0.3260686695575714\n",
      "Epoch: 12/40, Batch: 21/62, Discriminator loss: 0.6030917763710022, Generator loss: 0.34088334441185\n",
      "Epoch: 12/40, Batch: 22/62, Discriminator loss: 0.5891769528388977, Generator loss: 0.3422141671180725\n",
      "Epoch: 12/40, Batch: 23/62, Discriminator loss: 0.5666864514350891, Generator loss: 0.33616042137145996\n",
      "Epoch: 12/40, Batch: 24/62, Discriminator loss: 0.53682941198349, Generator loss: 0.29164597392082214\n",
      "Epoch: 12/40, Batch: 25/62, Discriminator loss: 0.7207192182540894, Generator loss: 0.31680402159690857\n",
      "Epoch: 12/40, Batch: 26/62, Discriminator loss: 0.6316496133804321, Generator loss: 0.3105665147304535\n",
      "Epoch: 12/40, Batch: 27/62, Discriminator loss: 0.6386217474937439, Generator loss: 0.3023499548435211\n",
      "Epoch: 12/40, Batch: 28/62, Discriminator loss: 0.7070239186286926, Generator loss: 0.29861676692962646\n",
      "Epoch: 12/40, Batch: 29/62, Discriminator loss: 0.6856993436813354, Generator loss: 0.28180861473083496\n",
      "Epoch: 12/40, Batch: 30/62, Discriminator loss: 0.6872947216033936, Generator loss: 0.2548999488353729\n",
      "Epoch: 12/40, Batch: 31/62, Discriminator loss: 0.6846481561660767, Generator loss: 0.24915607273578644\n",
      "Epoch: 12/40, Batch: 32/62, Discriminator loss: 0.7448207139968872, Generator loss: 0.23744641244411469\n",
      "Epoch: 12/40, Batch: 33/62, Discriminator loss: 0.5681225657463074, Generator loss: 0.21916936337947845\n",
      "Epoch: 12/40, Batch: 34/62, Discriminator loss: 0.8149643540382385, Generator loss: 0.2280072271823883\n",
      "Epoch: 12/40, Batch: 35/62, Discriminator loss: 0.6453448534011841, Generator loss: 0.22325696051120758\n",
      "Epoch: 12/40, Batch: 36/62, Discriminator loss: 0.7912829518318176, Generator loss: 0.2096148431301117\n",
      "Epoch: 12/40, Batch: 37/62, Discriminator loss: 0.6655950546264648, Generator loss: 0.21900694072246552\n",
      "Epoch: 12/40, Batch: 38/62, Discriminator loss: 0.6633453369140625, Generator loss: 0.22447143495082855\n",
      "Epoch: 12/40, Batch: 39/62, Discriminator loss: 0.6064828634262085, Generator loss: 0.207546204328537\n",
      "Epoch: 12/40, Batch: 40/62, Discriminator loss: 0.7876294255256653, Generator loss: 0.2166823446750641\n",
      "Epoch: 12/40, Batch: 41/62, Discriminator loss: 0.6921409368515015, Generator loss: 0.23132388293743134\n",
      "Epoch: 12/40, Batch: 42/62, Discriminator loss: 0.5458556413650513, Generator loss: 0.22450707852840424\n",
      "Epoch: 12/40, Batch: 43/62, Discriminator loss: 0.6293776035308838, Generator loss: 0.23465140163898468\n",
      "Epoch: 12/40, Batch: 44/62, Discriminator loss: 0.5355209112167358, Generator loss: 0.23352950811386108\n",
      "Epoch: 12/40, Batch: 45/62, Discriminator loss: 0.6708794236183167, Generator loss: 0.23637999594211578\n",
      "Epoch: 12/40, Batch: 46/62, Discriminator loss: 0.6110915541648865, Generator loss: 0.2497957944869995\n",
      "Epoch: 12/40, Batch: 47/62, Discriminator loss: 0.5584293007850647, Generator loss: 0.26291730999946594\n",
      "Epoch: 12/40, Batch: 48/62, Discriminator loss: 0.6487802863121033, Generator loss: 0.25336316227912903\n",
      "Epoch: 12/40, Batch: 49/62, Discriminator loss: 0.5096651315689087, Generator loss: 0.26933786273002625\n",
      "Epoch: 12/40, Batch: 50/62, Discriminator loss: 0.5265561938285828, Generator loss: 0.2975558638572693\n",
      "Epoch: 12/40, Batch: 51/62, Discriminator loss: 0.6096121072769165, Generator loss: 0.2646571695804596\n",
      "Epoch: 12/40, Batch: 52/62, Discriminator loss: 0.5054852366447449, Generator loss: 0.2852522134780884\n",
      "Epoch: 12/40, Batch: 53/62, Discriminator loss: 0.5632882118225098, Generator loss: 0.29742851853370667\n",
      "Epoch: 12/40, Batch: 54/62, Discriminator loss: 0.5413665175437927, Generator loss: 0.31085458397865295\n",
      "Epoch: 12/40, Batch: 55/62, Discriminator loss: 0.5419536232948303, Generator loss: 0.33412691950798035\n",
      "Epoch: 12/40, Batch: 56/62, Discriminator loss: 0.5576340556144714, Generator loss: 0.36493271589279175\n",
      "Epoch: 12/40, Batch: 57/62, Discriminator loss: 0.5055525898933411, Generator loss: 0.3859112560749054\n",
      "Epoch: 12/40, Batch: 58/62, Discriminator loss: 0.5652496814727783, Generator loss: 0.3890412747859955\n",
      "Epoch: 12/40, Batch: 59/62, Discriminator loss: 0.5783882141113281, Generator loss: 0.3957977890968323\n",
      "Epoch: 12/40, Batch: 60/62, Discriminator loss: 0.5690249800682068, Generator loss: 0.46101114153862\n",
      "Epoch: 12/40, Batch: 61/62, Discriminator loss: 0.5924293994903564, Generator loss: 0.4808180332183838\n",
      "Epoch: 12/40, Batch: 62/62, Discriminator loss: 0.5245234966278076, Generator loss: 0.5201547741889954\n",
      "Epoch: 13/40, Batch: 1/62, Discriminator loss: 0.5708625316619873, Generator loss: 0.4784335494041443\n",
      "Epoch: 13/40, Batch: 2/62, Discriminator loss: 0.567672610282898, Generator loss: 0.4717757999897003\n",
      "Epoch: 13/40, Batch: 3/62, Discriminator loss: 0.5126603841781616, Generator loss: 0.4576277434825897\n",
      "Epoch: 13/40, Batch: 4/62, Discriminator loss: 0.5891714096069336, Generator loss: 0.4387052655220032\n",
      "Epoch: 13/40, Batch: 5/62, Discriminator loss: 0.5516836643218994, Generator loss: 0.46255192160606384\n",
      "Epoch: 13/40, Batch: 6/62, Discriminator loss: 0.585385799407959, Generator loss: 0.5004376173019409\n",
      "Epoch: 13/40, Batch: 7/62, Discriminator loss: 0.5358206033706665, Generator loss: 0.5011335015296936\n",
      "Epoch: 13/40, Batch: 8/62, Discriminator loss: 0.5294181108474731, Generator loss: 0.47657355666160583\n",
      "Epoch: 13/40, Batch: 9/62, Discriminator loss: 0.5437032580375671, Generator loss: 0.5046554207801819\n",
      "Epoch: 13/40, Batch: 10/62, Discriminator loss: 0.5281886458396912, Generator loss: 0.5252417325973511\n",
      "Epoch: 13/40, Batch: 11/62, Discriminator loss: 0.5979228019714355, Generator loss: 0.51923668384552\n",
      "Epoch: 13/40, Batch: 12/62, Discriminator loss: 0.4573507308959961, Generator loss: 0.47536253929138184\n",
      "Epoch: 13/40, Batch: 13/62, Discriminator loss: 0.5308004021644592, Generator loss: 0.5045880079269409\n",
      "Epoch: 13/40, Batch: 14/62, Discriminator loss: 0.5606520175933838, Generator loss: 0.4698379933834076\n",
      "Epoch: 13/40, Batch: 15/62, Discriminator loss: 0.5360345840454102, Generator loss: 0.4462880790233612\n",
      "Epoch: 13/40, Batch: 16/62, Discriminator loss: 0.4627108871936798, Generator loss: 0.4082689881324768\n",
      "Epoch: 13/40, Batch: 17/62, Discriminator loss: 0.5789667367935181, Generator loss: 0.42371872067451477\n",
      "Epoch: 13/40, Batch: 18/62, Discriminator loss: 0.48395848274230957, Generator loss: 0.44697362184524536\n",
      "Epoch: 13/40, Batch: 19/62, Discriminator loss: 0.5222886800765991, Generator loss: 0.46241575479507446\n",
      "Epoch: 13/40, Batch: 20/62, Discriminator loss: 0.5523761510848999, Generator loss: 0.4611179828643799\n",
      "Epoch: 13/40, Batch: 21/62, Discriminator loss: 0.5379578471183777, Generator loss: 0.444475919008255\n",
      "Epoch: 13/40, Batch: 22/62, Discriminator loss: 0.5478957295417786, Generator loss: 0.4888571500778198\n",
      "Epoch: 13/40, Batch: 23/62, Discriminator loss: 0.5421768426895142, Generator loss: 0.5112550258636475\n",
      "Epoch: 13/40, Batch: 24/62, Discriminator loss: 0.4488546848297119, Generator loss: 0.4237194061279297\n",
      "Epoch: 13/40, Batch: 25/62, Discriminator loss: 0.6168794631958008, Generator loss: 0.46813368797302246\n",
      "Epoch: 13/40, Batch: 26/62, Discriminator loss: 0.5340640544891357, Generator loss: 0.4913918375968933\n",
      "Epoch: 13/40, Batch: 27/62, Discriminator loss: 0.5101263523101807, Generator loss: 0.4666108787059784\n",
      "Epoch: 13/40, Batch: 28/62, Discriminator loss: 0.5338685512542725, Generator loss: 0.48634016513824463\n",
      "Epoch: 13/40, Batch: 29/62, Discriminator loss: 0.4858837425708771, Generator loss: 0.49393025040626526\n",
      "Epoch: 13/40, Batch: 30/62, Discriminator loss: 0.4897922873497009, Generator loss: 0.4584711492061615\n",
      "Epoch: 13/40, Batch: 31/62, Discriminator loss: 0.4942948818206787, Generator loss: 0.41926464438438416\n",
      "Epoch: 13/40, Batch: 32/62, Discriminator loss: 0.502824068069458, Generator loss: 0.42270782589912415\n",
      "Epoch: 13/40, Batch: 33/62, Discriminator loss: 0.37030351161956787, Generator loss: 0.39256882667541504\n",
      "Epoch: 13/40, Batch: 34/62, Discriminator loss: 0.556177020072937, Generator loss: 0.4162141680717468\n",
      "Epoch: 13/40, Batch: 35/62, Discriminator loss: 0.3949163556098938, Generator loss: 0.4060256779193878\n",
      "Epoch: 13/40, Batch: 36/62, Discriminator loss: 0.5253204703330994, Generator loss: 0.39048221707344055\n",
      "Epoch: 13/40, Batch: 37/62, Discriminator loss: 0.45933377742767334, Generator loss: 0.4074420928955078\n",
      "Epoch: 13/40, Batch: 38/62, Discriminator loss: 0.42935261130332947, Generator loss: 0.3837240934371948\n",
      "Epoch: 13/40, Batch: 39/62, Discriminator loss: 0.5148814916610718, Generator loss: 0.3545817732810974\n",
      "Epoch: 13/40, Batch: 40/62, Discriminator loss: 0.6007766723632812, Generator loss: 0.3717898726463318\n",
      "Epoch: 13/40, Batch: 41/62, Discriminator loss: 0.5547705888748169, Generator loss: 0.37963932752609253\n",
      "Epoch: 13/40, Batch: 42/62, Discriminator loss: 0.47227856516838074, Generator loss: 0.337802916765213\n",
      "Epoch: 13/40, Batch: 43/62, Discriminator loss: 0.5678223371505737, Generator loss: 0.32954755425453186\n",
      "Epoch: 13/40, Batch: 44/62, Discriminator loss: 0.5164077281951904, Generator loss: 0.29739290475845337\n",
      "Epoch: 13/40, Batch: 45/62, Discriminator loss: 0.5815891623497009, Generator loss: 0.2857120931148529\n",
      "Epoch: 13/40, Batch: 46/62, Discriminator loss: 0.5882519483566284, Generator loss: 0.28246235847473145\n",
      "Epoch: 13/40, Batch: 47/62, Discriminator loss: 0.5182849168777466, Generator loss: 0.29431086778640747\n",
      "Epoch: 13/40, Batch: 48/62, Discriminator loss: 0.6590521335601807, Generator loss: 0.2884826064109802\n",
      "Epoch: 13/40, Batch: 49/62, Discriminator loss: 0.5462646484375, Generator loss: 0.2576555609703064\n",
      "Epoch: 13/40, Batch: 50/62, Discriminator loss: 0.5594046115875244, Generator loss: 0.24281354248523712\n",
      "Epoch: 13/40, Batch: 51/62, Discriminator loss: 0.6215438842773438, Generator loss: 0.2339247167110443\n",
      "Epoch: 13/40, Batch: 52/62, Discriminator loss: 0.45186638832092285, Generator loss: 0.21608571708202362\n",
      "Epoch: 13/40, Batch: 53/62, Discriminator loss: 0.5807254314422607, Generator loss: 0.2094748467206955\n",
      "Epoch: 13/40, Batch: 54/62, Discriminator loss: 0.5075925588607788, Generator loss: 0.20694871246814728\n",
      "Epoch: 13/40, Batch: 55/62, Discriminator loss: 0.5628055334091187, Generator loss: 0.1923549771308899\n",
      "Epoch: 13/40, Batch: 56/62, Discriminator loss: 0.5174540281295776, Generator loss: 0.18827638030052185\n",
      "Epoch: 13/40, Batch: 57/62, Discriminator loss: 0.4366745948791504, Generator loss: 0.18267342448234558\n",
      "Epoch: 13/40, Batch: 58/62, Discriminator loss: 0.5346465110778809, Generator loss: 0.1790810227394104\n",
      "Epoch: 13/40, Batch: 59/62, Discriminator loss: 0.5082905888557434, Generator loss: 0.18210318684577942\n",
      "Epoch: 13/40, Batch: 60/62, Discriminator loss: 0.5778343677520752, Generator loss: 0.19528672099113464\n",
      "Epoch: 13/40, Batch: 61/62, Discriminator loss: 0.452825665473938, Generator loss: 0.19946084916591644\n",
      "Epoch: 13/40, Batch: 62/62, Discriminator loss: 0.24151583015918732, Generator loss: 0.18391220271587372\n",
      "Epoch: 14/40, Batch: 1/62, Discriminator loss: 0.3376946449279785, Generator loss: 0.186907559633255\n",
      "Epoch: 14/40, Batch: 2/62, Discriminator loss: 0.35571300983428955, Generator loss: 0.18225666880607605\n",
      "Epoch: 14/40, Batch: 3/62, Discriminator loss: -0.013789340853691101, Generator loss: 0.16448533535003662\n",
      "Epoch: 14/40, Batch: 4/62, Discriminator loss: 0.40455520153045654, Generator loss: 0.15704657137393951\n",
      "Epoch: 14/40, Batch: 5/62, Discriminator loss: 0.4296550750732422, Generator loss: 0.15535660088062286\n",
      "Epoch: 14/40, Batch: 6/62, Discriminator loss: 0.3735199570655823, Generator loss: 0.17220506072044373\n",
      "Epoch: 14/40, Batch: 7/62, Discriminator loss: 0.30363425612449646, Generator loss: 0.15727370977401733\n",
      "Epoch: 14/40, Batch: 8/62, Discriminator loss: 0.20305851101875305, Generator loss: 0.15960828959941864\n",
      "Epoch: 14/40, Batch: 9/62, Discriminator loss: 0.43338584899902344, Generator loss: 0.17307592928409576\n",
      "Epoch: 14/40, Batch: 10/62, Discriminator loss: 0.41902440786361694, Generator loss: 0.1962469220161438\n",
      "Epoch: 14/40, Batch: 11/62, Discriminator loss: 0.5248713493347168, Generator loss: 0.2005721926689148\n",
      "Epoch: 14/40, Batch: 12/62, Discriminator loss: 0.276761531829834, Generator loss: 0.22176378965377808\n",
      "Epoch: 14/40, Batch: 13/62, Discriminator loss: 0.5228607654571533, Generator loss: 0.2248317301273346\n",
      "Epoch: 14/40, Batch: 14/62, Discriminator loss: 0.5027506351470947, Generator loss: 0.25803524255752563\n",
      "Epoch: 14/40, Batch: 15/62, Discriminator loss: 0.462166428565979, Generator loss: 0.25360381603240967\n",
      "Epoch: 14/40, Batch: 16/62, Discriminator loss: 0.37108755111694336, Generator loss: 0.27012574672698975\n",
      "Epoch: 14/40, Batch: 17/62, Discriminator loss: 0.6000064611434937, Generator loss: 0.29091402888298035\n",
      "Epoch: 14/40, Batch: 18/62, Discriminator loss: 0.5474838018417358, Generator loss: 0.31781917810440063\n",
      "Epoch: 14/40, Batch: 19/62, Discriminator loss: 0.5218865871429443, Generator loss: 0.3589424788951874\n",
      "Epoch: 14/40, Batch: 20/62, Discriminator loss: 0.5857699513435364, Generator loss: 0.40457165241241455\n",
      "Epoch: 14/40, Batch: 21/62, Discriminator loss: 0.5638207197189331, Generator loss: 0.39687642455101013\n",
      "Epoch: 14/40, Batch: 22/62, Discriminator loss: 0.6705915331840515, Generator loss: 0.4640827476978302\n",
      "Epoch: 14/40, Batch: 23/62, Discriminator loss: 0.6072481274604797, Generator loss: 0.4792215824127197\n",
      "Epoch: 14/40, Batch: 24/62, Discriminator loss: 0.49806416034698486, Generator loss: 0.44082051515579224\n",
      "Epoch: 14/40, Batch: 25/62, Discriminator loss: 0.6380360722541809, Generator loss: 0.4713726341724396\n",
      "Epoch: 14/40, Batch: 26/62, Discriminator loss: 0.5945754051208496, Generator loss: 0.47952812910079956\n",
      "Epoch: 14/40, Batch: 27/62, Discriminator loss: 0.5873845219612122, Generator loss: 0.5183415412902832\n",
      "Epoch: 14/40, Batch: 28/62, Discriminator loss: 0.6115171909332275, Generator loss: 0.535653293132782\n",
      "Epoch: 14/40, Batch: 29/62, Discriminator loss: 0.5723434090614319, Generator loss: 0.5406511425971985\n",
      "Epoch: 14/40, Batch: 30/62, Discriminator loss: 0.5579497814178467, Generator loss: 0.4899728298187256\n",
      "Epoch: 14/40, Batch: 31/62, Discriminator loss: 0.5541189312934875, Generator loss: 0.48701342940330505\n",
      "Epoch: 14/40, Batch: 32/62, Discriminator loss: 0.5967944860458374, Generator loss: 0.4451429545879364\n",
      "Epoch: 14/40, Batch: 33/62, Discriminator loss: 0.5049770474433899, Generator loss: 0.4318898618221283\n",
      "Epoch: 14/40, Batch: 34/62, Discriminator loss: 0.6616865992546082, Generator loss: 0.4894372522830963\n",
      "Epoch: 14/40, Batch: 35/62, Discriminator loss: 0.5958743095397949, Generator loss: 0.46100276708602905\n",
      "Epoch: 14/40, Batch: 36/62, Discriminator loss: 0.6166640520095825, Generator loss: 0.48791512846946716\n",
      "Epoch: 14/40, Batch: 37/62, Discriminator loss: 0.550527036190033, Generator loss: 0.5019864439964294\n",
      "Epoch: 14/40, Batch: 38/62, Discriminator loss: 0.5324869155883789, Generator loss: 0.5131280422210693\n",
      "Epoch: 14/40, Batch: 39/62, Discriminator loss: 0.5792325139045715, Generator loss: 0.448161780834198\n",
      "Epoch: 14/40, Batch: 40/62, Discriminator loss: 0.6181162595748901, Generator loss: 0.4478191137313843\n",
      "Epoch: 14/40, Batch: 41/62, Discriminator loss: 0.5929945707321167, Generator loss: 0.46066001057624817\n",
      "Epoch: 14/40, Batch: 42/62, Discriminator loss: 0.5610918998718262, Generator loss: 0.48426875472068787\n",
      "Epoch: 14/40, Batch: 43/62, Discriminator loss: 0.6091943979263306, Generator loss: 0.4252743124961853\n",
      "Epoch: 14/40, Batch: 44/62, Discriminator loss: 0.5613752603530884, Generator loss: 0.3690870404243469\n",
      "Epoch: 14/40, Batch: 45/62, Discriminator loss: 0.6266555786132812, Generator loss: 0.39118847250938416\n",
      "Epoch: 14/40, Batch: 46/62, Discriminator loss: 0.5833716988563538, Generator loss: 0.3748423755168915\n",
      "Epoch: 14/40, Batch: 47/62, Discriminator loss: 0.5537733435630798, Generator loss: 0.35014820098876953\n",
      "Epoch: 14/40, Batch: 48/62, Discriminator loss: 0.661618709564209, Generator loss: 0.3369878828525543\n",
      "Epoch: 14/40, Batch: 49/62, Discriminator loss: 0.6452292203903198, Generator loss: 0.30275338888168335\n",
      "Epoch: 14/40, Batch: 50/62, Discriminator loss: 0.6169925928115845, Generator loss: 0.2796216309070587\n",
      "Epoch: 14/40, Batch: 51/62, Discriminator loss: 0.70299232006073, Generator loss: 0.27210733294487\n",
      "Epoch: 14/40, Batch: 52/62, Discriminator loss: 0.6057027578353882, Generator loss: 0.2595965564250946\n",
      "Epoch: 14/40, Batch: 53/62, Discriminator loss: 0.6829073429107666, Generator loss: 0.25232186913490295\n",
      "Epoch: 14/40, Batch: 54/62, Discriminator loss: 0.6329578161239624, Generator loss: 0.24281784892082214\n",
      "Epoch: 14/40, Batch: 55/62, Discriminator loss: 0.6479854583740234, Generator loss: 0.24186217784881592\n",
      "Epoch: 14/40, Batch: 56/62, Discriminator loss: 0.5545555353164673, Generator loss: 0.23904095590114594\n",
      "Epoch: 14/40, Batch: 57/62, Discriminator loss: 0.5637142658233643, Generator loss: 0.23768369853496552\n",
      "Epoch: 14/40, Batch: 58/62, Discriminator loss: 0.6131929159164429, Generator loss: 0.23972877860069275\n",
      "Epoch: 14/40, Batch: 59/62, Discriminator loss: 0.5659724473953247, Generator loss: 0.23335620760917664\n",
      "Epoch: 14/40, Batch: 60/62, Discriminator loss: 0.6703316569328308, Generator loss: 0.24874967336654663\n",
      "Epoch: 14/40, Batch: 61/62, Discriminator loss: 0.5395150780677795, Generator loss: 0.24887509644031525\n",
      "Epoch: 14/40, Batch: 62/62, Discriminator loss: 0.4359370470046997, Generator loss: 0.2510325312614441\n",
      "Epoch: 15/40, Batch: 1/62, Discriminator loss: 0.48171696066856384, Generator loss: 0.2567068636417389\n",
      "Epoch: 15/40, Batch: 2/62, Discriminator loss: 0.5123704075813293, Generator loss: 0.2544798254966736\n",
      "Epoch: 15/40, Batch: 3/62, Discriminator loss: 0.24423514306545258, Generator loss: 0.2353050410747528\n",
      "Epoch: 15/40, Batch: 4/62, Discriminator loss: 0.5059643983840942, Generator loss: 0.23029904067516327\n",
      "Epoch: 15/40, Batch: 5/62, Discriminator loss: 0.5145717859268188, Generator loss: 0.22589828073978424\n",
      "Epoch: 15/40, Batch: 6/62, Discriminator loss: 0.48773542046546936, Generator loss: 0.23753251135349274\n",
      "Epoch: 15/40, Batch: 7/62, Discriminator loss: 0.42804524302482605, Generator loss: 0.24429070949554443\n",
      "Epoch: 15/40, Batch: 8/62, Discriminator loss: 0.3721218705177307, Generator loss: 0.2470911294221878\n",
      "Epoch: 15/40, Batch: 9/62, Discriminator loss: 0.4883459210395813, Generator loss: 0.2665973901748657\n",
      "Epoch: 15/40, Batch: 10/62, Discriminator loss: 0.4601542055606842, Generator loss: 0.2674809694290161\n",
      "Epoch: 15/40, Batch: 11/62, Discriminator loss: 0.5125234127044678, Generator loss: 0.2901446223258972\n",
      "Epoch: 15/40, Batch: 12/62, Discriminator loss: 0.29166853427886963, Generator loss: 0.2801610231399536\n",
      "Epoch: 15/40, Batch: 13/62, Discriminator loss: 0.4441201686859131, Generator loss: 0.3050520122051239\n",
      "Epoch: 15/40, Batch: 14/62, Discriminator loss: 0.4773522913455963, Generator loss: 0.31108322739601135\n",
      "Epoch: 15/40, Batch: 15/62, Discriminator loss: 0.397575318813324, Generator loss: 0.32694339752197266\n",
      "Epoch: 15/40, Batch: 16/62, Discriminator loss: 0.34492403268814087, Generator loss: 0.3378579020500183\n",
      "Epoch: 15/40, Batch: 17/62, Discriminator loss: 0.47371190786361694, Generator loss: 0.3497067093849182\n",
      "Epoch: 15/40, Batch: 18/62, Discriminator loss: 0.46309787034988403, Generator loss: 0.3632483184337616\n",
      "Epoch: 15/40, Batch: 19/62, Discriminator loss: 0.4723028838634491, Generator loss: 0.394951730966568\n",
      "Epoch: 15/40, Batch: 20/62, Discriminator loss: 0.5445518493652344, Generator loss: 0.4210939109325409\n",
      "Epoch: 15/40, Batch: 21/62, Discriminator loss: 0.4707174599170685, Generator loss: 0.4455932378768921\n",
      "Epoch: 15/40, Batch: 22/62, Discriminator loss: 0.5962870121002197, Generator loss: 0.4951219856739044\n",
      "Epoch: 15/40, Batch: 23/62, Discriminator loss: 0.5449602603912354, Generator loss: 0.4619472026824951\n",
      "Epoch: 15/40, Batch: 24/62, Discriminator loss: 0.4158705770969391, Generator loss: 0.4397147297859192\n",
      "Epoch: 15/40, Batch: 25/62, Discriminator loss: 0.6205301880836487, Generator loss: 0.4393389821052551\n",
      "Epoch: 15/40, Batch: 26/62, Discriminator loss: 0.5800434947013855, Generator loss: 0.46879568696022034\n",
      "Epoch: 15/40, Batch: 27/62, Discriminator loss: 0.5757445096969604, Generator loss: 0.4632585644721985\n",
      "Epoch: 15/40, Batch: 28/62, Discriminator loss: 0.5759212970733643, Generator loss: 0.45395979285240173\n",
      "Epoch: 15/40, Batch: 29/62, Discriminator loss: 0.5919440984725952, Generator loss: 0.4389439523220062\n",
      "Epoch: 15/40, Batch: 30/62, Discriminator loss: 0.5717846751213074, Generator loss: 0.40793153643608093\n",
      "Epoch: 15/40, Batch: 31/62, Discriminator loss: 0.6399219036102295, Generator loss: 0.3995908796787262\n",
      "Epoch: 15/40, Batch: 32/62, Discriminator loss: 0.600640058517456, Generator loss: 0.3523763120174408\n",
      "Epoch: 15/40, Batch: 33/62, Discriminator loss: 0.533237099647522, Generator loss: 0.34140291810035706\n",
      "Epoch: 15/40, Batch: 34/62, Discriminator loss: 0.6589410901069641, Generator loss: 0.3442082703113556\n",
      "Epoch: 15/40, Batch: 35/62, Discriminator loss: 0.5816062688827515, Generator loss: 0.36308175325393677\n",
      "Epoch: 15/40, Batch: 36/62, Discriminator loss: 0.665212094783783, Generator loss: 0.3572297990322113\n",
      "Epoch: 15/40, Batch: 37/62, Discriminator loss: 0.5678495168685913, Generator loss: 0.3664274513721466\n",
      "Epoch: 15/40, Batch: 38/62, Discriminator loss: 0.6114525198936462, Generator loss: 0.34256860613822937\n",
      "Epoch: 15/40, Batch: 39/62, Discriminator loss: 0.631348729133606, Generator loss: 0.3461432158946991\n",
      "Epoch: 15/40, Batch: 40/62, Discriminator loss: 0.6617989540100098, Generator loss: 0.37552884221076965\n",
      "Epoch: 15/40, Batch: 41/62, Discriminator loss: 0.6302040815353394, Generator loss: 0.3642030358314514\n",
      "Epoch: 15/40, Batch: 42/62, Discriminator loss: 0.5627424120903015, Generator loss: 0.34748175740242004\n",
      "Epoch: 15/40, Batch: 43/62, Discriminator loss: 0.5666656494140625, Generator loss: 0.3621068596839905\n",
      "Epoch: 15/40, Batch: 44/62, Discriminator loss: 0.5168774127960205, Generator loss: 0.3392956852912903\n",
      "Epoch: 15/40, Batch: 45/62, Discriminator loss: 0.6017431020736694, Generator loss: 0.3488340675830841\n",
      "Epoch: 15/40, Batch: 46/62, Discriminator loss: 0.5808141827583313, Generator loss: 0.3537012040615082\n",
      "Epoch: 15/40, Batch: 47/62, Discriminator loss: 0.49645718932151794, Generator loss: 0.34806978702545166\n",
      "Epoch: 15/40, Batch: 48/62, Discriminator loss: 0.6046587824821472, Generator loss: 0.3721672296524048\n",
      "Epoch: 15/40, Batch: 49/62, Discriminator loss: 0.5196828246116638, Generator loss: 0.32165026664733887\n",
      "Epoch: 15/40, Batch: 50/62, Discriminator loss: 0.5164309144020081, Generator loss: 0.32036128640174866\n",
      "Epoch: 15/40, Batch: 51/62, Discriminator loss: 0.5862019062042236, Generator loss: 0.318425714969635\n",
      "Epoch: 15/40, Batch: 52/62, Discriminator loss: 0.4329274892807007, Generator loss: 0.30738529562950134\n",
      "Epoch: 15/40, Batch: 53/62, Discriminator loss: 0.5527660250663757, Generator loss: 0.3297384977340698\n",
      "Epoch: 15/40, Batch: 54/62, Discriminator loss: 0.4541155993938446, Generator loss: 0.31604447960853577\n",
      "Epoch: 15/40, Batch: 55/62, Discriminator loss: 0.5033328533172607, Generator loss: 0.3182584047317505\n",
      "Epoch: 15/40, Batch: 56/62, Discriminator loss: 0.4752610921859741, Generator loss: 0.3091624677181244\n",
      "Epoch: 15/40, Batch: 57/62, Discriminator loss: 0.43613338470458984, Generator loss: 0.2973015010356903\n",
      "Epoch: 15/40, Batch: 58/62, Discriminator loss: 0.5294652581214905, Generator loss: 0.2924390137195587\n",
      "Epoch: 15/40, Batch: 59/62, Discriminator loss: 0.5011850595474243, Generator loss: 0.2815465033054352\n",
      "Epoch: 15/40, Batch: 60/62, Discriminator loss: 0.5577301979064941, Generator loss: 0.291568398475647\n",
      "Epoch: 15/40, Batch: 61/62, Discriminator loss: 0.49710676074028015, Generator loss: 0.29489806294441223\n",
      "Epoch: 15/40, Batch: 62/62, Discriminator loss: 0.4072524309158325, Generator loss: 0.27655699849128723\n",
      "Accuracy real: 25%, fake: 0%\n",
      "Epoch: 16/40, Batch: 1/62, Discriminator loss: 0.7601833343505859, Generator loss: 0.2709927260875702\n",
      "Epoch: 16/40, Batch: 2/62, Discriminator loss: 0.4495731592178345, Generator loss: 0.24710240960121155\n",
      "Epoch: 16/40, Batch: 3/62, Discriminator loss: 0.24730601906776428, Generator loss: 0.2254754602909088\n",
      "Epoch: 16/40, Batch: 4/62, Discriminator loss: 0.46149182319641113, Generator loss: 0.21350792050361633\n",
      "Epoch: 16/40, Batch: 5/62, Discriminator loss: 0.43518775701522827, Generator loss: 0.21864579617977142\n",
      "Epoch: 16/40, Batch: 6/62, Discriminator loss: 0.3919418454170227, Generator loss: 0.2115488052368164\n",
      "Epoch: 16/40, Batch: 7/62, Discriminator loss: 0.2628474235534668, Generator loss: 0.1938098967075348\n",
      "Epoch: 16/40, Batch: 8/62, Discriminator loss: 0.1445564478635788, Generator loss: 0.19210031628608704\n",
      "Epoch: 16/40, Batch: 9/62, Discriminator loss: 0.32635554671287537, Generator loss: 0.18879015743732452\n",
      "Epoch: 16/40, Batch: 10/62, Discriminator loss: 0.2497376650571823, Generator loss: 0.18987886607646942\n",
      "Epoch: 16/40, Batch: 11/62, Discriminator loss: 0.3096809387207031, Generator loss: 0.18313467502593994\n",
      "Epoch: 16/40, Batch: 12/62, Discriminator loss: -0.14577972888946533, Generator loss: 0.1680947095155716\n",
      "Epoch: 16/40, Batch: 13/62, Discriminator loss: 0.2057131677865982, Generator loss: 0.15511494874954224\n",
      "Epoch: 16/40, Batch: 14/62, Discriminator loss: 0.13260418176651, Generator loss: 0.14324113726615906\n",
      "Epoch: 16/40, Batch: 15/62, Discriminator loss: 0.004958420991897583, Generator loss: 0.12408673018217087\n",
      "Epoch: 16/40, Batch: 16/62, Discriminator loss: -0.20054841041564941, Generator loss: 0.10313087701797485\n",
      "Epoch: 16/40, Batch: 17/62, Discriminator loss: 0.46827536821365356, Generator loss: 0.09499016404151917\n",
      "Epoch: 16/40, Batch: 18/62, Discriminator loss: 0.31306618452072144, Generator loss: 0.09252125024795532\n",
      "Epoch: 16/40, Batch: 19/62, Discriminator loss: 0.2660486400127411, Generator loss: 0.08892371505498886\n",
      "Epoch: 16/40, Batch: 20/62, Discriminator loss: 0.5569466352462769, Generator loss: 0.10112065076828003\n",
      "Epoch: 16/40, Batch: 21/62, Discriminator loss: 0.4063887298107147, Generator loss: 0.11261504888534546\n",
      "Epoch: 16/40, Batch: 22/62, Discriminator loss: 0.6108078956604004, Generator loss: 0.1294390708208084\n",
      "Epoch: 16/40, Batch: 23/62, Discriminator loss: 0.5013951659202576, Generator loss: 0.16270320117473602\n",
      "Epoch: 16/40, Batch: 24/62, Discriminator loss: 0.1384272426366806, Generator loss: 0.1751018762588501\n",
      "Epoch: 16/40, Batch: 25/62, Discriminator loss: 0.6919121742248535, Generator loss: 0.21106064319610596\n",
      "Epoch: 16/40, Batch: 26/62, Discriminator loss: 0.4834108352661133, Generator loss: 0.27311527729034424\n",
      "Epoch: 16/40, Batch: 27/62, Discriminator loss: 0.4990910291671753, Generator loss: 0.3063032925128937\n",
      "Epoch: 16/40, Batch: 28/62, Discriminator loss: 0.5401188135147095, Generator loss: 0.36783674359321594\n",
      "Epoch: 16/40, Batch: 29/62, Discriminator loss: 0.49381422996520996, Generator loss: 0.3985351622104645\n",
      "Epoch: 16/40, Batch: 30/62, Discriminator loss: 0.42884230613708496, Generator loss: 0.3863995373249054\n",
      "Epoch: 16/40, Batch: 31/62, Discriminator loss: 0.45144444704055786, Generator loss: 0.3623429834842682\n",
      "Epoch: 16/40, Batch: 32/62, Discriminator loss: 0.6079663038253784, Generator loss: 0.33863022923469543\n",
      "Epoch: 16/40, Batch: 33/62, Discriminator loss: 0.4261769652366638, Generator loss: 0.30005398392677307\n",
      "Epoch: 16/40, Batch: 34/62, Discriminator loss: 0.7283874750137329, Generator loss: 0.2901075780391693\n",
      "Epoch: 16/40, Batch: 35/62, Discriminator loss: 0.6249309778213501, Generator loss: 0.2780363857746124\n",
      "Epoch: 16/40, Batch: 36/62, Discriminator loss: 0.7108711004257202, Generator loss: 0.30170729756355286\n",
      "Epoch: 16/40, Batch: 37/62, Discriminator loss: 0.6244553327560425, Generator loss: 0.31356722116470337\n",
      "Epoch: 16/40, Batch: 38/62, Discriminator loss: 0.6610767245292664, Generator loss: 0.2841300368309021\n",
      "Epoch: 16/40, Batch: 39/62, Discriminator loss: 0.5922681093215942, Generator loss: 0.2866825461387634\n",
      "Epoch: 16/40, Batch: 40/62, Discriminator loss: 0.7126533389091492, Generator loss: 0.3033771216869354\n",
      "Epoch: 16/40, Batch: 41/62, Discriminator loss: 0.6408964991569519, Generator loss: 0.31637439131736755\n",
      "Epoch: 16/40, Batch: 42/62, Discriminator loss: 0.5753891468048096, Generator loss: 0.3285389244556427\n",
      "Epoch: 16/40, Batch: 43/62, Discriminator loss: 0.6327387094497681, Generator loss: 0.31152164936065674\n",
      "Epoch: 16/40, Batch: 44/62, Discriminator loss: 0.5733562707901001, Generator loss: 0.3110552430152893\n",
      "Epoch: 16/40, Batch: 45/62, Discriminator loss: 0.6506651639938354, Generator loss: 0.3262501358985901\n",
      "Epoch: 16/40, Batch: 46/62, Discriminator loss: 0.6325933337211609, Generator loss: 0.33020082116127014\n",
      "Epoch: 16/40, Batch: 47/62, Discriminator loss: 0.5833922624588013, Generator loss: 0.32143405079841614\n",
      "Epoch: 16/40, Batch: 48/62, Discriminator loss: 0.6533527374267578, Generator loss: 0.3274235129356384\n",
      "Epoch: 16/40, Batch: 49/62, Discriminator loss: 0.5604114532470703, Generator loss: 0.32462602853775024\n",
      "Epoch: 16/40, Batch: 50/62, Discriminator loss: 0.63425612449646, Generator loss: 0.3178994059562683\n",
      "Epoch: 16/40, Batch: 51/62, Discriminator loss: 0.696428656578064, Generator loss: 0.30207356810569763\n",
      "Epoch: 16/40, Batch: 52/62, Discriminator loss: 0.5860694646835327, Generator loss: 0.29720908403396606\n",
      "Epoch: 16/40, Batch: 53/62, Discriminator loss: 0.6104845404624939, Generator loss: 0.29391083121299744\n",
      "Epoch: 16/40, Batch: 54/62, Discriminator loss: 0.614846408367157, Generator loss: 0.29316407442092896\n",
      "Epoch: 16/40, Batch: 55/62, Discriminator loss: 0.6632406711578369, Generator loss: 0.29371005296707153\n",
      "Epoch: 16/40, Batch: 56/62, Discriminator loss: 0.6120153665542603, Generator loss: 0.29764798283576965\n",
      "Epoch: 16/40, Batch: 57/62, Discriminator loss: 0.5993962287902832, Generator loss: 0.2779005169868469\n",
      "Epoch: 16/40, Batch: 58/62, Discriminator loss: 0.6511785387992859, Generator loss: 0.2791939973831177\n",
      "Epoch: 16/40, Batch: 59/62, Discriminator loss: 0.6215091943740845, Generator loss: 0.2862432599067688\n",
      "Epoch: 16/40, Batch: 60/62, Discriminator loss: 0.6464349031448364, Generator loss: 0.30296939611434937\n",
      "Epoch: 16/40, Batch: 61/62, Discriminator loss: 0.6093704104423523, Generator loss: 0.3212762773036957\n",
      "Epoch: 16/40, Batch: 62/62, Discriminator loss: 0.5081378221511841, Generator loss: 0.30564719438552856\n",
      "Epoch: 17/40, Batch: 1/62, Discriminator loss: 0.5541089773178101, Generator loss: 0.29972782731056213\n",
      "Epoch: 17/40, Batch: 2/62, Discriminator loss: 0.5912879705429077, Generator loss: 0.28612813353538513\n",
      "Epoch: 17/40, Batch: 3/62, Discriminator loss: 0.3649635910987854, Generator loss: 0.24926981329917908\n",
      "Epoch: 17/40, Batch: 4/62, Discriminator loss: 0.5921081900596619, Generator loss: 0.26302212476730347\n",
      "Epoch: 17/40, Batch: 5/62, Discriminator loss: 0.5489271879196167, Generator loss: 0.26739412546157837\n",
      "Epoch: 17/40, Batch: 6/62, Discriminator loss: 0.44555312395095825, Generator loss: 0.25688737630844116\n",
      "Epoch: 17/40, Batch: 7/62, Discriminator loss: 0.4668424129486084, Generator loss: 0.26444509625434875\n",
      "Epoch: 17/40, Batch: 8/62, Discriminator loss: 0.34542152285575867, Generator loss: 0.25277793407440186\n",
      "Epoch: 17/40, Batch: 9/62, Discriminator loss: 0.49808192253112793, Generator loss: 0.25879988074302673\n",
      "Epoch: 17/40, Batch: 10/62, Discriminator loss: 0.4527948200702667, Generator loss: 0.27531397342681885\n",
      "Epoch: 17/40, Batch: 11/62, Discriminator loss: 0.48865628242492676, Generator loss: 0.2779536843299866\n",
      "Epoch: 17/40, Batch: 12/62, Discriminator loss: 0.30223286151885986, Generator loss: 0.2905997335910797\n",
      "Epoch: 17/40, Batch: 13/62, Discriminator loss: 0.4053504765033722, Generator loss: 0.2796439528465271\n",
      "Epoch: 17/40, Batch: 14/62, Discriminator loss: 0.45339706540107727, Generator loss: 0.29036417603492737\n",
      "Epoch: 17/40, Batch: 15/62, Discriminator loss: 0.3357876241207123, Generator loss: 0.27224478125572205\n",
      "Epoch: 17/40, Batch: 16/62, Discriminator loss: 0.302434504032135, Generator loss: 0.25743868947029114\n",
      "Epoch: 17/40, Batch: 17/62, Discriminator loss: 0.5447452068328857, Generator loss: 0.292279988527298\n",
      "Epoch: 17/40, Batch: 18/62, Discriminator loss: 0.4652984142303467, Generator loss: 0.3514920473098755\n",
      "Epoch: 17/40, Batch: 19/62, Discriminator loss: 0.48036205768585205, Generator loss: 0.3520066738128662\n",
      "Epoch: 17/40, Batch: 20/62, Discriminator loss: 0.5908037424087524, Generator loss: 0.36653438210487366\n",
      "Epoch: 17/40, Batch: 21/62, Discriminator loss: 0.49412134289741516, Generator loss: 0.3558894991874695\n",
      "Epoch: 17/40, Batch: 22/62, Discriminator loss: 0.6854095458984375, Generator loss: 0.4111397862434387\n",
      "Epoch: 17/40, Batch: 23/62, Discriminator loss: 0.5979350805282593, Generator loss: 0.4362807869911194\n",
      "Epoch: 17/40, Batch: 24/62, Discriminator loss: 0.5491464138031006, Generator loss: 0.3841439187526703\n",
      "Epoch: 17/40, Batch: 25/62, Discriminator loss: 0.7375138998031616, Generator loss: 0.3494265675544739\n",
      "Epoch: 17/40, Batch: 26/62, Discriminator loss: 0.7592759132385254, Generator loss: 0.4449913799762726\n",
      "Epoch: 17/40, Batch: 27/62, Discriminator loss: 0.6429681777954102, Generator loss: 0.45533260703086853\n",
      "Epoch: 17/40, Batch: 28/62, Discriminator loss: 0.7215437889099121, Generator loss: 0.4473348557949066\n",
      "Epoch: 17/40, Batch: 29/62, Discriminator loss: 0.6866853833198547, Generator loss: 0.45963937044143677\n",
      "Epoch: 17/40, Batch: 30/62, Discriminator loss: 0.7768335938453674, Generator loss: 0.4612569510936737\n",
      "Epoch: 17/40, Batch: 31/62, Discriminator loss: 0.837261438369751, Generator loss: 0.39635536074638367\n",
      "Epoch: 17/40, Batch: 32/62, Discriminator loss: 0.6997402906417847, Generator loss: 0.3914705514907837\n",
      "Epoch: 17/40, Batch: 33/62, Discriminator loss: 0.6685914993286133, Generator loss: 0.3570145070552826\n",
      "Epoch: 17/40, Batch: 34/62, Discriminator loss: 0.7440482378005981, Generator loss: 0.38089802861213684\n",
      "Epoch: 17/40, Batch: 35/62, Discriminator loss: 0.640947699546814, Generator loss: 0.4052027761936188\n",
      "Epoch: 17/40, Batch: 36/62, Discriminator loss: 0.6970177888870239, Generator loss: 0.4188184440135956\n",
      "Epoch: 17/40, Batch: 37/62, Discriminator loss: 0.680216372013092, Generator loss: 0.4645468294620514\n",
      "Epoch: 17/40, Batch: 38/62, Discriminator loss: 0.6657789945602417, Generator loss: 0.4532676935195923\n",
      "Epoch: 17/40, Batch: 39/62, Discriminator loss: 0.6630285978317261, Generator loss: 0.46719881892204285\n",
      "Epoch: 17/40, Batch: 40/62, Discriminator loss: 0.7052661180496216, Generator loss: 0.4373452663421631\n",
      "Epoch: 17/40, Batch: 41/62, Discriminator loss: 0.6309889554977417, Generator loss: 0.4531465172767639\n",
      "Epoch: 17/40, Batch: 42/62, Discriminator loss: 0.597800076007843, Generator loss: 0.4419356882572174\n",
      "Epoch: 17/40, Batch: 43/62, Discriminator loss: 0.6215157508850098, Generator loss: 0.43568482995033264\n",
      "Epoch: 17/40, Batch: 44/62, Discriminator loss: 0.559673547744751, Generator loss: 0.40637993812561035\n",
      "Epoch: 17/40, Batch: 45/62, Discriminator loss: 0.6059415936470032, Generator loss: 0.42516204714775085\n",
      "Epoch: 17/40, Batch: 46/62, Discriminator loss: 0.5628930330276489, Generator loss: 0.4454384744167328\n",
      "Epoch: 17/40, Batch: 47/62, Discriminator loss: 0.5529001355171204, Generator loss: 0.4267136752605438\n",
      "Epoch: 17/40, Batch: 48/62, Discriminator loss: 0.5959358811378479, Generator loss: 0.4562719464302063\n",
      "Epoch: 17/40, Batch: 49/62, Discriminator loss: 0.5641394853591919, Generator loss: 0.4141963720321655\n",
      "Epoch: 17/40, Batch: 50/62, Discriminator loss: 0.5095693469047546, Generator loss: 0.3989937901496887\n",
      "Epoch: 17/40, Batch: 51/62, Discriminator loss: 0.5555076599121094, Generator loss: 0.3726871907711029\n",
      "Epoch: 17/40, Batch: 52/62, Discriminator loss: 0.4722291827201843, Generator loss: 0.3660125732421875\n",
      "Epoch: 17/40, Batch: 53/62, Discriminator loss: 0.5979169011116028, Generator loss: 0.3749200701713562\n",
      "Epoch: 17/40, Batch: 54/62, Discriminator loss: 0.5047568678855896, Generator loss: 0.3805442750453949\n",
      "Epoch: 17/40, Batch: 55/62, Discriminator loss: 0.541702389717102, Generator loss: 0.3952951431274414\n",
      "Epoch: 17/40, Batch: 56/62, Discriminator loss: 0.4498446583747864, Generator loss: 0.4106130301952362\n",
      "Epoch: 17/40, Batch: 57/62, Discriminator loss: 0.4216140806674957, Generator loss: 0.38998356461524963\n",
      "Epoch: 17/40, Batch: 58/62, Discriminator loss: 0.5094867944717407, Generator loss: 0.3682873845100403\n",
      "Epoch: 17/40, Batch: 59/62, Discriminator loss: 0.4423970580101013, Generator loss: 0.3841201364994049\n",
      "Epoch: 17/40, Batch: 60/62, Discriminator loss: 0.5024199485778809, Generator loss: 0.4008044898509979\n",
      "Epoch: 17/40, Batch: 61/62, Discriminator loss: 0.46576106548309326, Generator loss: 0.39692917466163635\n",
      "Epoch: 17/40, Batch: 62/62, Discriminator loss: 0.39549922943115234, Generator loss: 0.36585041880607605\n",
      "Epoch: 18/40, Batch: 1/62, Discriminator loss: 0.395257830619812, Generator loss: 0.35023123025894165\n",
      "Epoch: 18/40, Batch: 2/62, Discriminator loss: 0.4263766407966614, Generator loss: 0.3130377233028412\n",
      "Epoch: 18/40, Batch: 3/62, Discriminator loss: 0.29584309458732605, Generator loss: 0.2514292597770691\n",
      "Epoch: 18/40, Batch: 4/62, Discriminator loss: 0.527849555015564, Generator loss: 0.24205555021762848\n",
      "Epoch: 18/40, Batch: 5/62, Discriminator loss: 0.5372053384780884, Generator loss: 0.23330271244049072\n",
      "Epoch: 18/40, Batch: 6/62, Discriminator loss: 0.5382310152053833, Generator loss: 0.23852987587451935\n",
      "Epoch: 18/40, Batch: 7/62, Discriminator loss: 0.3726956248283386, Generator loss: 0.2382613718509674\n",
      "Epoch: 18/40, Batch: 8/62, Discriminator loss: 0.33931490778923035, Generator loss: 0.22810398042201996\n",
      "Epoch: 18/40, Batch: 9/62, Discriminator loss: 0.41810187697410583, Generator loss: 0.21696865558624268\n",
      "Epoch: 18/40, Batch: 10/62, Discriminator loss: 0.36134839057922363, Generator loss: 0.22036021947860718\n",
      "Epoch: 18/40, Batch: 11/62, Discriminator loss: 0.4308927059173584, Generator loss: 0.22827067971229553\n",
      "Epoch: 18/40, Batch: 12/62, Discriminator loss: 0.03811180591583252, Generator loss: 0.21933606266975403\n",
      "Epoch: 18/40, Batch: 13/62, Discriminator loss: 0.3381309509277344, Generator loss: 0.20466426014900208\n",
      "Epoch: 18/40, Batch: 14/62, Discriminator loss: 0.22558163106441498, Generator loss: 0.1971246302127838\n",
      "Epoch: 18/40, Batch: 15/62, Discriminator loss: 0.09401729702949524, Generator loss: 0.18393129110336304\n",
      "Epoch: 18/40, Batch: 16/62, Discriminator loss: -0.14209310710430145, Generator loss: 0.1593954712152481\n",
      "Epoch: 18/40, Batch: 17/62, Discriminator loss: 0.36438900232315063, Generator loss: 0.1409468799829483\n",
      "Epoch: 18/40, Batch: 18/62, Discriminator loss: 0.22834613919258118, Generator loss: 0.12547048926353455\n",
      "Epoch: 18/40, Batch: 19/62, Discriminator loss: 0.18256983160972595, Generator loss: 0.10955019295215607\n",
      "Epoch: 18/40, Batch: 20/62, Discriminator loss: 0.4865400791168213, Generator loss: 0.10232096910476685\n",
      "Epoch: 18/40, Batch: 21/62, Discriminator loss: 0.4037856161594391, Generator loss: 0.10720008611679077\n",
      "Epoch: 18/40, Batch: 22/62, Discriminator loss: 0.5989713668823242, Generator loss: 0.1140795424580574\n",
      "Epoch: 18/40, Batch: 23/62, Discriminator loss: 0.5113856792449951, Generator loss: 0.1334451287984848\n",
      "Epoch: 18/40, Batch: 24/62, Discriminator loss: 0.1733648180961609, Generator loss: 0.1454664021730423\n",
      "Epoch: 18/40, Batch: 25/62, Discriminator loss: 0.7056397199630737, Generator loss: 0.18876618146896362\n",
      "Epoch: 18/40, Batch: 26/62, Discriminator loss: 0.5174456238746643, Generator loss: 0.24195636808872223\n",
      "Epoch: 18/40, Batch: 27/62, Discriminator loss: 0.5540274381637573, Generator loss: 0.3242027461528778\n",
      "Epoch: 18/40, Batch: 28/62, Discriminator loss: 0.5278072953224182, Generator loss: 0.386546790599823\n",
      "Epoch: 18/40, Batch: 29/62, Discriminator loss: 0.49563995003700256, Generator loss: 0.44564419984817505\n",
      "Epoch: 18/40, Batch: 30/62, Discriminator loss: 0.3836439251899719, Generator loss: 0.4558166265487671\n",
      "Epoch: 18/40, Batch: 31/62, Discriminator loss: 0.40612486004829407, Generator loss: 0.4142801761627197\n",
      "Epoch: 18/40, Batch: 32/62, Discriminator loss: 0.5556561946868896, Generator loss: 0.37913405895233154\n",
      "Epoch: 18/40, Batch: 33/62, Discriminator loss: 0.42324337363243103, Generator loss: 0.3210527300834656\n",
      "Epoch: 18/40, Batch: 34/62, Discriminator loss: 0.7481700778007507, Generator loss: 0.32607176899909973\n",
      "Epoch: 18/40, Batch: 35/62, Discriminator loss: 0.6539187431335449, Generator loss: 0.31611359119415283\n",
      "Epoch: 18/40, Batch: 36/62, Discriminator loss: 0.7157571911811829, Generator loss: 0.3580890893936157\n",
      "Epoch: 18/40, Batch: 37/62, Discriminator loss: 0.6920095682144165, Generator loss: 0.3526485860347748\n",
      "Epoch: 18/40, Batch: 38/62, Discriminator loss: 0.6821933388710022, Generator loss: 0.3514566123485565\n",
      "Epoch: 18/40, Batch: 39/62, Discriminator loss: 0.6791982650756836, Generator loss: 0.33076778054237366\n",
      "Epoch: 18/40, Batch: 40/62, Discriminator loss: 0.8152279257774353, Generator loss: 0.3288322687149048\n",
      "Epoch: 18/40, Batch: 41/62, Discriminator loss: 0.7607948184013367, Generator loss: 0.32576796412467957\n",
      "Epoch: 18/40, Batch: 42/62, Discriminator loss: 0.7050985097885132, Generator loss: 0.3207107484340668\n",
      "Epoch: 18/40, Batch: 43/62, Discriminator loss: 0.7323669791221619, Generator loss: 0.3371764123439789\n",
      "Epoch: 18/40, Batch: 44/62, Discriminator loss: 0.7119766473770142, Generator loss: 0.32076090574264526\n",
      "Epoch: 18/40, Batch: 45/62, Discriminator loss: 0.7400718927383423, Generator loss: 0.29164159297943115\n",
      "Epoch: 18/40, Batch: 46/62, Discriminator loss: 0.7259216904640198, Generator loss: 0.310075044631958\n",
      "Epoch: 18/40, Batch: 47/62, Discriminator loss: 0.6772270202636719, Generator loss: 0.3258705735206604\n",
      "Epoch: 18/40, Batch: 48/62, Discriminator loss: 0.7672042846679688, Generator loss: 0.3278537392616272\n",
      "Epoch: 18/40, Batch: 49/62, Discriminator loss: 0.679588794708252, Generator loss: 0.3247825801372528\n",
      "Epoch: 18/40, Batch: 50/62, Discriminator loss: 0.6515180468559265, Generator loss: 0.2941479980945587\n",
      "Epoch: 18/40, Batch: 51/62, Discriminator loss: 0.7251152992248535, Generator loss: 0.2958473265171051\n",
      "Epoch: 18/40, Batch: 52/62, Discriminator loss: 0.6958578824996948, Generator loss: 0.29606887698173523\n",
      "Epoch: 18/40, Batch: 53/62, Discriminator loss: 0.7362949848175049, Generator loss: 0.3323363661766052\n",
      "Epoch: 18/40, Batch: 54/62, Discriminator loss: 0.7097417712211609, Generator loss: 0.3355673551559448\n",
      "Epoch: 18/40, Batch: 55/62, Discriminator loss: 0.7111067771911621, Generator loss: 0.35536712408065796\n",
      "Epoch: 18/40, Batch: 56/62, Discriminator loss: 0.6505022048950195, Generator loss: 0.34428536891937256\n",
      "Epoch: 18/40, Batch: 57/62, Discriminator loss: 0.6201767325401306, Generator loss: 0.3691996932029724\n",
      "Epoch: 18/40, Batch: 58/62, Discriminator loss: 0.6435244083404541, Generator loss: 0.38365429639816284\n",
      "Epoch: 18/40, Batch: 59/62, Discriminator loss: 0.6072033643722534, Generator loss: 0.42212799191474915\n",
      "Epoch: 18/40, Batch: 60/62, Discriminator loss: 0.6105261445045471, Generator loss: 0.4531306028366089\n",
      "Epoch: 18/40, Batch: 61/62, Discriminator loss: 0.5979833006858826, Generator loss: 0.45734140276908875\n",
      "Epoch: 18/40, Batch: 62/62, Discriminator loss: 0.5522328615188599, Generator loss: 0.44299212098121643\n",
      "Epoch: 19/40, Batch: 1/62, Discriminator loss: 0.570979118347168, Generator loss: 0.42462384700775146\n",
      "Epoch: 19/40, Batch: 2/62, Discriminator loss: 0.5247771143913269, Generator loss: 0.41620221734046936\n",
      "Epoch: 19/40, Batch: 3/62, Discriminator loss: 0.4430772364139557, Generator loss: 0.3727865517139435\n",
      "Epoch: 19/40, Batch: 4/62, Discriminator loss: 0.5623503923416138, Generator loss: 0.366364449262619\n",
      "Epoch: 19/40, Batch: 5/62, Discriminator loss: 0.5363773107528687, Generator loss: 0.39690232276916504\n",
      "Epoch: 19/40, Batch: 6/62, Discriminator loss: 0.5096156597137451, Generator loss: 0.4152308404445648\n",
      "Epoch: 19/40, Batch: 7/62, Discriminator loss: 0.5034632682800293, Generator loss: 0.43531709909439087\n",
      "Epoch: 19/40, Batch: 8/62, Discriminator loss: 0.4777325987815857, Generator loss: 0.3786630630493164\n",
      "Epoch: 19/40, Batch: 9/62, Discriminator loss: 0.5125942826271057, Generator loss: 0.39451494812965393\n",
      "Epoch: 19/40, Batch: 10/62, Discriminator loss: 0.5290900468826294, Generator loss: 0.42221808433532715\n",
      "Epoch: 19/40, Batch: 11/62, Discriminator loss: 0.5282072424888611, Generator loss: 0.4243590235710144\n",
      "Epoch: 19/40, Batch: 12/62, Discriminator loss: 0.4483181834220886, Generator loss: 0.3786609172821045\n",
      "Epoch: 19/40, Batch: 13/62, Discriminator loss: 0.47849586606025696, Generator loss: 0.38851821422576904\n",
      "Epoch: 19/40, Batch: 14/62, Discriminator loss: 0.47288888692855835, Generator loss: 0.3885176181793213\n",
      "Epoch: 19/40, Batch: 15/62, Discriminator loss: 0.4339277148246765, Generator loss: 0.353130578994751\n",
      "Epoch: 19/40, Batch: 16/62, Discriminator loss: 0.3207411766052246, Generator loss: 0.31939855217933655\n",
      "Epoch: 19/40, Batch: 17/62, Discriminator loss: 0.5163088440895081, Generator loss: 0.338286429643631\n",
      "Epoch: 19/40, Batch: 18/62, Discriminator loss: 0.46846628189086914, Generator loss: 0.37553802132606506\n",
      "Epoch: 19/40, Batch: 19/62, Discriminator loss: 0.4546077251434326, Generator loss: 0.3586655855178833\n",
      "Epoch: 19/40, Batch: 20/62, Discriminator loss: 0.576682448387146, Generator loss: 0.3773729205131531\n",
      "Epoch: 19/40, Batch: 21/62, Discriminator loss: 0.5030098557472229, Generator loss: 0.39268460869789124\n",
      "Epoch: 19/40, Batch: 22/62, Discriminator loss: 0.60799241065979, Generator loss: 0.38295796513557434\n",
      "Epoch: 19/40, Batch: 23/62, Discriminator loss: 0.6438697576522827, Generator loss: 0.3778868019580841\n",
      "Epoch: 19/40, Batch: 24/62, Discriminator loss: 0.5311217308044434, Generator loss: 0.31532934308052063\n",
      "Epoch: 19/40, Batch: 25/62, Discriminator loss: 0.7336840033531189, Generator loss: 0.28551357984542847\n",
      "Epoch: 19/40, Batch: 26/62, Discriminator loss: 0.723770797252655, Generator loss: 0.31686004996299744\n",
      "Epoch: 19/40, Batch: 27/62, Discriminator loss: 0.6434718370437622, Generator loss: 0.32598191499710083\n",
      "Epoch: 19/40, Batch: 28/62, Discriminator loss: 0.7019156217575073, Generator loss: 0.3335322141647339\n",
      "Epoch: 19/40, Batch: 29/62, Discriminator loss: 0.6445896625518799, Generator loss: 0.3399544060230255\n",
      "Epoch: 19/40, Batch: 30/62, Discriminator loss: 0.6832484006881714, Generator loss: 0.2742612957954407\n",
      "Epoch: 19/40, Batch: 31/62, Discriminator loss: 0.8041141033172607, Generator loss: 0.2399945855140686\n",
      "Epoch: 19/40, Batch: 32/62, Discriminator loss: 0.6928091645240784, Generator loss: 0.2058078944683075\n",
      "Epoch: 19/40, Batch: 33/62, Discriminator loss: 0.6372522711753845, Generator loss: 0.20731177926063538\n",
      "Epoch: 19/40, Batch: 34/62, Discriminator loss: 0.8532073497772217, Generator loss: 0.2213710993528366\n",
      "Epoch: 19/40, Batch: 35/62, Discriminator loss: 0.5855358839035034, Generator loss: 0.226082906126976\n",
      "Epoch: 19/40, Batch: 36/62, Discriminator loss: 0.7284055352210999, Generator loss: 0.21843524277210236\n",
      "Epoch: 19/40, Batch: 37/62, Discriminator loss: 0.5977248549461365, Generator loss: 0.23927654325962067\n",
      "Epoch: 19/40, Batch: 38/62, Discriminator loss: 0.64031982421875, Generator loss: 0.24238558113574982\n",
      "Epoch: 19/40, Batch: 39/62, Discriminator loss: 0.6804363131523132, Generator loss: 0.2289455235004425\n",
      "Epoch: 19/40, Batch: 40/62, Discriminator loss: 0.8082472085952759, Generator loss: 0.22505070269107819\n",
      "Epoch: 19/40, Batch: 41/62, Discriminator loss: 0.7263607978820801, Generator loss: 0.24338892102241516\n",
      "Epoch: 19/40, Batch: 42/62, Discriminator loss: 0.6046729683876038, Generator loss: 0.21933534741401672\n",
      "Epoch: 19/40, Batch: 43/62, Discriminator loss: 0.7222309112548828, Generator loss: 0.2253376692533493\n",
      "Epoch: 19/40, Batch: 44/62, Discriminator loss: 0.6032695770263672, Generator loss: 0.21727527678012848\n",
      "Epoch: 19/40, Batch: 45/62, Discriminator loss: 0.7061117887496948, Generator loss: 0.22457851469516754\n",
      "Epoch: 19/40, Batch: 46/62, Discriminator loss: 0.6816120147705078, Generator loss: 0.22605332732200623\n",
      "Epoch: 19/40, Batch: 47/62, Discriminator loss: 0.6176150441169739, Generator loss: 0.21800512075424194\n",
      "Epoch: 19/40, Batch: 48/62, Discriminator loss: 0.710658073425293, Generator loss: 0.23938490450382233\n",
      "Epoch: 19/40, Batch: 49/62, Discriminator loss: 0.559289276599884, Generator loss: 0.2384212464094162\n",
      "Epoch: 19/40, Batch: 50/62, Discriminator loss: 0.6030303239822388, Generator loss: 0.2352636158466339\n",
      "Epoch: 19/40, Batch: 51/62, Discriminator loss: 0.665522038936615, Generator loss: 0.2390957772731781\n",
      "Epoch: 19/40, Batch: 52/62, Discriminator loss: 0.5281816124916077, Generator loss: 0.2195984274148941\n",
      "Epoch: 19/40, Batch: 53/62, Discriminator loss: 0.6194846630096436, Generator loss: 0.25442013144493103\n",
      "Epoch: 19/40, Batch: 54/62, Discriminator loss: 0.5607420206069946, Generator loss: 0.24844712018966675\n",
      "Epoch: 19/40, Batch: 55/62, Discriminator loss: 0.5699520111083984, Generator loss: 0.26387763023376465\n",
      "Epoch: 19/40, Batch: 56/62, Discriminator loss: 0.5362359285354614, Generator loss: 0.26704269647598267\n",
      "Epoch: 19/40, Batch: 57/62, Discriminator loss: 0.5198624730110168, Generator loss: 0.25903767347335815\n",
      "Epoch: 19/40, Batch: 58/62, Discriminator loss: 0.5975778102874756, Generator loss: 0.283335417509079\n",
      "Epoch: 19/40, Batch: 59/62, Discriminator loss: 0.5877341628074646, Generator loss: 0.2967979609966278\n",
      "Epoch: 19/40, Batch: 60/62, Discriminator loss: 0.6275479793548584, Generator loss: 0.31720638275146484\n",
      "Epoch: 19/40, Batch: 61/62, Discriminator loss: 0.5550071001052856, Generator loss: 0.3239515423774719\n",
      "Epoch: 19/40, Batch: 62/62, Discriminator loss: 0.5311791896820068, Generator loss: 0.3418695330619812\n",
      "Epoch: 20/40, Batch: 1/62, Discriminator loss: 0.517545223236084, Generator loss: 0.31741032004356384\n",
      "Epoch: 20/40, Batch: 2/62, Discriminator loss: 0.5402155518531799, Generator loss: 0.3170661926269531\n",
      "Epoch: 20/40, Batch: 3/62, Discriminator loss: 0.3667084574699402, Generator loss: 0.30578312277793884\n",
      "Epoch: 20/40, Batch: 4/62, Discriminator loss: 0.5775128602981567, Generator loss: 0.2858226001262665\n",
      "Epoch: 20/40, Batch: 5/62, Discriminator loss: 0.5377615690231323, Generator loss: 0.30617621541023254\n",
      "Epoch: 20/40, Batch: 6/62, Discriminator loss: 0.5565205216407776, Generator loss: 0.31453919410705566\n",
      "Epoch: 20/40, Batch: 7/62, Discriminator loss: 0.4578455090522766, Generator loss: 0.32512542605400085\n",
      "Epoch: 20/40, Batch: 8/62, Discriminator loss: 0.43837031722068787, Generator loss: 0.3118495047092438\n",
      "Epoch: 20/40, Batch: 9/62, Discriminator loss: 0.4933721721172333, Generator loss: 0.31489208340644836\n",
      "Epoch: 20/40, Batch: 10/62, Discriminator loss: 0.4906386435031891, Generator loss: 0.3173094391822815\n",
      "Epoch: 20/40, Batch: 11/62, Discriminator loss: 0.55787193775177, Generator loss: 0.3350249230861664\n",
      "Epoch: 20/40, Batch: 12/62, Discriminator loss: 0.37685734033584595, Generator loss: 0.319044291973114\n",
      "Epoch: 20/40, Batch: 13/62, Discriminator loss: 0.5254708528518677, Generator loss: 0.32536134123802185\n",
      "Epoch: 20/40, Batch: 14/62, Discriminator loss: 0.5035234093666077, Generator loss: 0.3320140838623047\n",
      "Epoch: 20/40, Batch: 15/62, Discriminator loss: 0.4533299207687378, Generator loss: 0.32312628626823425\n",
      "Epoch: 20/40, Batch: 16/62, Discriminator loss: 0.3585217595100403, Generator loss: 0.30599579215049744\n",
      "Epoch: 20/40, Batch: 17/62, Discriminator loss: 0.5356926918029785, Generator loss: 0.3007764220237732\n",
      "Epoch: 20/40, Batch: 18/62, Discriminator loss: 0.5011554956436157, Generator loss: 0.3128313720226288\n",
      "Epoch: 20/40, Batch: 19/62, Discriminator loss: 0.4765135943889618, Generator loss: 0.3189505338668823\n",
      "Epoch: 20/40, Batch: 20/62, Discriminator loss: 0.5464373826980591, Generator loss: 0.33481475710868835\n",
      "Epoch: 20/40, Batch: 21/62, Discriminator loss: 0.5143150687217712, Generator loss: 0.33574381470680237\n",
      "Epoch: 20/40, Batch: 22/62, Discriminator loss: 0.5350136756896973, Generator loss: 0.34833207726478577\n",
      "Epoch: 20/40, Batch: 23/62, Discriminator loss: 0.4748440980911255, Generator loss: 0.3682510554790497\n",
      "Epoch: 20/40, Batch: 24/62, Discriminator loss: 0.37636837363243103, Generator loss: 0.34662607312202454\n",
      "Epoch: 20/40, Batch: 25/62, Discriminator loss: 0.6066584587097168, Generator loss: 0.35365840792655945\n",
      "Epoch: 20/40, Batch: 26/62, Discriminator loss: 0.5107060670852661, Generator loss: 0.3845043182373047\n",
      "Epoch: 20/40, Batch: 27/62, Discriminator loss: 0.4858933091163635, Generator loss: 0.37194955348968506\n",
      "Epoch: 20/40, Batch: 28/62, Discriminator loss: 0.5547321438789368, Generator loss: 0.3897950351238251\n",
      "Epoch: 20/40, Batch: 29/62, Discriminator loss: 0.48347580432891846, Generator loss: 0.39506277441978455\n",
      "Epoch: 20/40, Batch: 30/62, Discriminator loss: 0.38925808668136597, Generator loss: 0.3917555510997772\n",
      "Epoch: 20/40, Batch: 31/62, Discriminator loss: 0.42587751150131226, Generator loss: 0.3476477861404419\n",
      "Epoch: 20/40, Batch: 32/62, Discriminator loss: 0.5038939714431763, Generator loss: 0.3528619706630707\n",
      "Epoch: 20/40, Batch: 33/62, Discriminator loss: 0.36768561601638794, Generator loss: 0.32078638672828674\n",
      "Epoch: 20/40, Batch: 34/62, Discriminator loss: 0.5801366567611694, Generator loss: 0.32597485184669495\n",
      "Epoch: 20/40, Batch: 35/62, Discriminator loss: 0.49075770378112793, Generator loss: 0.30531010031700134\n",
      "Epoch: 20/40, Batch: 36/62, Discriminator loss: 0.5757360458374023, Generator loss: 0.3235335052013397\n",
      "Epoch: 20/40, Batch: 37/62, Discriminator loss: 0.47297203540802, Generator loss: 0.30083489418029785\n",
      "Epoch: 20/40, Batch: 38/62, Discriminator loss: 0.5081610083580017, Generator loss: 0.3063369691371918\n",
      "Epoch: 20/40, Batch: 39/62, Discriminator loss: 0.497723788022995, Generator loss: 0.2827832102775574\n",
      "Epoch: 20/40, Batch: 40/62, Discriminator loss: 0.637627363204956, Generator loss: 0.2816736102104187\n",
      "Epoch: 20/40, Batch: 41/62, Discriminator loss: 0.6031855344772339, Generator loss: 0.27471375465393066\n",
      "Epoch: 20/40, Batch: 42/62, Discriminator loss: 0.4728560447692871, Generator loss: 0.2827238142490387\n",
      "Epoch: 20/40, Batch: 43/62, Discriminator loss: 0.5577512383460999, Generator loss: 0.27787116169929504\n",
      "Epoch: 20/40, Batch: 44/62, Discriminator loss: 0.5241103172302246, Generator loss: 0.2616410553455353\n",
      "Epoch: 20/40, Batch: 45/62, Discriminator loss: 0.5601343512535095, Generator loss: 0.2596279978752136\n",
      "Epoch: 20/40, Batch: 46/62, Discriminator loss: 0.5513531565666199, Generator loss: 0.26095840334892273\n",
      "Epoch: 20/40, Batch: 47/62, Discriminator loss: 0.5418030619621277, Generator loss: 0.27036434412002563\n",
      "Epoch: 20/40, Batch: 48/62, Discriminator loss: 0.6374173164367676, Generator loss: 0.2691280245780945\n",
      "Epoch: 20/40, Batch: 49/62, Discriminator loss: 0.48226398229599, Generator loss: 0.2539964020252228\n",
      "Epoch: 20/40, Batch: 50/62, Discriminator loss: 0.5101980566978455, Generator loss: 0.2557801902294159\n",
      "Epoch: 20/40, Batch: 51/62, Discriminator loss: 0.5848969221115112, Generator loss: 0.2641233205795288\n",
      "Epoch: 20/40, Batch: 52/62, Discriminator loss: 0.4844081699848175, Generator loss: 0.2582959532737732\n",
      "Epoch: 20/40, Batch: 53/62, Discriminator loss: 0.5787901878356934, Generator loss: 0.2673936188220978\n",
      "Epoch: 20/40, Batch: 54/62, Discriminator loss: 0.5337429046630859, Generator loss: 0.267591655254364\n",
      "Epoch: 20/40, Batch: 55/62, Discriminator loss: 0.5236228704452515, Generator loss: 0.28206345438957214\n",
      "Epoch: 20/40, Batch: 56/62, Discriminator loss: 0.5376208424568176, Generator loss: 0.2807539105415344\n",
      "Epoch: 20/40, Batch: 57/62, Discriminator loss: 0.4760001301765442, Generator loss: 0.28165557980537415\n",
      "Epoch: 20/40, Batch: 58/62, Discriminator loss: 0.5785569548606873, Generator loss: 0.29088616371154785\n",
      "Epoch: 20/40, Batch: 59/62, Discriminator loss: 0.5308515429496765, Generator loss: 0.30089327692985535\n",
      "Epoch: 20/40, Batch: 60/62, Discriminator loss: 0.5660182237625122, Generator loss: 0.33698931336402893\n",
      "Epoch: 20/40, Batch: 61/62, Discriminator loss: 0.5677272081375122, Generator loss: 0.34546658396720886\n",
      "Epoch: 20/40, Batch: 62/62, Discriminator loss: 0.4695659279823303, Generator loss: 0.33754199743270874\n",
      "Accuracy real: 25%, fake: 0%\n",
      "Epoch: 21/40, Batch: 1/62, Discriminator loss: 0.7472060322761536, Generator loss: 0.32026103138923645\n",
      "Epoch: 21/40, Batch: 2/62, Discriminator loss: 0.4697073698043823, Generator loss: 0.3395656943321228\n",
      "Epoch: 21/40, Batch: 3/62, Discriminator loss: 0.35977447032928467, Generator loss: 0.30396202206611633\n",
      "Epoch: 21/40, Batch: 4/62, Discriminator loss: 0.6020246148109436, Generator loss: 0.3139728903770447\n",
      "Epoch: 21/40, Batch: 5/62, Discriminator loss: 0.5296629667282104, Generator loss: 0.3196561336517334\n",
      "Epoch: 21/40, Batch: 6/62, Discriminator loss: 0.5307064056396484, Generator loss: 0.32967814803123474\n",
      "Epoch: 21/40, Batch: 7/62, Discriminator loss: 0.5361368060112, Generator loss: 0.32967931032180786\n",
      "Epoch: 21/40, Batch: 8/62, Discriminator loss: 0.47306719422340393, Generator loss: 0.3176630139350891\n",
      "Epoch: 21/40, Batch: 9/62, Discriminator loss: 0.5384168028831482, Generator loss: 0.32899296283721924\n",
      "Epoch: 21/40, Batch: 10/62, Discriminator loss: 0.5502471923828125, Generator loss: 0.3265462815761566\n",
      "Epoch: 21/40, Batch: 11/62, Discriminator loss: 0.5224858522415161, Generator loss: 0.3470255136489868\n",
      "Epoch: 21/40, Batch: 12/62, Discriminator loss: 0.49095308780670166, Generator loss: 0.32097527384757996\n",
      "Epoch: 21/40, Batch: 13/62, Discriminator loss: 0.5240722298622131, Generator loss: 0.3053739368915558\n",
      "Epoch: 21/40, Batch: 14/62, Discriminator loss: 0.552519679069519, Generator loss: 0.2940419912338257\n",
      "Epoch: 21/40, Batch: 15/62, Discriminator loss: 0.5202162265777588, Generator loss: 0.2809038460254669\n",
      "Epoch: 21/40, Batch: 16/62, Discriminator loss: 0.41624927520751953, Generator loss: 0.26404327154159546\n",
      "Epoch: 21/40, Batch: 17/62, Discriminator loss: 0.6063487529754639, Generator loss: 0.2769623100757599\n",
      "Epoch: 21/40, Batch: 18/62, Discriminator loss: 0.547076940536499, Generator loss: 0.2662442922592163\n",
      "Epoch: 21/40, Batch: 19/62, Discriminator loss: 0.620100736618042, Generator loss: 0.29158493876457214\n",
      "Epoch: 21/40, Batch: 20/62, Discriminator loss: 0.6328413486480713, Generator loss: 0.28850969672203064\n",
      "Epoch: 21/40, Batch: 21/62, Discriminator loss: 0.5842947959899902, Generator loss: 0.3046126961708069\n",
      "Epoch: 21/40, Batch: 22/62, Discriminator loss: 0.683053195476532, Generator loss: 0.3248586356639862\n",
      "Epoch: 21/40, Batch: 23/62, Discriminator loss: 0.624436616897583, Generator loss: 0.33113107085227966\n",
      "Epoch: 21/40, Batch: 24/62, Discriminator loss: 0.5084002614021301, Generator loss: 0.3123956024646759\n",
      "Epoch: 21/40, Batch: 25/62, Discriminator loss: 0.7248295545578003, Generator loss: 0.31304290890693665\n",
      "Epoch: 21/40, Batch: 26/62, Discriminator loss: 0.6834977865219116, Generator loss: 0.323138028383255\n",
      "Epoch: 21/40, Batch: 27/62, Discriminator loss: 0.6052396297454834, Generator loss: 0.3294145464897156\n",
      "Epoch: 21/40, Batch: 28/62, Discriminator loss: 0.6652734279632568, Generator loss: 0.35582754015922546\n",
      "Epoch: 21/40, Batch: 29/62, Discriminator loss: 0.5619112253189087, Generator loss: 0.35512223839759827\n",
      "Epoch: 21/40, Batch: 30/62, Discriminator loss: 0.6224076747894287, Generator loss: 0.3483036458492279\n",
      "Epoch: 21/40, Batch: 31/62, Discriminator loss: 0.6296297311782837, Generator loss: 0.3149920403957367\n",
      "Epoch: 21/40, Batch: 32/62, Discriminator loss: 0.5557985305786133, Generator loss: 0.2988441586494446\n",
      "Epoch: 21/40, Batch: 33/62, Discriminator loss: 0.4678201675415039, Generator loss: 0.2904193103313446\n",
      "Epoch: 21/40, Batch: 34/62, Discriminator loss: 0.6817972660064697, Generator loss: 0.29686909914016724\n",
      "Epoch: 21/40, Batch: 35/62, Discriminator loss: 0.49837392568588257, Generator loss: 0.283993661403656\n",
      "Epoch: 21/40, Batch: 36/62, Discriminator loss: 0.6201049089431763, Generator loss: 0.30583763122558594\n",
      "Epoch: 21/40, Batch: 37/62, Discriminator loss: 0.5434343814849854, Generator loss: 0.3093566298484802\n",
      "Epoch: 21/40, Batch: 38/62, Discriminator loss: 0.500839352607727, Generator loss: 0.28792092204093933\n",
      "Epoch: 21/40, Batch: 39/62, Discriminator loss: 0.47404682636260986, Generator loss: 0.287574827671051\n",
      "Epoch: 21/40, Batch: 40/62, Discriminator loss: 0.627530038356781, Generator loss: 0.3042322099208832\n",
      "Epoch: 21/40, Batch: 41/62, Discriminator loss: 0.5155397057533264, Generator loss: 0.29286670684814453\n",
      "Epoch: 21/40, Batch: 42/62, Discriminator loss: 0.43846550583839417, Generator loss: 0.29673853516578674\n",
      "Epoch: 21/40, Batch: 43/62, Discriminator loss: 0.5520086288452148, Generator loss: 0.2687268853187561\n",
      "Epoch: 21/40, Batch: 44/62, Discriminator loss: 0.37458521127700806, Generator loss: 0.2582186460494995\n",
      "Epoch: 21/40, Batch: 45/62, Discriminator loss: 0.5596256256103516, Generator loss: 0.28069305419921875\n",
      "Epoch: 21/40, Batch: 46/62, Discriminator loss: 0.4813517928123474, Generator loss: 0.27695515751838684\n",
      "Epoch: 21/40, Batch: 47/62, Discriminator loss: 0.42095208168029785, Generator loss: 0.27114948630332947\n",
      "Epoch: 21/40, Batch: 48/62, Discriminator loss: 0.5799652934074402, Generator loss: 0.287244975566864\n",
      "Epoch: 21/40, Batch: 49/62, Discriminator loss: 0.3396871089935303, Generator loss: 0.2713637053966522\n",
      "Epoch: 21/40, Batch: 50/62, Discriminator loss: 0.4592411518096924, Generator loss: 0.27281132340431213\n",
      "Epoch: 21/40, Batch: 51/62, Discriminator loss: 0.5002977848052979, Generator loss: 0.27092909812927246\n",
      "Epoch: 21/40, Batch: 52/62, Discriminator loss: 0.411278635263443, Generator loss: 0.28153863549232483\n",
      "Epoch: 21/40, Batch: 53/62, Discriminator loss: 0.5228660702705383, Generator loss: 0.28686511516571045\n",
      "Epoch: 21/40, Batch: 54/62, Discriminator loss: 0.5241886377334595, Generator loss: 0.31328460574150085\n",
      "Epoch: 21/40, Batch: 55/62, Discriminator loss: 0.49707141518592834, Generator loss: 0.336669921875\n",
      "Epoch: 21/40, Batch: 56/62, Discriminator loss: 0.5305771827697754, Generator loss: 0.36550483107566833\n",
      "Epoch: 21/40, Batch: 57/62, Discriminator loss: 0.48786768317222595, Generator loss: 0.34537485241889954\n",
      "Epoch: 21/40, Batch: 58/62, Discriminator loss: 0.5646740198135376, Generator loss: 0.3667308986186981\n",
      "Epoch: 21/40, Batch: 59/62, Discriminator loss: 0.5402698516845703, Generator loss: 0.3846622705459595\n",
      "Epoch: 21/40, Batch: 60/62, Discriminator loss: 0.6149979829788208, Generator loss: 0.42319387197494507\n",
      "Epoch: 21/40, Batch: 61/62, Discriminator loss: 0.5499533414840698, Generator loss: 0.4284636974334717\n",
      "Epoch: 21/40, Batch: 62/62, Discriminator loss: 0.5201729536056519, Generator loss: 0.4021293818950653\n",
      "Epoch: 22/40, Batch: 1/62, Discriminator loss: 0.49677538871765137, Generator loss: 0.35686197876930237\n",
      "Epoch: 22/40, Batch: 2/62, Discriminator loss: 0.5780084133148193, Generator loss: 0.35832369327545166\n",
      "Epoch: 22/40, Batch: 3/62, Discriminator loss: 0.3993419110774994, Generator loss: 0.30251070857048035\n",
      "Epoch: 22/40, Batch: 4/62, Discriminator loss: 0.557959794998169, Generator loss: 0.3048795759677887\n",
      "Epoch: 22/40, Batch: 5/62, Discriminator loss: 0.5496474504470825, Generator loss: 0.30892106890678406\n",
      "Epoch: 22/40, Batch: 6/62, Discriminator loss: 0.5073270797729492, Generator loss: 0.3338955342769623\n",
      "Epoch: 22/40, Batch: 7/62, Discriminator loss: 0.4131530523300171, Generator loss: 0.3310159146785736\n",
      "Epoch: 22/40, Batch: 8/62, Discriminator loss: 0.3451477587223053, Generator loss: 0.3363575041294098\n",
      "Epoch: 22/40, Batch: 9/62, Discriminator loss: 0.46274587512016296, Generator loss: 0.32411324977874756\n",
      "Epoch: 22/40, Batch: 10/62, Discriminator loss: 0.5014099478721619, Generator loss: 0.3689554035663605\n",
      "Epoch: 22/40, Batch: 11/62, Discriminator loss: 0.5147752165794373, Generator loss: 0.3662036657333374\n",
      "Epoch: 22/40, Batch: 12/62, Discriminator loss: 0.33298197388648987, Generator loss: 0.329181432723999\n",
      "Epoch: 22/40, Batch: 13/62, Discriminator loss: 0.5458227396011353, Generator loss: 0.3371794819831848\n",
      "Epoch: 22/40, Batch: 14/62, Discriminator loss: 0.4678189754486084, Generator loss: 0.334331750869751\n",
      "Epoch: 22/40, Batch: 15/62, Discriminator loss: 0.5144699811935425, Generator loss: 0.3119758665561676\n",
      "Epoch: 22/40, Batch: 16/62, Discriminator loss: 0.3401139974594116, Generator loss: 0.28469374775886536\n",
      "Epoch: 22/40, Batch: 17/62, Discriminator loss: 0.545873761177063, Generator loss: 0.2981759011745453\n",
      "Epoch: 22/40, Batch: 18/62, Discriminator loss: 0.478139191865921, Generator loss: 0.31273820996284485\n",
      "Epoch: 22/40, Batch: 19/62, Discriminator loss: 0.496600866317749, Generator loss: 0.29107627272605896\n",
      "Epoch: 22/40, Batch: 20/62, Discriminator loss: 0.640342116355896, Generator loss: 0.28916481137275696\n",
      "Epoch: 22/40, Batch: 21/62, Discriminator loss: 0.6123735308647156, Generator loss: 0.26784300804138184\n",
      "Epoch: 22/40, Batch: 22/62, Discriminator loss: 0.6164557933807373, Generator loss: 0.271171510219574\n",
      "Epoch: 22/40, Batch: 23/62, Discriminator loss: 0.5841339230537415, Generator loss: 0.25205329060554504\n",
      "Epoch: 22/40, Batch: 24/62, Discriminator loss: 0.5709514617919922, Generator loss: 0.20683319866657257\n",
      "Epoch: 22/40, Batch: 25/62, Discriminator loss: 0.8620429039001465, Generator loss: 0.20372255146503448\n",
      "Epoch: 22/40, Batch: 26/62, Discriminator loss: 0.648024320602417, Generator loss: 0.22639691829681396\n",
      "Epoch: 22/40, Batch: 27/62, Discriminator loss: 0.692811131477356, Generator loss: 0.21170742809772491\n",
      "Epoch: 22/40, Batch: 28/62, Discriminator loss: 0.7474083304405212, Generator loss: 0.20966802537441254\n",
      "Epoch: 22/40, Batch: 29/62, Discriminator loss: 0.6587105989456177, Generator loss: 0.21778959035873413\n",
      "Epoch: 22/40, Batch: 30/62, Discriminator loss: 0.549500584602356, Generator loss: 0.21643245220184326\n",
      "Epoch: 22/40, Batch: 31/62, Discriminator loss: 0.5015838146209717, Generator loss: 0.20269574224948883\n",
      "Epoch: 22/40, Batch: 32/62, Discriminator loss: 0.5822107791900635, Generator loss: 0.20971018075942993\n",
      "Epoch: 22/40, Batch: 33/62, Discriminator loss: 0.3927345871925354, Generator loss: 0.18679600954055786\n",
      "Epoch: 22/40, Batch: 34/62, Discriminator loss: 0.6959333419799805, Generator loss: 0.1943362057209015\n",
      "Epoch: 22/40, Batch: 35/62, Discriminator loss: 0.5332220792770386, Generator loss: 0.19576559960842133\n",
      "Epoch: 22/40, Batch: 36/62, Discriminator loss: 0.6557224988937378, Generator loss: 0.22108806669712067\n",
      "Epoch: 22/40, Batch: 37/62, Discriminator loss: 0.5232568383216858, Generator loss: 0.2127843201160431\n",
      "Epoch: 22/40, Batch: 38/62, Discriminator loss: 0.5428423881530762, Generator loss: 0.22507719695568085\n",
      "Epoch: 22/40, Batch: 39/62, Discriminator loss: 0.4910091757774353, Generator loss: 0.2156248390674591\n",
      "Epoch: 22/40, Batch: 40/62, Discriminator loss: 0.6632505655288696, Generator loss: 0.26004549860954285\n",
      "Epoch: 22/40, Batch: 41/62, Discriminator loss: 0.5521371960639954, Generator loss: 0.27520105242729187\n",
      "Epoch: 22/40, Batch: 42/62, Discriminator loss: 0.4978254437446594, Generator loss: 0.2788902521133423\n",
      "Epoch: 22/40, Batch: 43/62, Discriminator loss: 0.5701751708984375, Generator loss: 0.30045029520988464\n",
      "Epoch: 22/40, Batch: 44/62, Discriminator loss: 0.4748910963535309, Generator loss: 0.30370354652404785\n",
      "Epoch: 22/40, Batch: 45/62, Discriminator loss: 0.6106991171836853, Generator loss: 0.3155056834220886\n",
      "Epoch: 22/40, Batch: 46/62, Discriminator loss: 0.5727460384368896, Generator loss: 0.353924036026001\n",
      "Epoch: 22/40, Batch: 47/62, Discriminator loss: 0.5027959942817688, Generator loss: 0.35769039392471313\n",
      "Epoch: 22/40, Batch: 48/62, Discriminator loss: 0.6295620203018188, Generator loss: 0.3763856589794159\n",
      "Epoch: 22/40, Batch: 49/62, Discriminator loss: 0.5072252750396729, Generator loss: 0.341854065656662\n",
      "Epoch: 22/40, Batch: 50/62, Discriminator loss: 0.5728326439857483, Generator loss: 0.3179594576358795\n",
      "Epoch: 22/40, Batch: 51/62, Discriminator loss: 0.6108294725418091, Generator loss: 0.3236980438232422\n",
      "Epoch: 22/40, Batch: 52/62, Discriminator loss: 0.5647902488708496, Generator loss: 0.30728915333747864\n",
      "Epoch: 22/40, Batch: 53/62, Discriminator loss: 0.65120929479599, Generator loss: 0.30577439069747925\n",
      "Epoch: 22/40, Batch: 54/62, Discriminator loss: 0.6062092781066895, Generator loss: 0.32488662004470825\n",
      "Epoch: 22/40, Batch: 55/62, Discriminator loss: 0.5789337754249573, Generator loss: 0.342327356338501\n",
      "Epoch: 22/40, Batch: 56/62, Discriminator loss: 0.6232346296310425, Generator loss: 0.36168694496154785\n",
      "Epoch: 22/40, Batch: 57/62, Discriminator loss: 0.6027979850769043, Generator loss: 0.35306912660598755\n",
      "Epoch: 22/40, Batch: 58/62, Discriminator loss: 0.6273906230926514, Generator loss: 0.3803819715976715\n",
      "Epoch: 22/40, Batch: 59/62, Discriminator loss: 0.5762172341346741, Generator loss: 0.3781735301017761\n",
      "Epoch: 22/40, Batch: 60/62, Discriminator loss: 0.5866647958755493, Generator loss: 0.4225683808326721\n",
      "Epoch: 22/40, Batch: 61/62, Discriminator loss: 0.5827080011367798, Generator loss: 0.45048367977142334\n",
      "Epoch: 22/40, Batch: 62/62, Discriminator loss: 0.5400997400283813, Generator loss: 0.4051018953323364\n",
      "Epoch: 23/40, Batch: 1/62, Discriminator loss: 0.574469804763794, Generator loss: 0.40293943881988525\n",
      "Epoch: 23/40, Batch: 2/62, Discriminator loss: 0.5567082166671753, Generator loss: 0.3773868978023529\n",
      "Epoch: 23/40, Batch: 3/62, Discriminator loss: 0.4239075481891632, Generator loss: 0.35546454787254333\n",
      "Epoch: 23/40, Batch: 4/62, Discriminator loss: 0.5974721312522888, Generator loss: 0.3792813718318939\n",
      "Epoch: 23/40, Batch: 5/62, Discriminator loss: 0.5838978290557861, Generator loss: 0.375193327665329\n",
      "Epoch: 23/40, Batch: 6/62, Discriminator loss: 0.5997744798660278, Generator loss: 0.3721848130226135\n",
      "Epoch: 23/40, Batch: 7/62, Discriminator loss: 0.5412452816963196, Generator loss: 0.4048762023448944\n",
      "Epoch: 23/40, Batch: 8/62, Discriminator loss: 0.5474040508270264, Generator loss: 0.42470723390579224\n",
      "Epoch: 23/40, Batch: 9/62, Discriminator loss: 0.5489864945411682, Generator loss: 0.43689316511154175\n",
      "Epoch: 23/40, Batch: 10/62, Discriminator loss: 0.5580011010169983, Generator loss: 0.42855969071388245\n",
      "Epoch: 23/40, Batch: 11/62, Discriminator loss: 0.5668057799339294, Generator loss: 0.4337846636772156\n",
      "Epoch: 23/40, Batch: 12/62, Discriminator loss: 0.5095703601837158, Generator loss: 0.38107627630233765\n",
      "Epoch: 23/40, Batch: 13/62, Discriminator loss: 0.5279167294502258, Generator loss: 0.37213531136512756\n",
      "Epoch: 23/40, Batch: 14/62, Discriminator loss: 0.544927179813385, Generator loss: 0.34783148765563965\n",
      "Epoch: 23/40, Batch: 15/62, Discriminator loss: 0.5280616283416748, Generator loss: 0.3355136513710022\n",
      "Epoch: 23/40, Batch: 16/62, Discriminator loss: 0.4742240905761719, Generator loss: 0.2920571565628052\n",
      "Epoch: 23/40, Batch: 17/62, Discriminator loss: 0.6111458539962769, Generator loss: 0.2880389988422394\n",
      "Epoch: 23/40, Batch: 18/62, Discriminator loss: 0.5886071920394897, Generator loss: 0.3101465702056885\n",
      "Epoch: 23/40, Batch: 19/62, Discriminator loss: 0.5767775177955627, Generator loss: 0.3124851584434509\n",
      "Epoch: 23/40, Batch: 20/62, Discriminator loss: 0.6200711727142334, Generator loss: 0.3108896017074585\n",
      "Epoch: 23/40, Batch: 21/62, Discriminator loss: 0.5888236165046692, Generator loss: 0.3092261850833893\n",
      "Epoch: 23/40, Batch: 22/62, Discriminator loss: 0.6900648474693298, Generator loss: 0.3127742111682892\n",
      "Epoch: 23/40, Batch: 23/62, Discriminator loss: 0.5882803201675415, Generator loss: 0.2925339341163635\n",
      "Epoch: 23/40, Batch: 24/62, Discriminator loss: 0.5249923467636108, Generator loss: 0.27211910486221313\n",
      "Epoch: 23/40, Batch: 25/62, Discriminator loss: 0.7570185661315918, Generator loss: 0.25945305824279785\n",
      "Epoch: 23/40, Batch: 26/62, Discriminator loss: 0.6109040975570679, Generator loss: 0.2710087299346924\n",
      "Epoch: 23/40, Batch: 27/62, Discriminator loss: 0.6035070419311523, Generator loss: 0.27826127409935\n",
      "Epoch: 23/40, Batch: 28/62, Discriminator loss: 0.635876476764679, Generator loss: 0.28659766912460327\n",
      "Epoch: 23/40, Batch: 29/62, Discriminator loss: 0.5344923138618469, Generator loss: 0.29189300537109375\n",
      "Epoch: 23/40, Batch: 30/62, Discriminator loss: 0.4748762249946594, Generator loss: 0.266082763671875\n",
      "Epoch: 23/40, Batch: 31/62, Discriminator loss: 0.4766886532306671, Generator loss: 0.2664497196674347\n",
      "Epoch: 23/40, Batch: 32/62, Discriminator loss: 0.4867708683013916, Generator loss: 0.24820035696029663\n",
      "Epoch: 23/40, Batch: 33/62, Discriminator loss: 0.2996636629104614, Generator loss: 0.24376939237117767\n",
      "Epoch: 23/40, Batch: 34/62, Discriminator loss: 0.6064852476119995, Generator loss: 0.24237403273582458\n",
      "Epoch: 23/40, Batch: 35/62, Discriminator loss: 0.3675474524497986, Generator loss: 0.23682601749897003\n",
      "Epoch: 23/40, Batch: 36/62, Discriminator loss: 0.5332140922546387, Generator loss: 0.24948862195014954\n",
      "Epoch: 23/40, Batch: 37/62, Discriminator loss: 0.3944566547870636, Generator loss: 0.24756234884262085\n",
      "Epoch: 23/40, Batch: 38/62, Discriminator loss: 0.39168065786361694, Generator loss: 0.24993909895420074\n",
      "Epoch: 23/40, Batch: 39/62, Discriminator loss: 0.41696956753730774, Generator loss: 0.24765171110630035\n",
      "Epoch: 23/40, Batch: 40/62, Discriminator loss: 0.6696730852127075, Generator loss: 0.27365222573280334\n",
      "Epoch: 23/40, Batch: 41/62, Discriminator loss: 0.5299444198608398, Generator loss: 0.2813234031200409\n",
      "Epoch: 23/40, Batch: 42/62, Discriminator loss: 0.4408472180366516, Generator loss: 0.3353782296180725\n",
      "Epoch: 23/40, Batch: 43/62, Discriminator loss: 0.559552788734436, Generator loss: 0.3603837490081787\n",
      "Epoch: 23/40, Batch: 44/62, Discriminator loss: 0.4753187298774719, Generator loss: 0.386944055557251\n",
      "Epoch: 23/40, Batch: 45/62, Discriminator loss: 0.6138266324996948, Generator loss: 0.3844626545906067\n",
      "Epoch: 23/40, Batch: 46/62, Discriminator loss: 0.5496695041656494, Generator loss: 0.4618735611438751\n",
      "Epoch: 23/40, Batch: 47/62, Discriminator loss: 0.5256231427192688, Generator loss: 0.43708452582359314\n",
      "Epoch: 23/40, Batch: 48/62, Discriminator loss: 0.6153313517570496, Generator loss: 0.49170008301734924\n",
      "Epoch: 23/40, Batch: 49/62, Discriminator loss: 0.5998547077178955, Generator loss: 0.43090856075286865\n",
      "Epoch: 23/40, Batch: 50/62, Discriminator loss: 0.5234616994857788, Generator loss: 0.39498940110206604\n",
      "Epoch: 23/40, Batch: 51/62, Discriminator loss: 0.6654210090637207, Generator loss: 0.3886192739009857\n",
      "Epoch: 23/40, Batch: 52/62, Discriminator loss: 0.5567640066146851, Generator loss: 0.3689183294773102\n",
      "Epoch: 23/40, Batch: 53/62, Discriminator loss: 0.6154530644416809, Generator loss: 0.35426729917526245\n",
      "Epoch: 23/40, Batch: 54/62, Discriminator loss: 0.6163037419319153, Generator loss: 0.36343783140182495\n",
      "Epoch: 23/40, Batch: 55/62, Discriminator loss: 0.6218885183334351, Generator loss: 0.3619992733001709\n",
      "Epoch: 23/40, Batch: 56/62, Discriminator loss: 0.5457957983016968, Generator loss: 0.40821394324302673\n",
      "Epoch: 23/40, Batch: 57/62, Discriminator loss: 0.5838009715080261, Generator loss: 0.3656448721885681\n",
      "Epoch: 23/40, Batch: 58/62, Discriminator loss: 0.6072596907615662, Generator loss: 0.3600292205810547\n",
      "Epoch: 23/40, Batch: 59/62, Discriminator loss: 0.5479893088340759, Generator loss: 0.3726879060268402\n",
      "Epoch: 23/40, Batch: 60/62, Discriminator loss: 0.6108039617538452, Generator loss: 0.38058122992515564\n",
      "Epoch: 23/40, Batch: 61/62, Discriminator loss: 0.5901057124137878, Generator loss: 0.3856193423271179\n",
      "Epoch: 23/40, Batch: 62/62, Discriminator loss: 0.5217286348342896, Generator loss: 0.3431444466114044\n",
      "Epoch: 24/40, Batch: 1/62, Discriminator loss: 0.5279866456985474, Generator loss: 0.3402484059333801\n",
      "Epoch: 24/40, Batch: 2/62, Discriminator loss: 0.568291962146759, Generator loss: 0.31052640080451965\n",
      "Epoch: 24/40, Batch: 3/62, Discriminator loss: 0.43439480662345886, Generator loss: 0.26128333806991577\n",
      "Epoch: 24/40, Batch: 4/62, Discriminator loss: 0.5853137373924255, Generator loss: 0.2623439431190491\n",
      "Epoch: 24/40, Batch: 5/62, Discriminator loss: 0.6006299257278442, Generator loss: 0.26499268412590027\n",
      "Epoch: 24/40, Batch: 6/62, Discriminator loss: 0.6183674335479736, Generator loss: 0.274283766746521\n",
      "Epoch: 24/40, Batch: 7/62, Discriminator loss: 0.4643127918243408, Generator loss: 0.26165926456451416\n",
      "Epoch: 24/40, Batch: 8/62, Discriminator loss: 0.48975351452827454, Generator loss: 0.2580263018608093\n",
      "Epoch: 24/40, Batch: 9/62, Discriminator loss: 0.5614732503890991, Generator loss: 0.2599681317806244\n",
      "Epoch: 24/40, Batch: 10/62, Discriminator loss: 0.56864333152771, Generator loss: 0.24656489491462708\n",
      "Epoch: 24/40, Batch: 11/62, Discriminator loss: 0.6276576519012451, Generator loss: 0.2478121817111969\n",
      "Epoch: 24/40, Batch: 12/62, Discriminator loss: 0.44179248809814453, Generator loss: 0.23423177003860474\n",
      "Epoch: 24/40, Batch: 13/62, Discriminator loss: 0.5916764140129089, Generator loss: 0.22459687292575836\n",
      "Epoch: 24/40, Batch: 14/62, Discriminator loss: 0.5398289561271667, Generator loss: 0.22577641904354095\n",
      "Epoch: 24/40, Batch: 15/62, Discriminator loss: 0.5315655469894409, Generator loss: 0.22662203013896942\n",
      "Epoch: 24/40, Batch: 16/62, Discriminator loss: 0.40617746114730835, Generator loss: 0.21266716718673706\n",
      "Epoch: 24/40, Batch: 17/62, Discriminator loss: 0.6319209337234497, Generator loss: 0.21585901081562042\n",
      "Epoch: 24/40, Batch: 18/62, Discriminator loss: 0.6018614172935486, Generator loss: 0.22287683188915253\n",
      "Epoch: 24/40, Batch: 19/62, Discriminator loss: 0.5506749153137207, Generator loss: 0.21961383521556854\n",
      "Epoch: 24/40, Batch: 20/62, Discriminator loss: 0.6244910359382629, Generator loss: 0.2308049350976944\n",
      "Epoch: 24/40, Batch: 21/62, Discriminator loss: 0.581741213798523, Generator loss: 0.24128179252147675\n",
      "Epoch: 24/40, Batch: 22/62, Discriminator loss: 0.6449092626571655, Generator loss: 0.26926860213279724\n",
      "Epoch: 24/40, Batch: 23/62, Discriminator loss: 0.5683571100234985, Generator loss: 0.28451502323150635\n",
      "Epoch: 24/40, Batch: 24/62, Discriminator loss: 0.44486498832702637, Generator loss: 0.2573712468147278\n",
      "Epoch: 24/40, Batch: 25/62, Discriminator loss: 0.6897592544555664, Generator loss: 0.2869437336921692\n",
      "Epoch: 24/40, Batch: 26/62, Discriminator loss: 0.5904697775840759, Generator loss: 0.3117741048336029\n",
      "Epoch: 24/40, Batch: 27/62, Discriminator loss: 0.5668653249740601, Generator loss: 0.3199756443500519\n",
      "Epoch: 24/40, Batch: 28/62, Discriminator loss: 0.6114188432693481, Generator loss: 0.3177012503147125\n",
      "Epoch: 24/40, Batch: 29/62, Discriminator loss: 0.5363554358482361, Generator loss: 0.33219221234321594\n",
      "Epoch: 24/40, Batch: 30/62, Discriminator loss: 0.5089722871780396, Generator loss: 0.3036217987537384\n",
      "Epoch: 24/40, Batch: 31/62, Discriminator loss: 0.5606689453125, Generator loss: 0.30361324548721313\n",
      "Epoch: 24/40, Batch: 32/62, Discriminator loss: 0.610427737236023, Generator loss: 0.30640044808387756\n",
      "Epoch: 24/40, Batch: 33/62, Discriminator loss: 0.4798446595668793, Generator loss: 0.277313232421875\n",
      "Epoch: 24/40, Batch: 34/62, Discriminator loss: 0.7232173681259155, Generator loss: 0.30031222105026245\n",
      "Epoch: 24/40, Batch: 35/62, Discriminator loss: 0.576910674571991, Generator loss: 0.2933470904827118\n",
      "Epoch: 24/40, Batch: 36/62, Discriminator loss: 0.6312211751937866, Generator loss: 0.30946293473243713\n",
      "Epoch: 24/40, Batch: 37/62, Discriminator loss: 0.5714102983474731, Generator loss: 0.3192051351070404\n",
      "Epoch: 24/40, Batch: 38/62, Discriminator loss: 0.5147602558135986, Generator loss: 0.3077274262905121\n",
      "Epoch: 24/40, Batch: 39/62, Discriminator loss: 0.5235729217529297, Generator loss: 0.31811946630477905\n",
      "Epoch: 24/40, Batch: 40/62, Discriminator loss: 0.6308027505874634, Generator loss: 0.32549917697906494\n",
      "Epoch: 24/40, Batch: 41/62, Discriminator loss: 0.5532728433609009, Generator loss: 0.32640406489372253\n",
      "Epoch: 24/40, Batch: 42/62, Discriminator loss: 0.5005980730056763, Generator loss: 0.2957760691642761\n",
      "Epoch: 24/40, Batch: 43/62, Discriminator loss: 0.5671958923339844, Generator loss: 0.2975504398345947\n",
      "Epoch: 24/40, Batch: 44/62, Discriminator loss: 0.4889330267906189, Generator loss: 0.26661401987075806\n",
      "Epoch: 24/40, Batch: 45/62, Discriminator loss: 0.6066014766693115, Generator loss: 0.2510553300380707\n",
      "Epoch: 24/40, Batch: 46/62, Discriminator loss: 0.5942524075508118, Generator loss: 0.2622927725315094\n",
      "Epoch: 24/40, Batch: 47/62, Discriminator loss: 0.5241827368736267, Generator loss: 0.24381501972675323\n",
      "Epoch: 24/40, Batch: 48/62, Discriminator loss: 0.6469035148620605, Generator loss: 0.2712517976760864\n",
      "Epoch: 24/40, Batch: 49/62, Discriminator loss: 0.5333543419837952, Generator loss: 0.23959901928901672\n",
      "Epoch: 24/40, Batch: 50/62, Discriminator loss: 0.5677695274353027, Generator loss: 0.24215808510780334\n",
      "Epoch: 24/40, Batch: 51/62, Discriminator loss: 0.6488457322120667, Generator loss: 0.2544343173503876\n",
      "Epoch: 24/40, Batch: 52/62, Discriminator loss: 0.5938658714294434, Generator loss: 0.2724786400794983\n",
      "Epoch: 24/40, Batch: 53/62, Discriminator loss: 0.6239232420921326, Generator loss: 0.2899169921875\n",
      "Epoch: 24/40, Batch: 54/62, Discriminator loss: 0.5739794373512268, Generator loss: 0.30322185158729553\n",
      "Epoch: 24/40, Batch: 55/62, Discriminator loss: 0.5972849130630493, Generator loss: 0.31026193499565125\n",
      "Epoch: 24/40, Batch: 56/62, Discriminator loss: 0.5800496339797974, Generator loss: 0.3254905939102173\n",
      "Epoch: 24/40, Batch: 57/62, Discriminator loss: 0.5178691148757935, Generator loss: 0.33034342527389526\n",
      "Epoch: 24/40, Batch: 58/62, Discriminator loss: 0.5656877160072327, Generator loss: 0.3432174324989319\n",
      "Epoch: 24/40, Batch: 59/62, Discriminator loss: 0.5655803680419922, Generator loss: 0.348134309053421\n",
      "Epoch: 24/40, Batch: 60/62, Discriminator loss: 0.6184337139129639, Generator loss: 0.3678811490535736\n",
      "Epoch: 24/40, Batch: 61/62, Discriminator loss: 0.5595166087150574, Generator loss: 0.39454588294029236\n",
      "Epoch: 24/40, Batch: 62/62, Discriminator loss: 0.5093836784362793, Generator loss: 0.3634752333164215\n",
      "Epoch: 25/40, Batch: 1/62, Discriminator loss: 0.5650873184204102, Generator loss: 0.3695611357688904\n",
      "Epoch: 25/40, Batch: 2/62, Discriminator loss: 0.4945938289165497, Generator loss: 0.3359302878379822\n",
      "Epoch: 25/40, Batch: 3/62, Discriminator loss: 0.36262452602386475, Generator loss: 0.3066357970237732\n",
      "Epoch: 25/40, Batch: 4/62, Discriminator loss: 0.6066102385520935, Generator loss: 0.31076887249946594\n",
      "Epoch: 25/40, Batch: 5/62, Discriminator loss: 0.5953702926635742, Generator loss: 0.2983260750770569\n",
      "Epoch: 25/40, Batch: 6/62, Discriminator loss: 0.5902179479598999, Generator loss: 0.29845181107521057\n",
      "Epoch: 25/40, Batch: 7/62, Discriminator loss: 0.5046346187591553, Generator loss: 0.29393357038497925\n",
      "Epoch: 25/40, Batch: 8/62, Discriminator loss: 0.4837730824947357, Generator loss: 0.2867269515991211\n",
      "Epoch: 25/40, Batch: 9/62, Discriminator loss: 0.549139142036438, Generator loss: 0.30857452750205994\n",
      "Epoch: 25/40, Batch: 10/62, Discriminator loss: 0.5666190385818481, Generator loss: 0.2917601764202118\n",
      "Epoch: 25/40, Batch: 11/62, Discriminator loss: 0.6072643995285034, Generator loss: 0.302224338054657\n",
      "Epoch: 25/40, Batch: 12/62, Discriminator loss: 0.4518515169620514, Generator loss: 0.29307809472084045\n",
      "Epoch: 25/40, Batch: 13/62, Discriminator loss: 0.5114740133285522, Generator loss: 0.28019481897354126\n",
      "Epoch: 25/40, Batch: 14/62, Discriminator loss: 0.5103012919425964, Generator loss: 0.2852102816104889\n",
      "Epoch: 25/40, Batch: 15/62, Discriminator loss: 0.44147390127182007, Generator loss: 0.2639926075935364\n",
      "Epoch: 25/40, Batch: 16/62, Discriminator loss: 0.33368754386901855, Generator loss: 0.24153093993663788\n",
      "Epoch: 25/40, Batch: 17/62, Discriminator loss: 0.5485893487930298, Generator loss: 0.24148301780223846\n",
      "Epoch: 25/40, Batch: 18/62, Discriminator loss: 0.5126480460166931, Generator loss: 0.2391315996646881\n",
      "Epoch: 25/40, Batch: 19/62, Discriminator loss: 0.48255985975265503, Generator loss: 0.22710736095905304\n",
      "Epoch: 25/40, Batch: 20/62, Discriminator loss: 0.558005690574646, Generator loss: 0.25472211837768555\n",
      "Epoch: 25/40, Batch: 21/62, Discriminator loss: 0.4822936952114105, Generator loss: 0.24473436176776886\n",
      "Epoch: 25/40, Batch: 22/62, Discriminator loss: 0.6439677476882935, Generator loss: 0.24249060451984406\n",
      "Epoch: 25/40, Batch: 23/62, Discriminator loss: 0.5569174289703369, Generator loss: 0.2699011564254761\n",
      "Epoch: 25/40, Batch: 24/62, Discriminator loss: 0.4021097421646118, Generator loss: 0.2427232563495636\n",
      "Epoch: 25/40, Batch: 25/62, Discriminator loss: 0.7035084962844849, Generator loss: 0.24038010835647583\n",
      "Epoch: 25/40, Batch: 26/62, Discriminator loss: 0.645289421081543, Generator loss: 0.2725052535533905\n",
      "Epoch: 25/40, Batch: 27/62, Discriminator loss: 0.594805121421814, Generator loss: 0.28263339400291443\n",
      "Epoch: 25/40, Batch: 28/62, Discriminator loss: 0.6329039335250854, Generator loss: 0.3047274649143219\n",
      "Epoch: 25/40, Batch: 29/62, Discriminator loss: 0.5883229970932007, Generator loss: 0.3203476369380951\n",
      "Epoch: 25/40, Batch: 30/62, Discriminator loss: 0.5391910672187805, Generator loss: 0.3063265085220337\n",
      "Epoch: 25/40, Batch: 31/62, Discriminator loss: 0.5653733611106873, Generator loss: 0.2953798174858093\n",
      "Epoch: 25/40, Batch: 32/62, Discriminator loss: 0.5241522789001465, Generator loss: 0.28593364357948303\n",
      "Epoch: 25/40, Batch: 33/62, Discriminator loss: 0.4586969017982483, Generator loss: 0.2737901508808136\n",
      "Epoch: 25/40, Batch: 34/62, Discriminator loss: 0.7105174660682678, Generator loss: 0.28867143392562866\n",
      "Epoch: 25/40, Batch: 35/62, Discriminator loss: 0.48126593232154846, Generator loss: 0.2713729441165924\n",
      "Epoch: 25/40, Batch: 36/62, Discriminator loss: 0.6054392457008362, Generator loss: 0.31384333968162537\n",
      "Epoch: 25/40, Batch: 37/62, Discriminator loss: 0.467382550239563, Generator loss: 0.2978043854236603\n",
      "Epoch: 25/40, Batch: 38/62, Discriminator loss: 0.5587641596794128, Generator loss: 0.29929450154304504\n",
      "Epoch: 25/40, Batch: 39/62, Discriminator loss: 0.5243308544158936, Generator loss: 0.2817493677139282\n",
      "Epoch: 25/40, Batch: 40/62, Discriminator loss: 0.6587215662002563, Generator loss: 0.31273189187049866\n",
      "Epoch: 25/40, Batch: 41/62, Discriminator loss: 0.5973037481307983, Generator loss: 0.3066262900829315\n",
      "Epoch: 25/40, Batch: 42/62, Discriminator loss: 0.5134521126747131, Generator loss: 0.28793370723724365\n",
      "Epoch: 25/40, Batch: 43/62, Discriminator loss: 0.574874222278595, Generator loss: 0.2709626853466034\n",
      "Epoch: 25/40, Batch: 44/62, Discriminator loss: 0.4862058162689209, Generator loss: 0.2505623400211334\n",
      "Epoch: 25/40, Batch: 45/62, Discriminator loss: 0.6120126247406006, Generator loss: 0.2805923521518707\n",
      "Epoch: 25/40, Batch: 46/62, Discriminator loss: 0.5805450677871704, Generator loss: 0.25560376048088074\n",
      "Epoch: 25/40, Batch: 47/62, Discriminator loss: 0.4941857159137726, Generator loss: 0.2530656158924103\n",
      "Epoch: 25/40, Batch: 48/62, Discriminator loss: 0.6890243291854858, Generator loss: 0.27466481924057007\n",
      "Epoch: 25/40, Batch: 49/62, Discriminator loss: 0.5076121687889099, Generator loss: 0.2660830020904541\n",
      "Epoch: 25/40, Batch: 50/62, Discriminator loss: 0.5504059791564941, Generator loss: 0.26202458143234253\n",
      "Epoch: 25/40, Batch: 51/62, Discriminator loss: 0.573487401008606, Generator loss: 0.23587313294410706\n",
      "Epoch: 25/40, Batch: 52/62, Discriminator loss: 0.5043479204177856, Generator loss: 0.2505200207233429\n",
      "Epoch: 25/40, Batch: 53/62, Discriminator loss: 0.5751280784606934, Generator loss: 0.2426081895828247\n",
      "Epoch: 25/40, Batch: 54/62, Discriminator loss: 0.5370287895202637, Generator loss: 0.2506989538669586\n",
      "Epoch: 25/40, Batch: 55/62, Discriminator loss: 0.5791360139846802, Generator loss: 0.26162979006767273\n",
      "Epoch: 25/40, Batch: 56/62, Discriminator loss: 0.5196059942245483, Generator loss: 0.25066182017326355\n",
      "Epoch: 25/40, Batch: 57/62, Discriminator loss: 0.5647053718566895, Generator loss: 0.25492531061172485\n",
      "Epoch: 25/40, Batch: 58/62, Discriminator loss: 0.5535880923271179, Generator loss: 0.2594495415687561\n",
      "Epoch: 25/40, Batch: 59/62, Discriminator loss: 0.5897444486618042, Generator loss: 0.28765586018562317\n",
      "Epoch: 25/40, Batch: 60/62, Discriminator loss: 0.6114269495010376, Generator loss: 0.30771034955978394\n",
      "Epoch: 25/40, Batch: 61/62, Discriminator loss: 0.5669729709625244, Generator loss: 0.33527547121047974\n",
      "Epoch: 25/40, Batch: 62/62, Discriminator loss: 0.5076823234558105, Generator loss: 0.32660922408103943\n",
      "Accuracy real: 25%, fake: 0%\n",
      "Epoch: 26/40, Batch: 1/62, Discriminator loss: 0.7772243618965149, Generator loss: 0.35053038597106934\n",
      "Epoch: 26/40, Batch: 2/62, Discriminator loss: 0.5308555364608765, Generator loss: 0.3216976225376129\n",
      "Epoch: 26/40, Batch: 3/62, Discriminator loss: 0.4243115782737732, Generator loss: 0.29971936345100403\n",
      "Epoch: 26/40, Batch: 4/62, Discriminator loss: 0.5912140011787415, Generator loss: 0.3101308345794678\n",
      "Epoch: 26/40, Batch: 5/62, Discriminator loss: 0.5871298313140869, Generator loss: 0.3132401704788208\n",
      "Epoch: 26/40, Batch: 6/62, Discriminator loss: 0.5894145369529724, Generator loss: 0.327434241771698\n",
      "Epoch: 26/40, Batch: 7/62, Discriminator loss: 0.4659830927848816, Generator loss: 0.33033233880996704\n",
      "Epoch: 26/40, Batch: 8/62, Discriminator loss: 0.4692964255809784, Generator loss: 0.30168282985687256\n",
      "Epoch: 26/40, Batch: 9/62, Discriminator loss: 0.5625675320625305, Generator loss: 0.3053298592567444\n",
      "Epoch: 26/40, Batch: 10/62, Discriminator loss: 0.5497390031814575, Generator loss: 0.3004423677921295\n",
      "Epoch: 26/40, Batch: 11/62, Discriminator loss: 0.5744465589523315, Generator loss: 0.33837881684303284\n",
      "Epoch: 26/40, Batch: 12/62, Discriminator loss: 0.4246664047241211, Generator loss: 0.3005998134613037\n",
      "Epoch: 26/40, Batch: 13/62, Discriminator loss: 0.5706747174263, Generator loss: 0.30059826374053955\n",
      "Epoch: 26/40, Batch: 14/62, Discriminator loss: 0.5488095283508301, Generator loss: 0.277388334274292\n",
      "Epoch: 26/40, Batch: 15/62, Discriminator loss: 0.5142719149589539, Generator loss: 0.2805216908454895\n",
      "Epoch: 26/40, Batch: 16/62, Discriminator loss: 0.41833633184432983, Generator loss: 0.25203999876976013\n",
      "Epoch: 26/40, Batch: 17/62, Discriminator loss: 0.5889976620674133, Generator loss: 0.23492033779621124\n",
      "Epoch: 26/40, Batch: 18/62, Discriminator loss: 0.5462743639945984, Generator loss: 0.25010836124420166\n",
      "Epoch: 26/40, Batch: 19/62, Discriminator loss: 0.5426738262176514, Generator loss: 0.26076066493988037\n",
      "Epoch: 26/40, Batch: 20/62, Discriminator loss: 0.5976346135139465, Generator loss: 0.25829094648361206\n",
      "Epoch: 26/40, Batch: 21/62, Discriminator loss: 0.550817608833313, Generator loss: 0.25888004899024963\n",
      "Epoch: 26/40, Batch: 22/62, Discriminator loss: 0.5873359441757202, Generator loss: 0.3005078136920929\n",
      "Epoch: 26/40, Batch: 23/62, Discriminator loss: 0.4925379753112793, Generator loss: 0.31166762113571167\n",
      "Epoch: 26/40, Batch: 24/62, Discriminator loss: 0.4205361008644104, Generator loss: 0.28745871782302856\n",
      "Epoch: 26/40, Batch: 25/62, Discriminator loss: 0.6723542213439941, Generator loss: 0.295823872089386\n",
      "Epoch: 26/40, Batch: 26/62, Discriminator loss: 0.5508559942245483, Generator loss: 0.32475534081459045\n",
      "Epoch: 26/40, Batch: 27/62, Discriminator loss: 0.5891948938369751, Generator loss: 0.3258240222930908\n",
      "Epoch: 26/40, Batch: 28/62, Discriminator loss: 0.5969909429550171, Generator loss: 0.35684826970100403\n",
      "Epoch: 26/40, Batch: 29/62, Discriminator loss: 0.5742372274398804, Generator loss: 0.3696516156196594\n",
      "Epoch: 26/40, Batch: 30/62, Discriminator loss: 0.5069655776023865, Generator loss: 0.3530657887458801\n",
      "Epoch: 26/40, Batch: 31/62, Discriminator loss: 0.5351612567901611, Generator loss: 0.3399921953678131\n",
      "Epoch: 26/40, Batch: 32/62, Discriminator loss: 0.5608493089675903, Generator loss: 0.34552696347236633\n",
      "Epoch: 26/40, Batch: 33/62, Discriminator loss: 0.46370434761047363, Generator loss: 0.31547611951828003\n",
      "Epoch: 26/40, Batch: 34/62, Discriminator loss: 0.6600979566574097, Generator loss: 0.34056127071380615\n",
      "Epoch: 26/40, Batch: 35/62, Discriminator loss: 0.5673067569732666, Generator loss: 0.33836936950683594\n",
      "Epoch: 26/40, Batch: 36/62, Discriminator loss: 0.6127560138702393, Generator loss: 0.3647482991218567\n",
      "Epoch: 26/40, Batch: 37/62, Discriminator loss: 0.5343132019042969, Generator loss: 0.34603333473205566\n",
      "Epoch: 26/40, Batch: 38/62, Discriminator loss: 0.5364598035812378, Generator loss: 0.337952584028244\n",
      "Epoch: 26/40, Batch: 39/62, Discriminator loss: 0.5092105865478516, Generator loss: 0.33186307549476624\n",
      "Epoch: 26/40, Batch: 40/62, Discriminator loss: 0.6347984075546265, Generator loss: 0.34471166133880615\n",
      "Epoch: 26/40, Batch: 41/62, Discriminator loss: 0.6434489488601685, Generator loss: 0.36214035749435425\n",
      "Epoch: 26/40, Batch: 42/62, Discriminator loss: 0.5386501550674438, Generator loss: 0.324852854013443\n",
      "Epoch: 26/40, Batch: 43/62, Discriminator loss: 0.5861666202545166, Generator loss: 0.3103008270263672\n",
      "Epoch: 26/40, Batch: 44/62, Discriminator loss: 0.5535696744918823, Generator loss: 0.2973794639110565\n",
      "Epoch: 26/40, Batch: 45/62, Discriminator loss: 0.6256735324859619, Generator loss: 0.296698659658432\n",
      "Epoch: 26/40, Batch: 46/62, Discriminator loss: 0.5847477912902832, Generator loss: 0.2979082465171814\n",
      "Epoch: 26/40, Batch: 47/62, Discriminator loss: 0.5488075017929077, Generator loss: 0.3114392161369324\n",
      "Epoch: 26/40, Batch: 48/62, Discriminator loss: 0.6323128938674927, Generator loss: 0.32164523005485535\n",
      "Epoch: 26/40, Batch: 49/62, Discriminator loss: 0.5342444181442261, Generator loss: 0.3215320110321045\n",
      "Epoch: 26/40, Batch: 50/62, Discriminator loss: 0.510589599609375, Generator loss: 0.3250139355659485\n",
      "Epoch: 26/40, Batch: 51/62, Discriminator loss: 0.5824114680290222, Generator loss: 0.31999149918556213\n",
      "Epoch: 26/40, Batch: 52/62, Discriminator loss: 0.4835265874862671, Generator loss: 0.3058522641658783\n",
      "Epoch: 26/40, Batch: 53/62, Discriminator loss: 0.5669716596603394, Generator loss: 0.3072088956832886\n",
      "Epoch: 26/40, Batch: 54/62, Discriminator loss: 0.5275101661682129, Generator loss: 0.3160244822502136\n",
      "Epoch: 26/40, Batch: 55/62, Discriminator loss: 0.5687482357025146, Generator loss: 0.2953464686870575\n",
      "Epoch: 26/40, Batch: 56/62, Discriminator loss: 0.5786235332489014, Generator loss: 0.29033875465393066\n",
      "Epoch: 26/40, Batch: 57/62, Discriminator loss: 0.538729190826416, Generator loss: 0.2924739122390747\n",
      "Epoch: 26/40, Batch: 58/62, Discriminator loss: 0.617609977722168, Generator loss: 0.29134121537208557\n",
      "Epoch: 26/40, Batch: 59/62, Discriminator loss: 0.620374321937561, Generator loss: 0.30439820885658264\n",
      "Epoch: 26/40, Batch: 60/62, Discriminator loss: 0.6489150524139404, Generator loss: 0.330852746963501\n",
      "Epoch: 26/40, Batch: 61/62, Discriminator loss: 0.6193830966949463, Generator loss: 0.3637792766094208\n",
      "Epoch: 26/40, Batch: 62/62, Discriminator loss: 0.5361467599868774, Generator loss: 0.36641594767570496\n",
      "Epoch: 27/40, Batch: 1/62, Discriminator loss: 0.5448774099349976, Generator loss: 0.3799278438091278\n",
      "Epoch: 27/40, Batch: 2/62, Discriminator loss: 0.5502272844314575, Generator loss: 0.3681924343109131\n",
      "Epoch: 27/40, Batch: 3/62, Discriminator loss: 0.40107542276382446, Generator loss: 0.3256279230117798\n",
      "Epoch: 27/40, Batch: 4/62, Discriminator loss: 0.6014653444290161, Generator loss: 0.3452673852443695\n",
      "Epoch: 27/40, Batch: 5/62, Discriminator loss: 0.5483242273330688, Generator loss: 0.3459185063838959\n",
      "Epoch: 27/40, Batch: 6/62, Discriminator loss: 0.5431883335113525, Generator loss: 0.3550276458263397\n",
      "Epoch: 27/40, Batch: 7/62, Discriminator loss: 0.5037718415260315, Generator loss: 0.3401896059513092\n",
      "Epoch: 27/40, Batch: 8/62, Discriminator loss: 0.4679737091064453, Generator loss: 0.35006290674209595\n",
      "Epoch: 27/40, Batch: 9/62, Discriminator loss: 0.5304892063140869, Generator loss: 0.31263279914855957\n",
      "Epoch: 27/40, Batch: 10/62, Discriminator loss: 0.5567260980606079, Generator loss: 0.2996116280555725\n",
      "Epoch: 27/40, Batch: 11/62, Discriminator loss: 0.5931613445281982, Generator loss: 0.3033283054828644\n",
      "Epoch: 27/40, Batch: 12/62, Discriminator loss: 0.49383819103240967, Generator loss: 0.3022039532661438\n",
      "Epoch: 27/40, Batch: 13/62, Discriminator loss: 0.61473548412323, Generator loss: 0.2748933732509613\n",
      "Epoch: 27/40, Batch: 14/62, Discriminator loss: 0.582785964012146, Generator loss: 0.3065560758113861\n",
      "Epoch: 27/40, Batch: 15/62, Discriminator loss: 0.5127131342887878, Generator loss: 0.2808816432952881\n",
      "Epoch: 27/40, Batch: 16/62, Discriminator loss: 0.40722623467445374, Generator loss: 0.2903711199760437\n",
      "Epoch: 27/40, Batch: 17/62, Discriminator loss: 0.5409858226776123, Generator loss: 0.2902185916900635\n",
      "Epoch: 27/40, Batch: 18/62, Discriminator loss: 0.5445860028266907, Generator loss: 0.30987271666526794\n",
      "Epoch: 27/40, Batch: 19/62, Discriminator loss: 0.4964725375175476, Generator loss: 0.28460216522216797\n",
      "Epoch: 27/40, Batch: 20/62, Discriminator loss: 0.5564569234848022, Generator loss: 0.2852087914943695\n",
      "Epoch: 27/40, Batch: 21/62, Discriminator loss: 0.48967957496643066, Generator loss: 0.27273404598236084\n",
      "Epoch: 27/40, Batch: 22/62, Discriminator loss: 0.5825523138046265, Generator loss: 0.2785068154335022\n",
      "Epoch: 27/40, Batch: 23/62, Discriminator loss: 0.5475192666053772, Generator loss: 0.2704014182090759\n",
      "Epoch: 27/40, Batch: 24/62, Discriminator loss: 0.406850665807724, Generator loss: 0.25280335545539856\n",
      "Epoch: 27/40, Batch: 25/62, Discriminator loss: 0.6574637293815613, Generator loss: 0.2712261974811554\n",
      "Epoch: 27/40, Batch: 26/62, Discriminator loss: 0.6113153100013733, Generator loss: 0.25809332728385925\n",
      "Epoch: 27/40, Batch: 27/62, Discriminator loss: 0.5823519229888916, Generator loss: 0.28348854184150696\n",
      "Epoch: 27/40, Batch: 28/62, Discriminator loss: 0.6363798379898071, Generator loss: 0.2960219979286194\n",
      "Epoch: 27/40, Batch: 29/62, Discriminator loss: 0.5635400414466858, Generator loss: 0.3038305938243866\n",
      "Epoch: 27/40, Batch: 30/62, Discriminator loss: 0.5175759792327881, Generator loss: 0.3186953663825989\n",
      "Epoch: 27/40, Batch: 31/62, Discriminator loss: 0.5332603454589844, Generator loss: 0.32728418707847595\n",
      "Epoch: 27/40, Batch: 32/62, Discriminator loss: 0.535800576210022, Generator loss: 0.3278518617153168\n",
      "Epoch: 27/40, Batch: 33/62, Discriminator loss: 0.4529920220375061, Generator loss: 0.29200321435928345\n",
      "Epoch: 27/40, Batch: 34/62, Discriminator loss: 0.6004213094711304, Generator loss: 0.3020169734954834\n",
      "Epoch: 27/40, Batch: 35/62, Discriminator loss: 0.5035538673400879, Generator loss: 0.3131696581840515\n",
      "Epoch: 27/40, Batch: 36/62, Discriminator loss: 0.601412296295166, Generator loss: 0.33550411462783813\n",
      "Epoch: 27/40, Batch: 37/62, Discriminator loss: 0.5025748610496521, Generator loss: 0.30472323298454285\n",
      "Epoch: 27/40, Batch: 38/62, Discriminator loss: 0.49483150243759155, Generator loss: 0.32084184885025024\n",
      "Epoch: 27/40, Batch: 39/62, Discriminator loss: 0.5044839382171631, Generator loss: 0.29865506291389465\n",
      "Epoch: 27/40, Batch: 40/62, Discriminator loss: 0.6134637594223022, Generator loss: 0.30686667561531067\n",
      "Epoch: 27/40, Batch: 41/62, Discriminator loss: 0.5743404626846313, Generator loss: 0.2972103953361511\n",
      "Epoch: 27/40, Batch: 42/62, Discriminator loss: 0.5098742246627808, Generator loss: 0.2864021062850952\n",
      "Epoch: 27/40, Batch: 43/62, Discriminator loss: 0.5787014961242676, Generator loss: 0.28707072138786316\n",
      "Epoch: 27/40, Batch: 44/62, Discriminator loss: 0.5072622299194336, Generator loss: 0.2770383954048157\n",
      "Epoch: 27/40, Batch: 45/62, Discriminator loss: 0.6068125367164612, Generator loss: 0.2742074429988861\n",
      "Epoch: 27/40, Batch: 46/62, Discriminator loss: 0.5659369230270386, Generator loss: 0.27232447266578674\n",
      "Epoch: 27/40, Batch: 47/62, Discriminator loss: 0.5460222959518433, Generator loss: 0.2805483341217041\n",
      "Epoch: 27/40, Batch: 48/62, Discriminator loss: 0.6222158670425415, Generator loss: 0.30051517486572266\n",
      "Epoch: 27/40, Batch: 49/62, Discriminator loss: 0.47664323449134827, Generator loss: 0.29551124572753906\n",
      "Epoch: 27/40, Batch: 50/62, Discriminator loss: 0.5365391969680786, Generator loss: 0.29243168234825134\n",
      "Epoch: 27/40, Batch: 51/62, Discriminator loss: 0.5420796871185303, Generator loss: 0.2848465144634247\n",
      "Epoch: 27/40, Batch: 52/62, Discriminator loss: 0.4563974440097809, Generator loss: 0.27867451310157776\n",
      "Epoch: 27/40, Batch: 53/62, Discriminator loss: 0.5450406074523926, Generator loss: 0.27205437421798706\n",
      "Epoch: 27/40, Batch: 54/62, Discriminator loss: 0.5009379386901855, Generator loss: 0.2749083638191223\n",
      "Epoch: 27/40, Batch: 55/62, Discriminator loss: 0.5394660830497742, Generator loss: 0.2725572884082794\n",
      "Epoch: 27/40, Batch: 56/62, Discriminator loss: 0.5172333717346191, Generator loss: 0.26681190729141235\n",
      "Epoch: 27/40, Batch: 57/62, Discriminator loss: 0.5089995861053467, Generator loss: 0.2626475989818573\n",
      "Epoch: 27/40, Batch: 58/62, Discriminator loss: 0.5905916690826416, Generator loss: 0.26836687326431274\n",
      "Epoch: 27/40, Batch: 59/62, Discriminator loss: 0.6110674142837524, Generator loss: 0.28853705525398254\n",
      "Epoch: 27/40, Batch: 60/62, Discriminator loss: 0.6507354378700256, Generator loss: 0.3020398020744324\n",
      "Epoch: 27/40, Batch: 61/62, Discriminator loss: 0.5957068204879761, Generator loss: 0.33240941166877747\n",
      "Epoch: 27/40, Batch: 62/62, Discriminator loss: 0.5098186731338501, Generator loss: 0.34177833795547485\n",
      "Epoch: 28/40, Batch: 1/62, Discriminator loss: 0.5501629114151001, Generator loss: 0.3534131944179535\n",
      "Epoch: 28/40, Batch: 2/62, Discriminator loss: 0.5648979544639587, Generator loss: 0.35241854190826416\n",
      "Epoch: 28/40, Batch: 3/62, Discriminator loss: 0.44075316190719604, Generator loss: 0.31828388571739197\n",
      "Epoch: 28/40, Batch: 4/62, Discriminator loss: 0.5755399465560913, Generator loss: 0.33162829279899597\n",
      "Epoch: 28/40, Batch: 5/62, Discriminator loss: 0.5858832597732544, Generator loss: 0.33205410838127136\n",
      "Epoch: 28/40, Batch: 6/62, Discriminator loss: 0.5778831243515015, Generator loss: 0.3286779820919037\n",
      "Epoch: 28/40, Batch: 7/62, Discriminator loss: 0.5331956744194031, Generator loss: 0.31807535886764526\n",
      "Epoch: 28/40, Batch: 8/62, Discriminator loss: 0.47031015157699585, Generator loss: 0.30374059081077576\n",
      "Epoch: 28/40, Batch: 9/62, Discriminator loss: 0.5587071180343628, Generator loss: 0.2888790965080261\n",
      "Epoch: 28/40, Batch: 10/62, Discriminator loss: 0.5752013325691223, Generator loss: 0.3023778200149536\n",
      "Epoch: 28/40, Batch: 11/62, Discriminator loss: 0.6153870224952698, Generator loss: 0.29545077681541443\n",
      "Epoch: 28/40, Batch: 12/62, Discriminator loss: 0.4598561227321625, Generator loss: 0.2623525559902191\n",
      "Epoch: 28/40, Batch: 13/62, Discriminator loss: 0.6013166904449463, Generator loss: 0.2540740668773651\n",
      "Epoch: 28/40, Batch: 14/62, Discriminator loss: 0.5977705121040344, Generator loss: 0.2580083906650543\n",
      "Epoch: 28/40, Batch: 15/62, Discriminator loss: 0.5577064752578735, Generator loss: 0.2565886974334717\n",
      "Epoch: 28/40, Batch: 16/62, Discriminator loss: 0.4351307153701782, Generator loss: 0.2276841402053833\n",
      "Epoch: 28/40, Batch: 17/62, Discriminator loss: 0.6403719186782837, Generator loss: 0.22107741236686707\n",
      "Epoch: 28/40, Batch: 18/62, Discriminator loss: 0.5969812273979187, Generator loss: 0.23805133998394012\n",
      "Epoch: 28/40, Batch: 19/62, Discriminator loss: 0.540262758731842, Generator loss: 0.2368638664484024\n",
      "Epoch: 28/40, Batch: 20/62, Discriminator loss: 0.5895336866378784, Generator loss: 0.2521378695964813\n",
      "Epoch: 28/40, Batch: 21/62, Discriminator loss: 0.5556784868240356, Generator loss: 0.24374531209468842\n",
      "Epoch: 28/40, Batch: 22/62, Discriminator loss: 0.6261314153671265, Generator loss: 0.24806852638721466\n",
      "Epoch: 28/40, Batch: 23/62, Discriminator loss: 0.5612947940826416, Generator loss: 0.2755853533744812\n",
      "Epoch: 28/40, Batch: 24/62, Discriminator loss: 0.39984458684921265, Generator loss: 0.2564724385738373\n",
      "Epoch: 28/40, Batch: 25/62, Discriminator loss: 0.6847322583198547, Generator loss: 0.27490314841270447\n",
      "Epoch: 28/40, Batch: 26/62, Discriminator loss: 0.5998529195785522, Generator loss: 0.2888490557670593\n",
      "Epoch: 28/40, Batch: 27/62, Discriminator loss: 0.5805588364601135, Generator loss: 0.2919134199619293\n",
      "Epoch: 28/40, Batch: 28/62, Discriminator loss: 0.6385645270347595, Generator loss: 0.3134874105453491\n",
      "Epoch: 28/40, Batch: 29/62, Discriminator loss: 0.5675734281539917, Generator loss: 0.3007127642631531\n",
      "Epoch: 28/40, Batch: 30/62, Discriminator loss: 0.5215749740600586, Generator loss: 0.29627346992492676\n",
      "Epoch: 28/40, Batch: 31/62, Discriminator loss: 0.5348788499832153, Generator loss: 0.2897094786167145\n",
      "Epoch: 28/40, Batch: 32/62, Discriminator loss: 0.5494585633277893, Generator loss: 0.3078305721282959\n",
      "Epoch: 28/40, Batch: 33/62, Discriminator loss: 0.4549603760242462, Generator loss: 0.2804952561855316\n",
      "Epoch: 28/40, Batch: 34/62, Discriminator loss: 0.6778249740600586, Generator loss: 0.30095043778419495\n",
      "Epoch: 28/40, Batch: 35/62, Discriminator loss: 0.5196419358253479, Generator loss: 0.2893572151660919\n",
      "Epoch: 28/40, Batch: 36/62, Discriminator loss: 0.5761091113090515, Generator loss: 0.3249746859073639\n",
      "Epoch: 28/40, Batch: 37/62, Discriminator loss: 0.5285239219665527, Generator loss: 0.31342220306396484\n",
      "Epoch: 28/40, Batch: 38/62, Discriminator loss: 0.5222779512405396, Generator loss: 0.3122957944869995\n",
      "Epoch: 28/40, Batch: 39/62, Discriminator loss: 0.5147950649261475, Generator loss: 0.29580995440483093\n",
      "Epoch: 28/40, Batch: 40/62, Discriminator loss: 0.6282252073287964, Generator loss: 0.32107827067375183\n",
      "Epoch: 28/40, Batch: 41/62, Discriminator loss: 0.555090069770813, Generator loss: 0.31923356652259827\n",
      "Epoch: 28/40, Batch: 42/62, Discriminator loss: 0.50967937707901, Generator loss: 0.3195933699607849\n",
      "Epoch: 28/40, Batch: 43/62, Discriminator loss: 0.5662806034088135, Generator loss: 0.30925610661506653\n",
      "Epoch: 28/40, Batch: 44/62, Discriminator loss: 0.5322814583778381, Generator loss: 0.2968887686729431\n",
      "Epoch: 28/40, Batch: 45/62, Discriminator loss: 0.5726487636566162, Generator loss: 0.304670512676239\n",
      "Epoch: 28/40, Batch: 46/62, Discriminator loss: 0.5724669694900513, Generator loss: 0.30353718996047974\n",
      "Epoch: 28/40, Batch: 47/62, Discriminator loss: 0.523368239402771, Generator loss: 0.302593857049942\n",
      "Epoch: 28/40, Batch: 48/62, Discriminator loss: 0.6336933970451355, Generator loss: 0.3188716471195221\n",
      "Epoch: 28/40, Batch: 49/62, Discriminator loss: 0.5453445911407471, Generator loss: 0.2916342318058014\n",
      "Epoch: 28/40, Batch: 50/62, Discriminator loss: 0.5500797033309937, Generator loss: 0.3021862208843231\n",
      "Epoch: 28/40, Batch: 51/62, Discriminator loss: 0.6219000816345215, Generator loss: 0.30392518639564514\n",
      "Epoch: 28/40, Batch: 52/62, Discriminator loss: 0.5221516489982605, Generator loss: 0.2967841923236847\n",
      "Epoch: 28/40, Batch: 53/62, Discriminator loss: 0.6010480523109436, Generator loss: 0.31238681077957153\n",
      "Epoch: 28/40, Batch: 54/62, Discriminator loss: 0.5310291647911072, Generator loss: 0.3184284567832947\n",
      "Epoch: 28/40, Batch: 55/62, Discriminator loss: 0.5882699489593506, Generator loss: 0.32205286622047424\n",
      "Epoch: 28/40, Batch: 56/62, Discriminator loss: 0.552092432975769, Generator loss: 0.3303326666355133\n",
      "Epoch: 28/40, Batch: 57/62, Discriminator loss: 0.539190411567688, Generator loss: 0.3308086395263672\n",
      "Epoch: 28/40, Batch: 58/62, Discriminator loss: 0.5861986875534058, Generator loss: 0.3239346146583557\n",
      "Epoch: 28/40, Batch: 59/62, Discriminator loss: 0.5724689960479736, Generator loss: 0.33287927508354187\n",
      "Epoch: 28/40, Batch: 60/62, Discriminator loss: 0.6020926237106323, Generator loss: 0.33174246549606323\n",
      "Epoch: 28/40, Batch: 61/62, Discriminator loss: 0.5733895897865295, Generator loss: 0.34473946690559387\n",
      "Epoch: 28/40, Batch: 62/62, Discriminator loss: 0.5172843933105469, Generator loss: 0.3292680084705353\n",
      "Epoch: 29/40, Batch: 1/62, Discriminator loss: 0.5426545143127441, Generator loss: 0.3114548325538635\n",
      "Epoch: 29/40, Batch: 2/62, Discriminator loss: 0.590964674949646, Generator loss: 0.32702815532684326\n",
      "Epoch: 29/40, Batch: 3/62, Discriminator loss: 0.4598834216594696, Generator loss: 0.2928675711154938\n",
      "Epoch: 29/40, Batch: 4/62, Discriminator loss: 0.6344957947731018, Generator loss: 0.2932412624359131\n",
      "Epoch: 29/40, Batch: 5/62, Discriminator loss: 0.5881798267364502, Generator loss: 0.29098638892173767\n",
      "Epoch: 29/40, Batch: 6/62, Discriminator loss: 0.5748745799064636, Generator loss: 0.3001388907432556\n",
      "Epoch: 29/40, Batch: 7/62, Discriminator loss: 0.5379307866096497, Generator loss: 0.30079227685928345\n",
      "Epoch: 29/40, Batch: 8/62, Discriminator loss: 0.5125956535339355, Generator loss: 0.2914631962776184\n",
      "Epoch: 29/40, Batch: 9/62, Discriminator loss: 0.5851794481277466, Generator loss: 0.2972491383552551\n",
      "Epoch: 29/40, Batch: 10/62, Discriminator loss: 0.5708984136581421, Generator loss: 0.30326762795448303\n",
      "Epoch: 29/40, Batch: 11/62, Discriminator loss: 0.605838418006897, Generator loss: 0.3053418695926666\n",
      "Epoch: 29/40, Batch: 12/62, Discriminator loss: 0.449067085981369, Generator loss: 0.2863631546497345\n",
      "Epoch: 29/40, Batch: 13/62, Discriminator loss: 0.58476722240448, Generator loss: 0.2966149151325226\n",
      "Epoch: 29/40, Batch: 14/62, Discriminator loss: 0.5351698994636536, Generator loss: 0.28834259510040283\n",
      "Epoch: 29/40, Batch: 15/62, Discriminator loss: 0.5537223815917969, Generator loss: 0.286663293838501\n",
      "Epoch: 29/40, Batch: 16/62, Discriminator loss: 0.43286940455436707, Generator loss: 0.2672668695449829\n",
      "Epoch: 29/40, Batch: 17/62, Discriminator loss: 0.5747836232185364, Generator loss: 0.26694291830062866\n",
      "Epoch: 29/40, Batch: 18/62, Discriminator loss: 0.5662286877632141, Generator loss: 0.2794709801673889\n",
      "Epoch: 29/40, Batch: 19/62, Discriminator loss: 0.5358605980873108, Generator loss: 0.2715875506401062\n",
      "Epoch: 29/40, Batch: 20/62, Discriminator loss: 0.6222441792488098, Generator loss: 0.285944402217865\n",
      "Epoch: 29/40, Batch: 21/62, Discriminator loss: 0.572155237197876, Generator loss: 0.2742882966995239\n",
      "Epoch: 29/40, Batch: 22/62, Discriminator loss: 0.6147995591163635, Generator loss: 0.29989853501319885\n",
      "Epoch: 29/40, Batch: 23/62, Discriminator loss: 0.568496584892273, Generator loss: 0.30948951840400696\n",
      "Epoch: 29/40, Batch: 24/62, Discriminator loss: 0.4448031783103943, Generator loss: 0.29804399609565735\n",
      "Epoch: 29/40, Batch: 25/62, Discriminator loss: 0.6694226264953613, Generator loss: 0.31264492869377136\n",
      "Epoch: 29/40, Batch: 26/62, Discriminator loss: 0.5901577472686768, Generator loss: 0.3313242495059967\n",
      "Epoch: 29/40, Batch: 27/62, Discriminator loss: 0.5528297424316406, Generator loss: 0.3383563160896301\n",
      "Epoch: 29/40, Batch: 28/62, Discriminator loss: 0.608952522277832, Generator loss: 0.341450572013855\n",
      "Epoch: 29/40, Batch: 29/62, Discriminator loss: 0.540978729724884, Generator loss: 0.340040385723114\n",
      "Epoch: 29/40, Batch: 30/62, Discriminator loss: 0.4853573441505432, Generator loss: 0.33897972106933594\n",
      "Epoch: 29/40, Batch: 31/62, Discriminator loss: 0.5174949169158936, Generator loss: 0.32820332050323486\n",
      "Epoch: 29/40, Batch: 32/62, Discriminator loss: 0.5712603330612183, Generator loss: 0.31557705998420715\n",
      "Epoch: 29/40, Batch: 33/62, Discriminator loss: 0.4280354380607605, Generator loss: 0.30369919538497925\n",
      "Epoch: 29/40, Batch: 34/62, Discriminator loss: 0.6743108034133911, Generator loss: 0.30201461911201477\n",
      "Epoch: 29/40, Batch: 35/62, Discriminator loss: 0.5220599174499512, Generator loss: 0.2982748746871948\n",
      "Epoch: 29/40, Batch: 36/62, Discriminator loss: 0.627265214920044, Generator loss: 0.29595786333084106\n",
      "Epoch: 29/40, Batch: 37/62, Discriminator loss: 0.5527536869049072, Generator loss: 0.3031822443008423\n",
      "Epoch: 29/40, Batch: 38/62, Discriminator loss: 0.5379840135574341, Generator loss: 0.2949832081794739\n",
      "Epoch: 29/40, Batch: 39/62, Discriminator loss: 0.5456546545028687, Generator loss: 0.2918010354042053\n",
      "Epoch: 29/40, Batch: 40/62, Discriminator loss: 0.6766499876976013, Generator loss: 0.2896571457386017\n",
      "Epoch: 29/40, Batch: 41/62, Discriminator loss: 0.6201510429382324, Generator loss: 0.3104107081890106\n",
      "Epoch: 29/40, Batch: 42/62, Discriminator loss: 0.5364869236946106, Generator loss: 0.3057384490966797\n",
      "Epoch: 29/40, Batch: 43/62, Discriminator loss: 0.597332775592804, Generator loss: 0.31013545393943787\n",
      "Epoch: 29/40, Batch: 44/62, Discriminator loss: 0.5247812271118164, Generator loss: 0.2955053448677063\n",
      "Epoch: 29/40, Batch: 45/62, Discriminator loss: 0.6018089652061462, Generator loss: 0.302185595035553\n",
      "Epoch: 29/40, Batch: 46/62, Discriminator loss: 0.5587375164031982, Generator loss: 0.29277893900871277\n",
      "Epoch: 29/40, Batch: 47/62, Discriminator loss: 0.5511122345924377, Generator loss: 0.2742465138435364\n",
      "Epoch: 29/40, Batch: 48/62, Discriminator loss: 0.6381387114524841, Generator loss: 0.28495654463768005\n",
      "Epoch: 29/40, Batch: 49/62, Discriminator loss: 0.5420045852661133, Generator loss: 0.25976526737213135\n",
      "Epoch: 29/40, Batch: 50/62, Discriminator loss: 0.5502380132675171, Generator loss: 0.27065742015838623\n",
      "Epoch: 29/40, Batch: 51/62, Discriminator loss: 0.6165374517440796, Generator loss: 0.27050289511680603\n",
      "Epoch: 29/40, Batch: 52/62, Discriminator loss: 0.5003219842910767, Generator loss: 0.25642073154449463\n",
      "Epoch: 29/40, Batch: 53/62, Discriminator loss: 0.6292681097984314, Generator loss: 0.262228786945343\n",
      "Epoch: 29/40, Batch: 54/62, Discriminator loss: 0.562065601348877, Generator loss: 0.26192036271095276\n",
      "Epoch: 29/40, Batch: 55/62, Discriminator loss: 0.604722261428833, Generator loss: 0.2652455270290375\n",
      "Epoch: 29/40, Batch: 56/62, Discriminator loss: 0.5454769134521484, Generator loss: 0.2757119834423065\n",
      "Epoch: 29/40, Batch: 57/62, Discriminator loss: 0.535332441329956, Generator loss: 0.2822151184082031\n",
      "Epoch: 29/40, Batch: 58/62, Discriminator loss: 0.5959873199462891, Generator loss: 0.2945559024810791\n",
      "Epoch: 29/40, Batch: 59/62, Discriminator loss: 0.5538884401321411, Generator loss: 0.2888163626194\n",
      "Epoch: 29/40, Batch: 60/62, Discriminator loss: 0.586435079574585, Generator loss: 0.3093191683292389\n",
      "Epoch: 29/40, Batch: 61/62, Discriminator loss: 0.5422255396842957, Generator loss: 0.32687142491340637\n",
      "Epoch: 29/40, Batch: 62/62, Discriminator loss: 0.4446377754211426, Generator loss: 0.3169780969619751\n",
      "Epoch: 30/40, Batch: 1/62, Discriminator loss: 0.5050087571144104, Generator loss: 0.311626672744751\n",
      "Epoch: 30/40, Batch: 2/62, Discriminator loss: 0.5356431603431702, Generator loss: 0.291489839553833\n",
      "Epoch: 30/40, Batch: 3/62, Discriminator loss: 0.3876151442527771, Generator loss: 0.2735612988471985\n",
      "Epoch: 30/40, Batch: 4/62, Discriminator loss: 0.6096941232681274, Generator loss: 0.26027414202690125\n",
      "Epoch: 30/40, Batch: 5/62, Discriminator loss: 0.6013520956039429, Generator loss: 0.2500177323818207\n",
      "Epoch: 30/40, Batch: 6/62, Discriminator loss: 0.5793828964233398, Generator loss: 0.2561388313770294\n",
      "Epoch: 30/40, Batch: 7/62, Discriminator loss: 0.5298984050750732, Generator loss: 0.25362101197242737\n",
      "Epoch: 30/40, Batch: 8/62, Discriminator loss: 0.5244666337966919, Generator loss: 0.26988551020622253\n",
      "Epoch: 30/40, Batch: 9/62, Discriminator loss: 0.5899111032485962, Generator loss: 0.27528372406959534\n",
      "Epoch: 30/40, Batch: 10/62, Discriminator loss: 0.5748871564865112, Generator loss: 0.2870210111141205\n",
      "Epoch: 30/40, Batch: 11/62, Discriminator loss: 0.607813835144043, Generator loss: 0.30246272683143616\n",
      "Epoch: 30/40, Batch: 12/62, Discriminator loss: 0.42438703775405884, Generator loss: 0.31582316756248474\n",
      "Epoch: 30/40, Batch: 13/62, Discriminator loss: 0.5472331047058105, Generator loss: 0.3294471502304077\n",
      "Epoch: 30/40, Batch: 14/62, Discriminator loss: 0.4835185408592224, Generator loss: 0.3376712501049042\n",
      "Epoch: 30/40, Batch: 15/62, Discriminator loss: 0.4694707691669464, Generator loss: 0.33148425817489624\n",
      "Epoch: 30/40, Batch: 16/62, Discriminator loss: 0.3520395755767822, Generator loss: 0.32999178767204285\n",
      "Epoch: 30/40, Batch: 17/62, Discriminator loss: 0.5249067544937134, Generator loss: 0.33004334568977356\n",
      "Epoch: 30/40, Batch: 18/62, Discriminator loss: 0.5077146887779236, Generator loss: 0.3366102874279022\n",
      "Epoch: 30/40, Batch: 19/62, Discriminator loss: 0.4775713086128235, Generator loss: 0.3337213695049286\n",
      "Epoch: 30/40, Batch: 20/62, Discriminator loss: 0.5354825258255005, Generator loss: 0.338065505027771\n",
      "Epoch: 30/40, Batch: 21/62, Discriminator loss: 0.5327116250991821, Generator loss: 0.31193599104881287\n",
      "Epoch: 30/40, Batch: 22/62, Discriminator loss: 0.627164363861084, Generator loss: 0.3218725919723511\n",
      "Epoch: 30/40, Batch: 23/62, Discriminator loss: 0.5277622938156128, Generator loss: 0.30332738161087036\n",
      "Epoch: 30/40, Batch: 24/62, Discriminator loss: 0.4476715326309204, Generator loss: 0.2752419710159302\n",
      "Epoch: 30/40, Batch: 25/62, Discriminator loss: 0.7299092411994934, Generator loss: 0.28501349687576294\n",
      "Epoch: 30/40, Batch: 26/62, Discriminator loss: 0.6033496260643005, Generator loss: 0.2952987849712372\n",
      "Epoch: 30/40, Batch: 27/62, Discriminator loss: 0.5906453132629395, Generator loss: 0.2974509000778198\n",
      "Epoch: 30/40, Batch: 28/62, Discriminator loss: 0.6243776679039001, Generator loss: 0.31728339195251465\n",
      "Epoch: 30/40, Batch: 29/62, Discriminator loss: 0.6034445762634277, Generator loss: 0.3108420968055725\n",
      "Epoch: 30/40, Batch: 30/62, Discriminator loss: 0.47936877608299255, Generator loss: 0.31392958760261536\n",
      "Epoch: 30/40, Batch: 31/62, Discriminator loss: 0.5263611674308777, Generator loss: 0.2883431017398834\n",
      "Epoch: 30/40, Batch: 32/62, Discriminator loss: 0.5170873403549194, Generator loss: 0.29932525753974915\n",
      "Epoch: 30/40, Batch: 33/62, Discriminator loss: 0.4381021559238434, Generator loss: 0.27947402000427246\n",
      "Epoch: 30/40, Batch: 34/62, Discriminator loss: 0.6612727642059326, Generator loss: 0.29036566615104675\n",
      "Epoch: 30/40, Batch: 35/62, Discriminator loss: 0.5073676705360413, Generator loss: 0.27761077880859375\n",
      "Epoch: 30/40, Batch: 36/62, Discriminator loss: 0.6282793283462524, Generator loss: 0.2720668315887451\n",
      "Epoch: 30/40, Batch: 37/62, Discriminator loss: 0.4993285536766052, Generator loss: 0.2567608058452606\n",
      "Epoch: 30/40, Batch: 38/62, Discriminator loss: 0.49398571252822876, Generator loss: 0.24761436879634857\n",
      "Epoch: 30/40, Batch: 39/62, Discriminator loss: 0.4686610698699951, Generator loss: 0.24594424664974213\n",
      "Epoch: 30/40, Batch: 40/62, Discriminator loss: 0.6638780832290649, Generator loss: 0.23282212018966675\n",
      "Epoch: 30/40, Batch: 41/62, Discriminator loss: 0.5643169283866882, Generator loss: 0.24692149460315704\n",
      "Epoch: 30/40, Batch: 42/62, Discriminator loss: 0.5389305949211121, Generator loss: 0.2429644614458084\n",
      "Epoch: 30/40, Batch: 43/62, Discriminator loss: 0.5958925485610962, Generator loss: 0.2510276734828949\n",
      "Epoch: 30/40, Batch: 44/62, Discriminator loss: 0.5268242359161377, Generator loss: 0.2358168214559555\n",
      "Epoch: 30/40, Batch: 45/62, Discriminator loss: 0.6739095449447632, Generator loss: 0.24881651997566223\n",
      "Epoch: 30/40, Batch: 46/62, Discriminator loss: 0.6174395084381104, Generator loss: 0.26198095083236694\n",
      "Epoch: 30/40, Batch: 47/62, Discriminator loss: 0.5683286786079407, Generator loss: 0.2713388502597809\n",
      "Epoch: 30/40, Batch: 48/62, Discriminator loss: 0.665981113910675, Generator loss: 0.28439775109291077\n",
      "Epoch: 30/40, Batch: 49/62, Discriminator loss: 0.5063738226890564, Generator loss: 0.28776854276657104\n",
      "Epoch: 30/40, Batch: 50/62, Discriminator loss: 0.5972379446029663, Generator loss: 0.2969639003276825\n",
      "Epoch: 30/40, Batch: 51/62, Discriminator loss: 0.6067043542861938, Generator loss: 0.3065375089645386\n",
      "Epoch: 30/40, Batch: 52/62, Discriminator loss: 0.5757864117622375, Generator loss: 0.31075987219810486\n",
      "Epoch: 30/40, Batch: 53/62, Discriminator loss: 0.6321412920951843, Generator loss: 0.306265652179718\n",
      "Epoch: 30/40, Batch: 54/62, Discriminator loss: 0.5951894521713257, Generator loss: 0.33588385581970215\n",
      "Epoch: 30/40, Batch: 55/62, Discriminator loss: 0.6140780448913574, Generator loss: 0.33059579133987427\n",
      "Epoch: 30/40, Batch: 56/62, Discriminator loss: 0.5765120983123779, Generator loss: 0.3293108642101288\n",
      "Epoch: 30/40, Batch: 57/62, Discriminator loss: 0.5700942277908325, Generator loss: 0.3518199324607849\n",
      "Epoch: 30/40, Batch: 58/62, Discriminator loss: 0.6087433099746704, Generator loss: 0.3508968949317932\n",
      "Epoch: 30/40, Batch: 59/62, Discriminator loss: 0.5761784315109253, Generator loss: 0.3506578505039215\n",
      "Epoch: 30/40, Batch: 60/62, Discriminator loss: 0.6215269565582275, Generator loss: 0.362638384103775\n",
      "Epoch: 30/40, Batch: 61/62, Discriminator loss: 0.5788898468017578, Generator loss: 0.3656066656112671\n",
      "Epoch: 30/40, Batch: 62/62, Discriminator loss: 0.5395911931991577, Generator loss: 0.3679088354110718\n",
      "Accuracy real: 25%, fake: 0%\n",
      "Epoch: 31/40, Batch: 1/62, Discriminator loss: 0.7604710459709167, Generator loss: 0.35000619292259216\n",
      "Epoch: 31/40, Batch: 2/62, Discriminator loss: 0.5731093883514404, Generator loss: 0.3453447222709656\n",
      "Epoch: 31/40, Batch: 3/62, Discriminator loss: 0.47488826513290405, Generator loss: 0.3309136927127838\n",
      "Epoch: 31/40, Batch: 4/62, Discriminator loss: 0.6092299222946167, Generator loss: 0.3172920346260071\n",
      "Epoch: 31/40, Batch: 5/62, Discriminator loss: 0.6001949906349182, Generator loss: 0.3016010820865631\n",
      "Epoch: 31/40, Batch: 6/62, Discriminator loss: 0.6025522947311401, Generator loss: 0.31699618697166443\n",
      "Epoch: 31/40, Batch: 7/62, Discriminator loss: 0.5192049145698547, Generator loss: 0.2951071262359619\n",
      "Epoch: 31/40, Batch: 8/62, Discriminator loss: 0.5052905082702637, Generator loss: 0.29903584718704224\n",
      "Epoch: 31/40, Batch: 9/62, Discriminator loss: 0.6020010709762573, Generator loss: 0.29908809065818787\n",
      "Epoch: 31/40, Batch: 10/62, Discriminator loss: 0.5434389114379883, Generator loss: 0.2948131859302521\n",
      "Epoch: 31/40, Batch: 11/62, Discriminator loss: 0.5718498826026917, Generator loss: 0.28647178411483765\n",
      "Epoch: 31/40, Batch: 12/62, Discriminator loss: 0.440410852432251, Generator loss: 0.2869429290294647\n",
      "Epoch: 31/40, Batch: 13/62, Discriminator loss: 0.5442526340484619, Generator loss: 0.28121593594551086\n",
      "Epoch: 31/40, Batch: 14/62, Discriminator loss: 0.5572905540466309, Generator loss: 0.28926900029182434\n",
      "Epoch: 31/40, Batch: 15/62, Discriminator loss: 0.48678040504455566, Generator loss: 0.2664543688297272\n",
      "Epoch: 31/40, Batch: 16/62, Discriminator loss: 0.37973207235336304, Generator loss: 0.2468230277299881\n",
      "Epoch: 31/40, Batch: 17/62, Discriminator loss: 0.5946208238601685, Generator loss: 0.24642126262187958\n",
      "Epoch: 31/40, Batch: 18/62, Discriminator loss: 0.5372795462608337, Generator loss: 0.24954566359519958\n",
      "Epoch: 31/40, Batch: 19/62, Discriminator loss: 0.5071609020233154, Generator loss: 0.26094678044319153\n",
      "Epoch: 31/40, Batch: 20/62, Discriminator loss: 0.5991420745849609, Generator loss: 0.2758244276046753\n",
      "Epoch: 31/40, Batch: 21/62, Discriminator loss: 0.5210459232330322, Generator loss: 0.27443134784698486\n",
      "Epoch: 31/40, Batch: 22/62, Discriminator loss: 0.6077449321746826, Generator loss: 0.2895940840244293\n",
      "Epoch: 31/40, Batch: 23/62, Discriminator loss: 0.5396407842636108, Generator loss: 0.3103726804256439\n",
      "Epoch: 31/40, Batch: 24/62, Discriminator loss: 0.4306440055370331, Generator loss: 0.28568026423454285\n",
      "Epoch: 31/40, Batch: 25/62, Discriminator loss: 0.6550543904304504, Generator loss: 0.2982943654060364\n",
      "Epoch: 31/40, Batch: 26/62, Discriminator loss: 0.6165280342102051, Generator loss: 0.31840065121650696\n",
      "Epoch: 31/40, Batch: 27/62, Discriminator loss: 0.604718804359436, Generator loss: 0.3145401179790497\n",
      "Epoch: 31/40, Batch: 28/62, Discriminator loss: 0.6427169442176819, Generator loss: 0.3393429219722748\n",
      "Epoch: 31/40, Batch: 29/62, Discriminator loss: 0.5693380832672119, Generator loss: 0.3446851968765259\n",
      "Epoch: 31/40, Batch: 30/62, Discriminator loss: 0.5735700130462646, Generator loss: 0.34582385420799255\n",
      "Epoch: 31/40, Batch: 31/62, Discriminator loss: 0.5921223163604736, Generator loss: 0.3274930417537689\n",
      "Epoch: 31/40, Batch: 32/62, Discriminator loss: 0.6033430099487305, Generator loss: 0.30816739797592163\n",
      "Epoch: 31/40, Batch: 33/62, Discriminator loss: 0.48830848932266235, Generator loss: 0.30574101209640503\n",
      "Epoch: 31/40, Batch: 34/62, Discriminator loss: 0.6677373647689819, Generator loss: 0.3140099048614502\n",
      "Epoch: 31/40, Batch: 35/62, Discriminator loss: 0.5579570531845093, Generator loss: 0.31559738516807556\n",
      "Epoch: 31/40, Batch: 36/62, Discriminator loss: 0.6475682258605957, Generator loss: 0.3365251421928406\n",
      "Epoch: 31/40, Batch: 37/62, Discriminator loss: 0.5843645334243774, Generator loss: 0.3208456039428711\n",
      "Epoch: 31/40, Batch: 38/62, Discriminator loss: 0.5590376853942871, Generator loss: 0.3201664388179779\n",
      "Epoch: 31/40, Batch: 39/62, Discriminator loss: 0.5698287487030029, Generator loss: 0.31076493859291077\n",
      "Epoch: 31/40, Batch: 40/62, Discriminator loss: 0.6755218505859375, Generator loss: 0.3206035792827606\n",
      "Epoch: 31/40, Batch: 41/62, Discriminator loss: 0.6530265212059021, Generator loss: 0.3177075684070587\n",
      "Epoch: 31/40, Batch: 42/62, Discriminator loss: 0.5674853324890137, Generator loss: 0.30859068036079407\n",
      "Epoch: 31/40, Batch: 43/62, Discriminator loss: 0.6037266254425049, Generator loss: 0.2968306243419647\n",
      "Epoch: 31/40, Batch: 44/62, Discriminator loss: 0.5412216186523438, Generator loss: 0.2991611659526825\n",
      "Epoch: 31/40, Batch: 45/62, Discriminator loss: 0.6243467330932617, Generator loss: 0.2968265116214752\n",
      "Epoch: 31/40, Batch: 46/62, Discriminator loss: 0.6127466559410095, Generator loss: 0.2931980490684509\n",
      "Epoch: 31/40, Batch: 47/62, Discriminator loss: 0.572746992111206, Generator loss: 0.28826725482940674\n",
      "Epoch: 31/40, Batch: 48/62, Discriminator loss: 0.65478515625, Generator loss: 0.29915353655815125\n",
      "Epoch: 31/40, Batch: 49/62, Discriminator loss: 0.5221566557884216, Generator loss: 0.2901732623577118\n",
      "Epoch: 31/40, Batch: 50/62, Discriminator loss: 0.5612634420394897, Generator loss: 0.28210315108299255\n",
      "Epoch: 31/40, Batch: 51/62, Discriminator loss: 0.6074327826499939, Generator loss: 0.27989462018013\n",
      "Epoch: 31/40, Batch: 52/62, Discriminator loss: 0.5294642448425293, Generator loss: 0.27624863386154175\n",
      "Epoch: 31/40, Batch: 53/62, Discriminator loss: 0.6327309608459473, Generator loss: 0.29588261246681213\n",
      "Epoch: 31/40, Batch: 54/62, Discriminator loss: 0.5331712961196899, Generator loss: 0.2922835946083069\n",
      "Epoch: 31/40, Batch: 55/62, Discriminator loss: 0.5882665514945984, Generator loss: 0.28172168135643005\n",
      "Epoch: 31/40, Batch: 56/62, Discriminator loss: 0.5439387559890747, Generator loss: 0.28468069434165955\n",
      "Epoch: 31/40, Batch: 57/62, Discriminator loss: 0.523642897605896, Generator loss: 0.2794858515262604\n",
      "Epoch: 31/40, Batch: 58/62, Discriminator loss: 0.6090754866600037, Generator loss: 0.27984851598739624\n",
      "Epoch: 31/40, Batch: 59/62, Discriminator loss: 0.5918979644775391, Generator loss: 0.28928712010383606\n",
      "Epoch: 31/40, Batch: 60/62, Discriminator loss: 0.6323287487030029, Generator loss: 0.31191563606262207\n",
      "Epoch: 31/40, Batch: 61/62, Discriminator loss: 0.589539647102356, Generator loss: 0.3178224265575409\n",
      "Epoch: 31/40, Batch: 62/62, Discriminator loss: 0.48904553055763245, Generator loss: 0.31130293011665344\n",
      "Epoch: 32/40, Batch: 1/62, Discriminator loss: 0.5416465997695923, Generator loss: 0.31736284494400024\n",
      "Epoch: 32/40, Batch: 2/62, Discriminator loss: 0.5393914580345154, Generator loss: 0.3177506625652313\n",
      "Epoch: 32/40, Batch: 3/62, Discriminator loss: 0.39374464750289917, Generator loss: 0.3113127052783966\n",
      "Epoch: 32/40, Batch: 4/62, Discriminator loss: 0.5913689136505127, Generator loss: 0.30619361996650696\n",
      "Epoch: 32/40, Batch: 5/62, Discriminator loss: 0.5768950581550598, Generator loss: 0.313625305891037\n",
      "Epoch: 32/40, Batch: 6/62, Discriminator loss: 0.5722336769104004, Generator loss: 0.2996918261051178\n",
      "Epoch: 32/40, Batch: 7/62, Discriminator loss: 0.51544189453125, Generator loss: 0.2978498339653015\n",
      "Epoch: 32/40, Batch: 8/62, Discriminator loss: 0.5112261772155762, Generator loss: 0.2885814905166626\n",
      "Epoch: 32/40, Batch: 9/62, Discriminator loss: 0.5891904830932617, Generator loss: 0.2873244881629944\n",
      "Epoch: 32/40, Batch: 10/62, Discriminator loss: 0.5588539838790894, Generator loss: 0.2887924611568451\n",
      "Epoch: 32/40, Batch: 11/62, Discriminator loss: 0.5983238220214844, Generator loss: 0.29421210289001465\n",
      "Epoch: 32/40, Batch: 12/62, Discriminator loss: 0.4667544662952423, Generator loss: 0.3052350580692291\n",
      "Epoch: 32/40, Batch: 13/62, Discriminator loss: 0.5801827311515808, Generator loss: 0.3194066882133484\n",
      "Epoch: 32/40, Batch: 14/62, Discriminator loss: 0.5356218814849854, Generator loss: 0.32809749245643616\n",
      "Epoch: 32/40, Batch: 15/62, Discriminator loss: 0.4890446960926056, Generator loss: 0.3349643349647522\n",
      "Epoch: 32/40, Batch: 16/62, Discriminator loss: 0.38693204522132874, Generator loss: 0.32668784260749817\n",
      "Epoch: 32/40, Batch: 17/62, Discriminator loss: 0.5354658365249634, Generator loss: 0.3159939646720886\n",
      "Epoch: 32/40, Batch: 18/62, Discriminator loss: 0.5527983903884888, Generator loss: 0.30424249172210693\n",
      "Epoch: 32/40, Batch: 19/62, Discriminator loss: 0.5288716554641724, Generator loss: 0.2819039225578308\n",
      "Epoch: 32/40, Batch: 20/62, Discriminator loss: 0.6072045564651489, Generator loss: 0.26766663789749146\n",
      "Epoch: 32/40, Batch: 21/62, Discriminator loss: 0.5696861743927002, Generator loss: 0.26581841707229614\n",
      "Epoch: 32/40, Batch: 22/62, Discriminator loss: 0.6809147596359253, Generator loss: 0.2647189497947693\n",
      "Epoch: 32/40, Batch: 23/62, Discriminator loss: 0.6090705394744873, Generator loss: 0.24249267578125\n",
      "Epoch: 32/40, Batch: 24/62, Discriminator loss: 0.46228986978530884, Generator loss: 0.2367997020483017\n",
      "Epoch: 32/40, Batch: 25/62, Discriminator loss: 0.7354593276977539, Generator loss: 0.25544944405555725\n",
      "Epoch: 32/40, Batch: 26/62, Discriminator loss: 0.6537843942642212, Generator loss: 0.25567322969436646\n",
      "Epoch: 32/40, Batch: 27/62, Discriminator loss: 0.6564566493034363, Generator loss: 0.26799479126930237\n",
      "Epoch: 32/40, Batch: 28/62, Discriminator loss: 0.6945592164993286, Generator loss: 0.2708492577075958\n",
      "Epoch: 32/40, Batch: 29/62, Discriminator loss: 0.6431462168693542, Generator loss: 0.274997353553772\n",
      "Epoch: 32/40, Batch: 30/62, Discriminator loss: 0.5716951489448547, Generator loss: 0.27419281005859375\n",
      "Epoch: 32/40, Batch: 31/62, Discriminator loss: 0.5928294658660889, Generator loss: 0.2632713317871094\n",
      "Epoch: 32/40, Batch: 32/62, Discriminator loss: 0.6113066673278809, Generator loss: 0.2608546316623688\n",
      "Epoch: 32/40, Batch: 33/62, Discriminator loss: 0.4709216356277466, Generator loss: 0.25532230734825134\n",
      "Epoch: 32/40, Batch: 34/62, Discriminator loss: 0.7248757481575012, Generator loss: 0.26018205285072327\n",
      "Epoch: 32/40, Batch: 35/62, Discriminator loss: 0.5585374236106873, Generator loss: 0.2529377341270447\n",
      "Epoch: 32/40, Batch: 36/62, Discriminator loss: 0.6634650230407715, Generator loss: 0.23774832487106323\n",
      "Epoch: 32/40, Batch: 37/62, Discriminator loss: 0.5873677730560303, Generator loss: 0.24485544860363007\n",
      "Epoch: 32/40, Batch: 38/62, Discriminator loss: 0.5806116461753845, Generator loss: 0.24094882607460022\n",
      "Epoch: 32/40, Batch: 39/62, Discriminator loss: 0.595695436000824, Generator loss: 0.23271194100379944\n",
      "Epoch: 32/40, Batch: 40/62, Discriminator loss: 0.7273155450820923, Generator loss: 0.23533454537391663\n",
      "Epoch: 32/40, Batch: 41/62, Discriminator loss: 0.6688366532325745, Generator loss: 0.24598237872123718\n",
      "Epoch: 32/40, Batch: 42/62, Discriminator loss: 0.567011833190918, Generator loss: 0.2552441358566284\n",
      "Epoch: 32/40, Batch: 43/62, Discriminator loss: 0.6315455436706543, Generator loss: 0.2471352070569992\n",
      "Epoch: 32/40, Batch: 44/62, Discriminator loss: 0.545599639415741, Generator loss: 0.255182147026062\n",
      "Epoch: 32/40, Batch: 45/62, Discriminator loss: 0.6341050267219543, Generator loss: 0.25903499126434326\n",
      "Epoch: 32/40, Batch: 46/62, Discriminator loss: 0.6001259088516235, Generator loss: 0.27153143286705017\n",
      "Epoch: 32/40, Batch: 47/62, Discriminator loss: 0.5688790082931519, Generator loss: 0.27680128812789917\n",
      "Epoch: 32/40, Batch: 48/62, Discriminator loss: 0.6634770631790161, Generator loss: 0.2854352593421936\n",
      "Epoch: 32/40, Batch: 49/62, Discriminator loss: 0.5465719699859619, Generator loss: 0.27960553765296936\n",
      "Epoch: 32/40, Batch: 50/62, Discriminator loss: 0.5600881576538086, Generator loss: 0.2846178412437439\n",
      "Epoch: 32/40, Batch: 51/62, Discriminator loss: 0.5701956748962402, Generator loss: 0.288833349943161\n",
      "Epoch: 32/40, Batch: 52/62, Discriminator loss: 0.5175549387931824, Generator loss: 0.2834003269672394\n",
      "Epoch: 32/40, Batch: 53/62, Discriminator loss: 0.5921037197113037, Generator loss: 0.2859148383140564\n",
      "Epoch: 32/40, Batch: 54/62, Discriminator loss: 0.5528091192245483, Generator loss: 0.2858630120754242\n",
      "Epoch: 32/40, Batch: 55/62, Discriminator loss: 0.6026939749717712, Generator loss: 0.29907873272895813\n",
      "Epoch: 32/40, Batch: 56/62, Discriminator loss: 0.5425961017608643, Generator loss: 0.3057360053062439\n",
      "Epoch: 32/40, Batch: 57/62, Discriminator loss: 0.5541109442710876, Generator loss: 0.2937809228897095\n",
      "Epoch: 32/40, Batch: 58/62, Discriminator loss: 0.6189572215080261, Generator loss: 0.30130958557128906\n",
      "Epoch: 32/40, Batch: 59/62, Discriminator loss: 0.6212567090988159, Generator loss: 0.31976985931396484\n",
      "Epoch: 32/40, Batch: 60/62, Discriminator loss: 0.6231421828269958, Generator loss: 0.3440459966659546\n",
      "Epoch: 32/40, Batch: 61/62, Discriminator loss: 0.5763162970542908, Generator loss: 0.3574555218219757\n",
      "Epoch: 32/40, Batch: 62/62, Discriminator loss: 0.515170156955719, Generator loss: 0.3452317714691162\n",
      "Epoch: 33/40, Batch: 1/62, Discriminator loss: 0.5500714182853699, Generator loss: 0.35392695665359497\n",
      "Epoch: 33/40, Batch: 2/62, Discriminator loss: 0.5564508438110352, Generator loss: 0.3448382318019867\n",
      "Epoch: 33/40, Batch: 3/62, Discriminator loss: 0.43864119052886963, Generator loss: 0.3298436999320984\n",
      "Epoch: 33/40, Batch: 4/62, Discriminator loss: 0.6018675565719604, Generator loss: 0.32901835441589355\n",
      "Epoch: 33/40, Batch: 5/62, Discriminator loss: 0.5821069478988647, Generator loss: 0.3359021246433258\n",
      "Epoch: 33/40, Batch: 6/62, Discriminator loss: 0.5868102312088013, Generator loss: 0.33567509055137634\n",
      "Epoch: 33/40, Batch: 7/62, Discriminator loss: 0.5264233946800232, Generator loss: 0.3265911936759949\n",
      "Epoch: 33/40, Batch: 8/62, Discriminator loss: 0.5072546005249023, Generator loss: 0.32042011618614197\n",
      "Epoch: 33/40, Batch: 9/62, Discriminator loss: 0.5759989023208618, Generator loss: 0.3319757580757141\n",
      "Epoch: 33/40, Batch: 10/62, Discriminator loss: 0.5548899173736572, Generator loss: 0.32316601276397705\n",
      "Epoch: 33/40, Batch: 11/62, Discriminator loss: 0.6049680113792419, Generator loss: 0.3365373909473419\n",
      "Epoch: 33/40, Batch: 12/62, Discriminator loss: 0.46586495637893677, Generator loss: 0.3247356414794922\n",
      "Epoch: 33/40, Batch: 13/62, Discriminator loss: 0.5717496871948242, Generator loss: 0.3013761043548584\n",
      "Epoch: 33/40, Batch: 14/62, Discriminator loss: 0.5717069506645203, Generator loss: 0.29947492480278015\n",
      "Epoch: 33/40, Batch: 15/62, Discriminator loss: 0.5531952977180481, Generator loss: 0.2892760634422302\n",
      "Epoch: 33/40, Batch: 16/62, Discriminator loss: 0.4513168931007385, Generator loss: 0.2650895416736603\n",
      "Epoch: 33/40, Batch: 17/62, Discriminator loss: 0.592840313911438, Generator loss: 0.2677221894264221\n",
      "Epoch: 33/40, Batch: 18/62, Discriminator loss: 0.5768146514892578, Generator loss: 0.2555682361125946\n",
      "Epoch: 33/40, Batch: 19/62, Discriminator loss: 0.5511345267295837, Generator loss: 0.2660713791847229\n",
      "Epoch: 33/40, Batch: 20/62, Discriminator loss: 0.6113361120223999, Generator loss: 0.26012545824050903\n",
      "Epoch: 33/40, Batch: 21/62, Discriminator loss: 0.5738785266876221, Generator loss: 0.270031213760376\n",
      "Epoch: 33/40, Batch: 22/62, Discriminator loss: 0.6309834718704224, Generator loss: 0.27054253220558167\n",
      "Epoch: 33/40, Batch: 23/62, Discriminator loss: 0.5789651870727539, Generator loss: 0.26567167043685913\n",
      "Epoch: 33/40, Batch: 24/62, Discriminator loss: 0.44356685876846313, Generator loss: 0.25561386346817017\n",
      "Epoch: 33/40, Batch: 25/62, Discriminator loss: 0.6818307638168335, Generator loss: 0.25683242082595825\n",
      "Epoch: 33/40, Batch: 26/62, Discriminator loss: 0.6103094816207886, Generator loss: 0.2740150988101959\n",
      "Epoch: 33/40, Batch: 27/62, Discriminator loss: 0.5999717116355896, Generator loss: 0.2880060076713562\n",
      "Epoch: 33/40, Batch: 28/62, Discriminator loss: 0.6414963006973267, Generator loss: 0.3024138808250427\n",
      "Epoch: 33/40, Batch: 29/62, Discriminator loss: 0.576158881187439, Generator loss: 0.31500834226608276\n",
      "Epoch: 33/40, Batch: 30/62, Discriminator loss: 0.5237795114517212, Generator loss: 0.29788878560066223\n",
      "Epoch: 33/40, Batch: 31/62, Discriminator loss: 0.5402735471725464, Generator loss: 0.30503156781196594\n",
      "Epoch: 33/40, Batch: 32/62, Discriminator loss: 0.586882472038269, Generator loss: 0.3089839220046997\n",
      "Epoch: 33/40, Batch: 33/62, Discriminator loss: 0.4497613310813904, Generator loss: 0.2998160421848297\n",
      "Epoch: 33/40, Batch: 34/62, Discriminator loss: 0.6852225065231323, Generator loss: 0.3028618097305298\n",
      "Epoch: 33/40, Batch: 35/62, Discriminator loss: 0.5399379134178162, Generator loss: 0.30714091658592224\n",
      "Epoch: 33/40, Batch: 36/62, Discriminator loss: 0.6523833870887756, Generator loss: 0.30975455045700073\n",
      "Epoch: 33/40, Batch: 37/62, Discriminator loss: 0.5550659894943237, Generator loss: 0.3223150968551636\n",
      "Epoch: 33/40, Batch: 38/62, Discriminator loss: 0.5452227592468262, Generator loss: 0.30994945764541626\n",
      "Epoch: 33/40, Batch: 39/62, Discriminator loss: 0.5603448152542114, Generator loss: 0.28949829936027527\n",
      "Epoch: 33/40, Batch: 40/62, Discriminator loss: 0.6970459222793579, Generator loss: 0.3073669970035553\n",
      "Epoch: 33/40, Batch: 41/62, Discriminator loss: 0.630318820476532, Generator loss: 0.3113989531993866\n",
      "Epoch: 33/40, Batch: 42/62, Discriminator loss: 0.5687189102172852, Generator loss: 0.3049527704715729\n",
      "Epoch: 33/40, Batch: 43/62, Discriminator loss: 0.6177396178245544, Generator loss: 0.2898717522621155\n",
      "Epoch: 33/40, Batch: 44/62, Discriminator loss: 0.5744072198867798, Generator loss: 0.30201271176338196\n",
      "Epoch: 33/40, Batch: 45/62, Discriminator loss: 0.6388572454452515, Generator loss: 0.30160847306251526\n",
      "Epoch: 33/40, Batch: 46/62, Discriminator loss: 0.5877832174301147, Generator loss: 0.3068022131919861\n",
      "Epoch: 33/40, Batch: 47/62, Discriminator loss: 0.5682343244552612, Generator loss: 0.3046714961528778\n",
      "Epoch: 33/40, Batch: 48/62, Discriminator loss: 0.6242969036102295, Generator loss: 0.3146398663520813\n",
      "Epoch: 33/40, Batch: 49/62, Discriminator loss: 0.5464555621147156, Generator loss: 0.2887312173843384\n",
      "Epoch: 33/40, Batch: 50/62, Discriminator loss: 0.5598707795143127, Generator loss: 0.2937411665916443\n",
      "Epoch: 33/40, Batch: 51/62, Discriminator loss: 0.6171368360519409, Generator loss: 0.28870242834091187\n",
      "Epoch: 33/40, Batch: 52/62, Discriminator loss: 0.5505921840667725, Generator loss: 0.294572651386261\n",
      "Epoch: 33/40, Batch: 53/62, Discriminator loss: 0.6070388555526733, Generator loss: 0.2882104814052582\n",
      "Epoch: 33/40, Batch: 54/62, Discriminator loss: 0.5487510561943054, Generator loss: 0.2752517759799957\n",
      "Epoch: 33/40, Batch: 55/62, Discriminator loss: 0.5848672986030579, Generator loss: 0.2808516025543213\n",
      "Epoch: 33/40, Batch: 56/62, Discriminator loss: 0.5829622149467468, Generator loss: 0.2845367193222046\n",
      "Epoch: 33/40, Batch: 57/62, Discriminator loss: 0.5536494255065918, Generator loss: 0.29146525263786316\n",
      "Epoch: 33/40, Batch: 58/62, Discriminator loss: 0.6197184324264526, Generator loss: 0.296854704618454\n",
      "Epoch: 33/40, Batch: 59/62, Discriminator loss: 0.6039170622825623, Generator loss: 0.3045664429664612\n",
      "Epoch: 33/40, Batch: 60/62, Discriminator loss: 0.6252762079238892, Generator loss: 0.31042641401290894\n",
      "Epoch: 33/40, Batch: 61/62, Discriminator loss: 0.567661464214325, Generator loss: 0.31991976499557495\n",
      "Epoch: 33/40, Batch: 62/62, Discriminator loss: 0.5054061412811279, Generator loss: 0.3373829126358032\n",
      "Epoch: 34/40, Batch: 1/62, Discriminator loss: 0.5350572466850281, Generator loss: 0.32128241658210754\n",
      "Epoch: 34/40, Batch: 2/62, Discriminator loss: 0.559355616569519, Generator loss: 0.33183786273002625\n",
      "Epoch: 34/40, Batch: 3/62, Discriminator loss: 0.43761947751045227, Generator loss: 0.3224443793296814\n",
      "Epoch: 34/40, Batch: 4/62, Discriminator loss: 0.6061697006225586, Generator loss: 0.32353171706199646\n",
      "Epoch: 34/40, Batch: 5/62, Discriminator loss: 0.5952857136726379, Generator loss: 0.3117380440235138\n",
      "Epoch: 34/40, Batch: 6/62, Discriminator loss: 0.569083034992218, Generator loss: 0.3229726552963257\n",
      "Epoch: 34/40, Batch: 7/62, Discriminator loss: 0.5145455002784729, Generator loss: 0.319522887468338\n",
      "Epoch: 34/40, Batch: 8/62, Discriminator loss: 0.4887703061103821, Generator loss: 0.30779340863227844\n",
      "Epoch: 34/40, Batch: 9/62, Discriminator loss: 0.5727817416191101, Generator loss: 0.2979636490345001\n",
      "Epoch: 34/40, Batch: 10/62, Discriminator loss: 0.5682868361473083, Generator loss: 0.2820943295955658\n",
      "Epoch: 34/40, Batch: 11/62, Discriminator loss: 0.5764248967170715, Generator loss: 0.290764719247818\n",
      "Epoch: 34/40, Batch: 12/62, Discriminator loss: 0.4662095308303833, Generator loss: 0.266297847032547\n",
      "Epoch: 34/40, Batch: 13/62, Discriminator loss: 0.5947966575622559, Generator loss: 0.27178800106048584\n",
      "Epoch: 34/40, Batch: 14/62, Discriminator loss: 0.5783509016036987, Generator loss: 0.27590155601501465\n",
      "Epoch: 34/40, Batch: 15/62, Discriminator loss: 0.5558849573135376, Generator loss: 0.2514488697052002\n",
      "Epoch: 34/40, Batch: 16/62, Discriminator loss: 0.4545248746871948, Generator loss: 0.2627759873867035\n",
      "Epoch: 34/40, Batch: 17/62, Discriminator loss: 0.5987288951873779, Generator loss: 0.269469290971756\n",
      "Epoch: 34/40, Batch: 18/62, Discriminator loss: 0.5786422491073608, Generator loss: 0.26521366834640503\n",
      "Epoch: 34/40, Batch: 19/62, Discriminator loss: 0.5756930708885193, Generator loss: 0.2625192105770111\n",
      "Epoch: 34/40, Batch: 20/62, Discriminator loss: 0.6091774702072144, Generator loss: 0.27857980132102966\n",
      "Epoch: 34/40, Batch: 21/62, Discriminator loss: 0.5992459058761597, Generator loss: 0.2923582196235657\n",
      "Epoch: 34/40, Batch: 22/62, Discriminator loss: 0.6328701972961426, Generator loss: 0.31193941831588745\n",
      "Epoch: 34/40, Batch: 23/62, Discriminator loss: 0.586982011795044, Generator loss: 0.3168202340602875\n",
      "Epoch: 34/40, Batch: 24/62, Discriminator loss: 0.4664627015590668, Generator loss: 0.30027806758880615\n",
      "Epoch: 34/40, Batch: 25/62, Discriminator loss: 0.7032702565193176, Generator loss: 0.29794827103614807\n",
      "Epoch: 34/40, Batch: 26/62, Discriminator loss: 0.6341785192489624, Generator loss: 0.3159673511981964\n",
      "Epoch: 34/40, Batch: 27/62, Discriminator loss: 0.5969220399856567, Generator loss: 0.34008291363716125\n",
      "Epoch: 34/40, Batch: 28/62, Discriminator loss: 0.6286240220069885, Generator loss: 0.34648409485816956\n",
      "Epoch: 34/40, Batch: 29/62, Discriminator loss: 0.5719096660614014, Generator loss: 0.35117393732070923\n",
      "Epoch: 34/40, Batch: 30/62, Discriminator loss: 0.5247838497161865, Generator loss: 0.3210529088973999\n",
      "Epoch: 34/40, Batch: 31/62, Discriminator loss: 0.5903656482696533, Generator loss: 0.3126087784767151\n",
      "Epoch: 34/40, Batch: 32/62, Discriminator loss: 0.5562788248062134, Generator loss: 0.29381832480430603\n",
      "Epoch: 34/40, Batch: 33/62, Discriminator loss: 0.4843030571937561, Generator loss: 0.2750745117664337\n",
      "Epoch: 34/40, Batch: 34/62, Discriminator loss: 0.69504714012146, Generator loss: 0.28479596972465515\n",
      "Epoch: 34/40, Batch: 35/62, Discriminator loss: 0.5407183170318604, Generator loss: 0.27718135714530945\n",
      "Epoch: 34/40, Batch: 36/62, Discriminator loss: 0.6589436531066895, Generator loss: 0.2808655798435211\n",
      "Epoch: 34/40, Batch: 37/62, Discriminator loss: 0.5178916454315186, Generator loss: 0.28150540590286255\n",
      "Epoch: 34/40, Batch: 38/62, Discriminator loss: 0.552134096622467, Generator loss: 0.278785765171051\n",
      "Epoch: 34/40, Batch: 39/62, Discriminator loss: 0.5635448098182678, Generator loss: 0.2652856111526489\n",
      "Epoch: 34/40, Batch: 40/62, Discriminator loss: 0.6892229318618774, Generator loss: 0.28268954157829285\n",
      "Epoch: 34/40, Batch: 41/62, Discriminator loss: 0.5986320972442627, Generator loss: 0.28016534447669983\n",
      "Epoch: 34/40, Batch: 42/62, Discriminator loss: 0.5260454416275024, Generator loss: 0.28014159202575684\n",
      "Epoch: 34/40, Batch: 43/62, Discriminator loss: 0.5941497087478638, Generator loss: 0.2820335626602173\n",
      "Epoch: 34/40, Batch: 44/62, Discriminator loss: 0.5121968984603882, Generator loss: 0.2764410674571991\n",
      "Epoch: 34/40, Batch: 45/62, Discriminator loss: 0.6052310466766357, Generator loss: 0.2723849415779114\n",
      "Epoch: 34/40, Batch: 46/62, Discriminator loss: 0.5908695459365845, Generator loss: 0.2829511761665344\n",
      "Epoch: 34/40, Batch: 47/62, Discriminator loss: 0.5339550971984863, Generator loss: 0.27237796783447266\n",
      "Epoch: 34/40, Batch: 48/62, Discriminator loss: 0.6556203365325928, Generator loss: 0.2835603654384613\n",
      "Epoch: 34/40, Batch: 49/62, Discriminator loss: 0.5021470189094543, Generator loss: 0.2662290632724762\n",
      "Epoch: 34/40, Batch: 50/62, Discriminator loss: 0.5646559000015259, Generator loss: 0.27718254923820496\n",
      "Epoch: 34/40, Batch: 51/62, Discriminator loss: 0.6143295764923096, Generator loss: 0.2816246449947357\n",
      "Epoch: 34/40, Batch: 52/62, Discriminator loss: 0.5514556169509888, Generator loss: 0.27941372990608215\n",
      "Epoch: 34/40, Batch: 53/62, Discriminator loss: 0.6099112033843994, Generator loss: 0.28952649235725403\n",
      "Epoch: 34/40, Batch: 54/62, Discriminator loss: 0.5788294076919556, Generator loss: 0.2889959514141083\n",
      "Epoch: 34/40, Batch: 55/62, Discriminator loss: 0.6393451690673828, Generator loss: 0.297224223613739\n",
      "Epoch: 34/40, Batch: 56/62, Discriminator loss: 0.5932440757751465, Generator loss: 0.2943488359451294\n",
      "Epoch: 34/40, Batch: 57/62, Discriminator loss: 0.5819166898727417, Generator loss: 0.2887749969959259\n",
      "Epoch: 34/40, Batch: 58/62, Discriminator loss: 0.6601391434669495, Generator loss: 0.2924612760543823\n",
      "Epoch: 34/40, Batch: 59/62, Discriminator loss: 0.6211168766021729, Generator loss: 0.31204885244369507\n",
      "Epoch: 34/40, Batch: 60/62, Discriminator loss: 0.6664663553237915, Generator loss: 0.32349637150764465\n",
      "Epoch: 34/40, Batch: 61/62, Discriminator loss: 0.6086289286613464, Generator loss: 0.32984426617622375\n",
      "Epoch: 34/40, Batch: 62/62, Discriminator loss: 0.5530470013618469, Generator loss: 0.3267216086387634\n",
      "Epoch: 35/40, Batch: 1/62, Discriminator loss: 0.580697774887085, Generator loss: 0.3235713243484497\n",
      "Epoch: 35/40, Batch: 2/62, Discriminator loss: 0.6013487577438354, Generator loss: 0.31376761198043823\n",
      "Epoch: 35/40, Batch: 3/62, Discriminator loss: 0.48940402269363403, Generator loss: 0.30807340145111084\n",
      "Epoch: 35/40, Batch: 4/62, Discriminator loss: 0.6283808350563049, Generator loss: 0.28487199544906616\n",
      "Epoch: 35/40, Batch: 5/62, Discriminator loss: 0.6268394589424133, Generator loss: 0.2972419261932373\n",
      "Epoch: 35/40, Batch: 6/62, Discriminator loss: 0.6104962825775146, Generator loss: 0.28530368208885193\n",
      "Epoch: 35/40, Batch: 7/62, Discriminator loss: 0.5545648336410522, Generator loss: 0.28756746649742126\n",
      "Epoch: 35/40, Batch: 8/62, Discriminator loss: 0.5674959421157837, Generator loss: 0.2759546935558319\n",
      "Epoch: 35/40, Batch: 9/62, Discriminator loss: 0.6209848523139954, Generator loss: 0.27296242117881775\n",
      "Epoch: 35/40, Batch: 10/62, Discriminator loss: 0.5842676162719727, Generator loss: 0.27439504861831665\n",
      "Epoch: 35/40, Batch: 11/62, Discriminator loss: 0.631513237953186, Generator loss: 0.2753632366657257\n",
      "Epoch: 35/40, Batch: 12/62, Discriminator loss: 0.4800563156604767, Generator loss: 0.26179230213165283\n",
      "Epoch: 35/40, Batch: 13/62, Discriminator loss: 0.6247275471687317, Generator loss: 0.2534021735191345\n",
      "Epoch: 35/40, Batch: 14/62, Discriminator loss: 0.5888386964797974, Generator loss: 0.25661998987197876\n",
      "Epoch: 35/40, Batch: 15/62, Discriminator loss: 0.5554891228675842, Generator loss: 0.24952533841133118\n",
      "Epoch: 35/40, Batch: 16/62, Discriminator loss: 0.4673067331314087, Generator loss: 0.2478780448436737\n",
      "Epoch: 35/40, Batch: 17/62, Discriminator loss: 0.6152920722961426, Generator loss: 0.2510479986667633\n",
      "Epoch: 35/40, Batch: 18/62, Discriminator loss: 0.5727464556694031, Generator loss: 0.2403164952993393\n",
      "Epoch: 35/40, Batch: 19/62, Discriminator loss: 0.5448669195175171, Generator loss: 0.2484545260667801\n",
      "Epoch: 35/40, Batch: 20/62, Discriminator loss: 0.6001228094100952, Generator loss: 0.2533016800880432\n",
      "Epoch: 35/40, Batch: 21/62, Discriminator loss: 0.5644055604934692, Generator loss: 0.257453590631485\n",
      "Epoch: 35/40, Batch: 22/62, Discriminator loss: 0.6464269161224365, Generator loss: 0.27171847224235535\n",
      "Epoch: 35/40, Batch: 23/62, Discriminator loss: 0.5926985740661621, Generator loss: 0.2654706835746765\n",
      "Epoch: 35/40, Batch: 24/62, Discriminator loss: 0.4509992003440857, Generator loss: 0.259938508272171\n",
      "Epoch: 35/40, Batch: 25/62, Discriminator loss: 0.6914421916007996, Generator loss: 0.27941885590553284\n",
      "Epoch: 35/40, Batch: 26/62, Discriminator loss: 0.6188710927963257, Generator loss: 0.2849845886230469\n",
      "Epoch: 35/40, Batch: 27/62, Discriminator loss: 0.5924756526947021, Generator loss: 0.2892158627510071\n",
      "Epoch: 35/40, Batch: 28/62, Discriminator loss: 0.6275073289871216, Generator loss: 0.30071091651916504\n",
      "Epoch: 35/40, Batch: 29/62, Discriminator loss: 0.5760141611099243, Generator loss: 0.3040972948074341\n",
      "Epoch: 35/40, Batch: 30/62, Discriminator loss: 0.5329650044441223, Generator loss: 0.3080558180809021\n",
      "Epoch: 35/40, Batch: 31/62, Discriminator loss: 0.5359386205673218, Generator loss: 0.30404582619667053\n",
      "Epoch: 35/40, Batch: 32/62, Discriminator loss: 0.5567998886108398, Generator loss: 0.3103334307670593\n",
      "Epoch: 35/40, Batch: 33/62, Discriminator loss: 0.45983457565307617, Generator loss: 0.2991102933883667\n",
      "Epoch: 35/40, Batch: 34/62, Discriminator loss: 0.6780526638031006, Generator loss: 0.31219562888145447\n",
      "Epoch: 35/40, Batch: 35/62, Discriminator loss: 0.5274434089660645, Generator loss: 0.30344367027282715\n",
      "Epoch: 35/40, Batch: 36/62, Discriminator loss: 0.6142557263374329, Generator loss: 0.304330438375473\n",
      "Epoch: 35/40, Batch: 37/62, Discriminator loss: 0.5458515882492065, Generator loss: 0.30046290159225464\n",
      "Epoch: 35/40, Batch: 38/62, Discriminator loss: 0.5352000594139099, Generator loss: 0.304836630821228\n",
      "Epoch: 35/40, Batch: 39/62, Discriminator loss: 0.5482926368713379, Generator loss: 0.3036339581012726\n",
      "Epoch: 35/40, Batch: 40/62, Discriminator loss: 0.6397961974143982, Generator loss: 0.3162086308002472\n",
      "Epoch: 35/40, Batch: 41/62, Discriminator loss: 0.5976587533950806, Generator loss: 0.3150390088558197\n",
      "Epoch: 35/40, Batch: 42/62, Discriminator loss: 0.5524974465370178, Generator loss: 0.3054709732532501\n",
      "Epoch: 35/40, Batch: 43/62, Discriminator loss: 0.5907970070838928, Generator loss: 0.3039039075374603\n",
      "Epoch: 35/40, Batch: 44/62, Discriminator loss: 0.5047897100448608, Generator loss: 0.29939886927604675\n",
      "Epoch: 35/40, Batch: 45/62, Discriminator loss: 0.589400053024292, Generator loss: 0.3074936270713806\n",
      "Epoch: 35/40, Batch: 46/62, Discriminator loss: 0.5805071592330933, Generator loss: 0.31079164147377014\n",
      "Epoch: 35/40, Batch: 47/62, Discriminator loss: 0.5438013076782227, Generator loss: 0.3029678761959076\n",
      "Epoch: 35/40, Batch: 48/62, Discriminator loss: 0.6365572214126587, Generator loss: 0.30985984206199646\n",
      "Epoch: 35/40, Batch: 49/62, Discriminator loss: 0.5231529474258423, Generator loss: 0.30689701437950134\n",
      "Epoch: 35/40, Batch: 50/62, Discriminator loss: 0.5717154741287231, Generator loss: 0.2985302209854126\n",
      "Epoch: 35/40, Batch: 51/62, Discriminator loss: 0.5902837514877319, Generator loss: 0.29361626505851746\n",
      "Epoch: 35/40, Batch: 52/62, Discriminator loss: 0.5181305408477783, Generator loss: 0.29692724347114563\n",
      "Epoch: 35/40, Batch: 53/62, Discriminator loss: 0.5824109315872192, Generator loss: 0.30406397581100464\n",
      "Epoch: 35/40, Batch: 54/62, Discriminator loss: 0.5404472947120667, Generator loss: 0.2985877990722656\n",
      "Epoch: 35/40, Batch: 55/62, Discriminator loss: 0.5893369317054749, Generator loss: 0.2944590151309967\n",
      "Epoch: 35/40, Batch: 56/62, Discriminator loss: 0.584391713142395, Generator loss: 0.3024250864982605\n",
      "Epoch: 35/40, Batch: 57/62, Discriminator loss: 0.5559971332550049, Generator loss: 0.2945203483104706\n",
      "Epoch: 35/40, Batch: 58/62, Discriminator loss: 0.6224700212478638, Generator loss: 0.30969393253326416\n",
      "Epoch: 35/40, Batch: 59/62, Discriminator loss: 0.5951218605041504, Generator loss: 0.29818686842918396\n",
      "Epoch: 35/40, Batch: 60/62, Discriminator loss: 0.6476000547409058, Generator loss: 0.3057824373245239\n",
      "Epoch: 35/40, Batch: 61/62, Discriminator loss: 0.6286705732345581, Generator loss: 0.31539738178253174\n",
      "Epoch: 35/40, Batch: 62/62, Discriminator loss: 0.5490714907646179, Generator loss: 0.31497859954833984\n",
      "Accuracy real: 25%, fake: 0%\n",
      "Epoch: 36/40, Batch: 1/62, Discriminator loss: 0.8193052411079407, Generator loss: 0.3159480690956116\n",
      "Epoch: 36/40, Batch: 2/62, Discriminator loss: 0.5929911136627197, Generator loss: 0.32269737124443054\n",
      "Epoch: 36/40, Batch: 3/62, Discriminator loss: 0.46112218499183655, Generator loss: 0.31108778715133667\n",
      "Epoch: 36/40, Batch: 4/62, Discriminator loss: 0.6199535727500916, Generator loss: 0.30805033445358276\n",
      "Epoch: 36/40, Batch: 5/62, Discriminator loss: 0.5967233777046204, Generator loss: 0.3211327791213989\n",
      "Epoch: 36/40, Batch: 6/62, Discriminator loss: 0.5643106698989868, Generator loss: 0.3266802132129669\n",
      "Epoch: 36/40, Batch: 7/62, Discriminator loss: 0.5433343648910522, Generator loss: 0.3259792923927307\n",
      "Epoch: 36/40, Batch: 8/62, Discriminator loss: 0.5067233443260193, Generator loss: 0.31476905941963196\n",
      "Epoch: 36/40, Batch: 9/62, Discriminator loss: 0.5611334443092346, Generator loss: 0.3131818473339081\n",
      "Epoch: 36/40, Batch: 10/62, Discriminator loss: 0.5411887764930725, Generator loss: 0.3080306947231293\n",
      "Epoch: 36/40, Batch: 11/62, Discriminator loss: 0.5823342800140381, Generator loss: 0.30131611227989197\n",
      "Epoch: 36/40, Batch: 12/62, Discriminator loss: 0.46430978178977966, Generator loss: 0.2837011218070984\n",
      "Epoch: 36/40, Batch: 13/62, Discriminator loss: 0.5800071954727173, Generator loss: 0.2737094759941101\n",
      "Epoch: 36/40, Batch: 14/62, Discriminator loss: 0.5669471025466919, Generator loss: 0.26183345913887024\n",
      "Epoch: 36/40, Batch: 15/62, Discriminator loss: 0.532066822052002, Generator loss: 0.2604379653930664\n",
      "Epoch: 36/40, Batch: 16/62, Discriminator loss: 0.4201193153858185, Generator loss: 0.2478414624929428\n",
      "Epoch: 36/40, Batch: 17/62, Discriminator loss: 0.614883303642273, Generator loss: 0.24928289651870728\n",
      "Epoch: 36/40, Batch: 18/62, Discriminator loss: 0.5753093957901001, Generator loss: 0.24958102405071259\n",
      "Epoch: 36/40, Batch: 19/62, Discriminator loss: 0.5438724756240845, Generator loss: 0.2650053799152374\n",
      "Epoch: 36/40, Batch: 20/62, Discriminator loss: 0.5959247946739197, Generator loss: 0.2598017752170563\n",
      "Epoch: 36/40, Batch: 21/62, Discriminator loss: 0.5301933288574219, Generator loss: 0.2644231915473938\n",
      "Epoch: 36/40, Batch: 22/62, Discriminator loss: 0.6184338927268982, Generator loss: 0.26904112100601196\n",
      "Epoch: 36/40, Batch: 23/62, Discriminator loss: 0.5565730333328247, Generator loss: 0.2735889256000519\n",
      "Epoch: 36/40, Batch: 24/62, Discriminator loss: 0.42031291127204895, Generator loss: 0.2678263783454895\n",
      "Epoch: 36/40, Batch: 25/62, Discriminator loss: 0.6740219593048096, Generator loss: 0.277089923620224\n",
      "Epoch: 36/40, Batch: 26/62, Discriminator loss: 0.58049076795578, Generator loss: 0.2882835566997528\n",
      "Epoch: 36/40, Batch: 27/62, Discriminator loss: 0.5835487246513367, Generator loss: 0.28661641478538513\n",
      "Epoch: 36/40, Batch: 28/62, Discriminator loss: 0.6404780149459839, Generator loss: 0.2974967360496521\n",
      "Epoch: 36/40, Batch: 29/62, Discriminator loss: 0.5848404765129089, Generator loss: 0.3074466586112976\n",
      "Epoch: 36/40, Batch: 30/62, Discriminator loss: 0.5365912318229675, Generator loss: 0.3107125759124756\n",
      "Epoch: 36/40, Batch: 31/62, Discriminator loss: 0.5645391941070557, Generator loss: 0.30454370379447937\n",
      "Epoch: 36/40, Batch: 32/62, Discriminator loss: 0.5760742425918579, Generator loss: 0.31012776494026184\n",
      "Epoch: 36/40, Batch: 33/62, Discriminator loss: 0.48293614387512207, Generator loss: 0.30920398235321045\n",
      "Epoch: 36/40, Batch: 34/62, Discriminator loss: 0.6731405258178711, Generator loss: 0.3211885988712311\n",
      "Epoch: 36/40, Batch: 35/62, Discriminator loss: 0.538902759552002, Generator loss: 0.3128809630870819\n",
      "Epoch: 36/40, Batch: 36/62, Discriminator loss: 0.6310323476791382, Generator loss: 0.32745829224586487\n",
      "Epoch: 36/40, Batch: 37/62, Discriminator loss: 0.5356227159500122, Generator loss: 0.3265846371650696\n",
      "Epoch: 36/40, Batch: 38/62, Discriminator loss: 0.5244978666305542, Generator loss: 0.332135409116745\n",
      "Epoch: 36/40, Batch: 39/62, Discriminator loss: 0.534250020980835, Generator loss: 0.31097716093063354\n",
      "Epoch: 36/40, Batch: 40/62, Discriminator loss: 0.6538877487182617, Generator loss: 0.3167559802532196\n",
      "Epoch: 36/40, Batch: 41/62, Discriminator loss: 0.614446222782135, Generator loss: 0.31569913029670715\n",
      "Epoch: 36/40, Batch: 42/62, Discriminator loss: 0.523770809173584, Generator loss: 0.3019922971725464\n",
      "Epoch: 36/40, Batch: 43/62, Discriminator loss: 0.5991881489753723, Generator loss: 0.29977044463157654\n",
      "Epoch: 36/40, Batch: 44/62, Discriminator loss: 0.5367953777313232, Generator loss: 0.2910100817680359\n",
      "Epoch: 36/40, Batch: 45/62, Discriminator loss: 0.6176148653030396, Generator loss: 0.2772069275379181\n",
      "Epoch: 36/40, Batch: 46/62, Discriminator loss: 0.5888349413871765, Generator loss: 0.27788057923316956\n",
      "Epoch: 36/40, Batch: 47/62, Discriminator loss: 0.5567829608917236, Generator loss: 0.2764987349510193\n",
      "Epoch: 36/40, Batch: 48/62, Discriminator loss: 0.6577578783035278, Generator loss: 0.27655115723609924\n",
      "Epoch: 36/40, Batch: 49/62, Discriminator loss: 0.5502616167068481, Generator loss: 0.2738824486732483\n",
      "Epoch: 36/40, Batch: 50/62, Discriminator loss: 0.5618046522140503, Generator loss: 0.27184930443763733\n",
      "Epoch: 36/40, Batch: 51/62, Discriminator loss: 0.6168514490127563, Generator loss: 0.2601360082626343\n",
      "Epoch: 36/40, Batch: 52/62, Discriminator loss: 0.5431513786315918, Generator loss: 0.2698921859264374\n",
      "Epoch: 36/40, Batch: 53/62, Discriminator loss: 0.6105896234512329, Generator loss: 0.2665075361728668\n",
      "Epoch: 36/40, Batch: 54/62, Discriminator loss: 0.5684903860092163, Generator loss: 0.27045291662216187\n",
      "Epoch: 36/40, Batch: 55/62, Discriminator loss: 0.6270725727081299, Generator loss: 0.2668696343898773\n",
      "Epoch: 36/40, Batch: 56/62, Discriminator loss: 0.562321662902832, Generator loss: 0.2651868164539337\n",
      "Epoch: 36/40, Batch: 57/62, Discriminator loss: 0.5418172478675842, Generator loss: 0.2685946226119995\n",
      "Epoch: 36/40, Batch: 58/62, Discriminator loss: 0.6162211894989014, Generator loss: 0.27124935388565063\n",
      "Epoch: 36/40, Batch: 59/62, Discriminator loss: 0.587141752243042, Generator loss: 0.2810429632663727\n",
      "Epoch: 36/40, Batch: 60/62, Discriminator loss: 0.6476523280143738, Generator loss: 0.28813615441322327\n",
      "Epoch: 36/40, Batch: 61/62, Discriminator loss: 0.6042788028717041, Generator loss: 0.2905453145503998\n",
      "Epoch: 36/40, Batch: 62/62, Discriminator loss: 0.5405725240707397, Generator loss: 0.28714579343795776\n",
      "Epoch: 37/40, Batch: 1/62, Discriminator loss: 0.5624199509620667, Generator loss: 0.2975599765777588\n",
      "Epoch: 37/40, Batch: 2/62, Discriminator loss: 0.593800961971283, Generator loss: 0.3004351556301117\n",
      "Epoch: 37/40, Batch: 3/62, Discriminator loss: 0.448182076215744, Generator loss: 0.2887740731239319\n",
      "Epoch: 37/40, Batch: 4/62, Discriminator loss: 0.6307864785194397, Generator loss: 0.29584410786628723\n",
      "Epoch: 37/40, Batch: 5/62, Discriminator loss: 0.5899872183799744, Generator loss: 0.2980443239212036\n",
      "Epoch: 37/40, Batch: 6/62, Discriminator loss: 0.5988390445709229, Generator loss: 0.3106135427951813\n",
      "Epoch: 37/40, Batch: 7/62, Discriminator loss: 0.5408180356025696, Generator loss: 0.3043537437915802\n",
      "Epoch: 37/40, Batch: 8/62, Discriminator loss: 0.5298237204551697, Generator loss: 0.3119738698005676\n",
      "Epoch: 37/40, Batch: 9/62, Discriminator loss: 0.5621234774589539, Generator loss: 0.3116742968559265\n",
      "Epoch: 37/40, Batch: 10/62, Discriminator loss: 0.5572983026504517, Generator loss: 0.3245250880718231\n",
      "Epoch: 37/40, Batch: 11/62, Discriminator loss: 0.5710269212722778, Generator loss: 0.32903480529785156\n",
      "Epoch: 37/40, Batch: 12/62, Discriminator loss: 0.4627155065536499, Generator loss: 0.3124071955680847\n",
      "Epoch: 37/40, Batch: 13/62, Discriminator loss: 0.544131338596344, Generator loss: 0.3127215504646301\n",
      "Epoch: 37/40, Batch: 14/62, Discriminator loss: 0.5589410662651062, Generator loss: 0.30995050072669983\n",
      "Epoch: 37/40, Batch: 15/62, Discriminator loss: 0.5227344036102295, Generator loss: 0.30406951904296875\n",
      "Epoch: 37/40, Batch: 16/62, Discriminator loss: 0.4530409276485443, Generator loss: 0.2856411337852478\n",
      "Epoch: 37/40, Batch: 17/62, Discriminator loss: 0.5725342035293579, Generator loss: 0.27917999029159546\n",
      "Epoch: 37/40, Batch: 18/62, Discriminator loss: 0.582711935043335, Generator loss: 0.28330403566360474\n",
      "Epoch: 37/40, Batch: 19/62, Discriminator loss: 0.5399326682090759, Generator loss: 0.28144270181655884\n",
      "Epoch: 37/40, Batch: 20/62, Discriminator loss: 0.6075953245162964, Generator loss: 0.27914533019065857\n",
      "Epoch: 37/40, Batch: 21/62, Discriminator loss: 0.5684608221054077, Generator loss: 0.29088300466537476\n",
      "Epoch: 37/40, Batch: 22/62, Discriminator loss: 0.6172592043876648, Generator loss: 0.29889562726020813\n",
      "Epoch: 37/40, Batch: 23/62, Discriminator loss: 0.5816243886947632, Generator loss: 0.29554009437561035\n",
      "Epoch: 37/40, Batch: 24/62, Discriminator loss: 0.49405062198638916, Generator loss: 0.285844087600708\n",
      "Epoch: 37/40, Batch: 25/62, Discriminator loss: 0.6913121938705444, Generator loss: 0.27775704860687256\n",
      "Epoch: 37/40, Batch: 26/62, Discriminator loss: 0.6073174476623535, Generator loss: 0.28210437297821045\n",
      "Epoch: 37/40, Batch: 27/62, Discriminator loss: 0.6024339199066162, Generator loss: 0.29288429021835327\n",
      "Epoch: 37/40, Batch: 28/62, Discriminator loss: 0.6442184448242188, Generator loss: 0.29701754450798035\n",
      "Epoch: 37/40, Batch: 29/62, Discriminator loss: 0.5958048701286316, Generator loss: 0.3011769950389862\n",
      "Epoch: 37/40, Batch: 30/62, Discriminator loss: 0.5343737006187439, Generator loss: 0.28963637351989746\n",
      "Epoch: 37/40, Batch: 31/62, Discriminator loss: 0.5763851404190063, Generator loss: 0.29039111733436584\n",
      "Epoch: 37/40, Batch: 32/62, Discriminator loss: 0.5935612916946411, Generator loss: 0.28582897782325745\n",
      "Epoch: 37/40, Batch: 33/62, Discriminator loss: 0.4496138095855713, Generator loss: 0.2791220247745514\n",
      "Epoch: 37/40, Batch: 34/62, Discriminator loss: 0.6967397928237915, Generator loss: 0.2710092067718506\n",
      "Epoch: 37/40, Batch: 35/62, Discriminator loss: 0.5584720373153687, Generator loss: 0.284071147441864\n",
      "Epoch: 37/40, Batch: 36/62, Discriminator loss: 0.6378612518310547, Generator loss: 0.28063836693763733\n",
      "Epoch: 37/40, Batch: 37/62, Discriminator loss: 0.5392917394638062, Generator loss: 0.2812654972076416\n",
      "Epoch: 37/40, Batch: 38/62, Discriminator loss: 0.5638992786407471, Generator loss: 0.2831801176071167\n",
      "Epoch: 37/40, Batch: 39/62, Discriminator loss: 0.5338380336761475, Generator loss: 0.2717847526073456\n",
      "Epoch: 37/40, Batch: 40/62, Discriminator loss: 0.6838144063949585, Generator loss: 0.27879050374031067\n",
      "Epoch: 37/40, Batch: 41/62, Discriminator loss: 0.6077823638916016, Generator loss: 0.29739245772361755\n",
      "Epoch: 37/40, Batch: 42/62, Discriminator loss: 0.5280200242996216, Generator loss: 0.29570168256759644\n",
      "Epoch: 37/40, Batch: 43/62, Discriminator loss: 0.5906919240951538, Generator loss: 0.28232237696647644\n",
      "Epoch: 37/40, Batch: 44/62, Discriminator loss: 0.523539662361145, Generator loss: 0.2862837314605713\n",
      "Epoch: 37/40, Batch: 45/62, Discriminator loss: 0.619057297706604, Generator loss: 0.2890692353248596\n",
      "Epoch: 37/40, Batch: 46/62, Discriminator loss: 0.5856993198394775, Generator loss: 0.288813978433609\n",
      "Epoch: 37/40, Batch: 47/62, Discriminator loss: 0.5386645197868347, Generator loss: 0.28981876373291016\n",
      "Epoch: 37/40, Batch: 48/62, Discriminator loss: 0.6448616981506348, Generator loss: 0.29569771885871887\n",
      "Epoch: 37/40, Batch: 49/62, Discriminator loss: 0.5081942081451416, Generator loss: 0.29203569889068604\n",
      "Epoch: 37/40, Batch: 50/62, Discriminator loss: 0.5680016279220581, Generator loss: 0.2985357940196991\n",
      "Epoch: 37/40, Batch: 51/62, Discriminator loss: 0.5990986824035645, Generator loss: 0.29957276582717896\n",
      "Epoch: 37/40, Batch: 52/62, Discriminator loss: 0.5469995141029358, Generator loss: 0.29681098461151123\n",
      "Epoch: 37/40, Batch: 53/62, Discriminator loss: 0.6053738594055176, Generator loss: 0.3060494661331177\n",
      "Epoch: 37/40, Batch: 54/62, Discriminator loss: 0.574748158454895, Generator loss: 0.3064376413822174\n",
      "Epoch: 37/40, Batch: 55/62, Discriminator loss: 0.6168294548988342, Generator loss: 0.3158234655857086\n",
      "Epoch: 37/40, Batch: 56/62, Discriminator loss: 0.5766803622245789, Generator loss: 0.3268190324306488\n",
      "Epoch: 37/40, Batch: 57/62, Discriminator loss: 0.5568550825119019, Generator loss: 0.32209423184394836\n",
      "Epoch: 37/40, Batch: 58/62, Discriminator loss: 0.6089043617248535, Generator loss: 0.33943361043930054\n",
      "Epoch: 37/40, Batch: 59/62, Discriminator loss: 0.6065433621406555, Generator loss: 0.34079834818840027\n",
      "Epoch: 37/40, Batch: 60/62, Discriminator loss: 0.6379855871200562, Generator loss: 0.3657667338848114\n",
      "Epoch: 37/40, Batch: 61/62, Discriminator loss: 0.592921793460846, Generator loss: 0.35670071840286255\n",
      "Epoch: 37/40, Batch: 62/62, Discriminator loss: 0.539323091506958, Generator loss: 0.3568341135978699\n",
      "Epoch: 38/40, Batch: 1/62, Discriminator loss: 0.5772868394851685, Generator loss: 0.355299174785614\n",
      "Epoch: 38/40, Batch: 2/62, Discriminator loss: 0.5734907388687134, Generator loss: 0.33565637469291687\n",
      "Epoch: 38/40, Batch: 3/62, Discriminator loss: 0.46750345826148987, Generator loss: 0.3191791772842407\n",
      "Epoch: 38/40, Batch: 4/62, Discriminator loss: 0.6069929599761963, Generator loss: 0.3002273142337799\n",
      "Epoch: 38/40, Batch: 5/62, Discriminator loss: 0.6069647073745728, Generator loss: 0.295380562543869\n",
      "Epoch: 38/40, Batch: 6/62, Discriminator loss: 0.5968379974365234, Generator loss: 0.2980160117149353\n",
      "Epoch: 38/40, Batch: 7/62, Discriminator loss: 0.550562858581543, Generator loss: 0.2894803285598755\n",
      "Epoch: 38/40, Batch: 8/62, Discriminator loss: 0.5140640735626221, Generator loss: 0.2802448272705078\n",
      "Epoch: 38/40, Batch: 9/62, Discriminator loss: 0.576438307762146, Generator loss: 0.2802317142486572\n",
      "Epoch: 38/40, Batch: 10/62, Discriminator loss: 0.5804332494735718, Generator loss: 0.28079837560653687\n",
      "Epoch: 38/40, Batch: 11/62, Discriminator loss: 0.6046329736709595, Generator loss: 0.27112454175949097\n",
      "Epoch: 38/40, Batch: 12/62, Discriminator loss: 0.44819876551628113, Generator loss: 0.2692992687225342\n",
      "Epoch: 38/40, Batch: 13/62, Discriminator loss: 0.5724288821220398, Generator loss: 0.2676982581615448\n",
      "Epoch: 38/40, Batch: 14/62, Discriminator loss: 0.565667986869812, Generator loss: 0.259547621011734\n",
      "Epoch: 38/40, Batch: 15/62, Discriminator loss: 0.5113484859466553, Generator loss: 0.25412753224372864\n",
      "Epoch: 38/40, Batch: 16/62, Discriminator loss: 0.4261341691017151, Generator loss: 0.23979522287845612\n",
      "Epoch: 38/40, Batch: 17/62, Discriminator loss: 0.6015246510505676, Generator loss: 0.2445286512374878\n",
      "Epoch: 38/40, Batch: 18/62, Discriminator loss: 0.5856077075004578, Generator loss: 0.2379159927368164\n",
      "Epoch: 38/40, Batch: 19/62, Discriminator loss: 0.5628377199172974, Generator loss: 0.24949778616428375\n",
      "Epoch: 38/40, Batch: 20/62, Discriminator loss: 0.6344234943389893, Generator loss: 0.2569253742694855\n",
      "Epoch: 38/40, Batch: 21/62, Discriminator loss: 0.5572395920753479, Generator loss: 0.26067790389060974\n",
      "Epoch: 38/40, Batch: 22/62, Discriminator loss: 0.6281450390815735, Generator loss: 0.27347081899642944\n",
      "Epoch: 38/40, Batch: 23/62, Discriminator loss: 0.5675027370452881, Generator loss: 0.2879839539527893\n",
      "Epoch: 38/40, Batch: 24/62, Discriminator loss: 0.4340856075286865, Generator loss: 0.2741590142250061\n",
      "Epoch: 38/40, Batch: 25/62, Discriminator loss: 0.6755236387252808, Generator loss: 0.28454455733299255\n",
      "Epoch: 38/40, Batch: 26/62, Discriminator loss: 0.6140788197517395, Generator loss: 0.2933533489704132\n",
      "Epoch: 38/40, Batch: 27/62, Discriminator loss: 0.5681233406066895, Generator loss: 0.31836768984794617\n",
      "Epoch: 38/40, Batch: 28/62, Discriminator loss: 0.6151453852653503, Generator loss: 0.31989768147468567\n",
      "Epoch: 38/40, Batch: 29/62, Discriminator loss: 0.5526368021965027, Generator loss: 0.32606926560401917\n",
      "Epoch: 38/40, Batch: 30/62, Discriminator loss: 0.5197142362594604, Generator loss: 0.318796843290329\n",
      "Epoch: 38/40, Batch: 31/62, Discriminator loss: 0.5541843175888062, Generator loss: 0.3105350732803345\n",
      "Epoch: 38/40, Batch: 32/62, Discriminator loss: 0.5745295286178589, Generator loss: 0.30778130888938904\n",
      "Epoch: 38/40, Batch: 33/62, Discriminator loss: 0.4781528413295746, Generator loss: 0.2881779074668884\n",
      "Epoch: 38/40, Batch: 34/62, Discriminator loss: 0.6759973764419556, Generator loss: 0.2974303960800171\n",
      "Epoch: 38/40, Batch: 35/62, Discriminator loss: 0.557058572769165, Generator loss: 0.2867240309715271\n",
      "Epoch: 38/40, Batch: 36/62, Discriminator loss: 0.6510773301124573, Generator loss: 0.29843589663505554\n",
      "Epoch: 38/40, Batch: 37/62, Discriminator loss: 0.5691931843757629, Generator loss: 0.2953341007232666\n",
      "Epoch: 38/40, Batch: 38/62, Discriminator loss: 0.5502539873123169, Generator loss: 0.29805701971054077\n",
      "Epoch: 38/40, Batch: 39/62, Discriminator loss: 0.5477074384689331, Generator loss: 0.28279170393943787\n",
      "Epoch: 38/40, Batch: 40/62, Discriminator loss: 0.6623766422271729, Generator loss: 0.29132670164108276\n",
      "Epoch: 38/40, Batch: 41/62, Discriminator loss: 0.6223810911178589, Generator loss: 0.2918574810028076\n",
      "Epoch: 38/40, Batch: 42/62, Discriminator loss: 0.5210158824920654, Generator loss: 0.28751668334007263\n",
      "Epoch: 38/40, Batch: 43/62, Discriminator loss: 0.5975782871246338, Generator loss: 0.2757842540740967\n",
      "Epoch: 38/40, Batch: 44/62, Discriminator loss: 0.533849835395813, Generator loss: 0.27765533328056335\n",
      "Epoch: 38/40, Batch: 45/62, Discriminator loss: 0.6232908964157104, Generator loss: 0.27790188789367676\n",
      "Epoch: 38/40, Batch: 46/62, Discriminator loss: 0.6192302703857422, Generator loss: 0.2691921591758728\n",
      "Epoch: 38/40, Batch: 47/62, Discriminator loss: 0.5592431426048279, Generator loss: 0.2677129805088043\n",
      "Epoch: 38/40, Batch: 48/62, Discriminator loss: 0.6848793029785156, Generator loss: 0.26469069719314575\n",
      "Epoch: 38/40, Batch: 49/62, Discriminator loss: 0.5189476013183594, Generator loss: 0.26703527569770813\n",
      "Epoch: 38/40, Batch: 50/62, Discriminator loss: 0.5742905139923096, Generator loss: 0.2717588543891907\n",
      "Epoch: 38/40, Batch: 51/62, Discriminator loss: 0.6343273520469666, Generator loss: 0.281196266412735\n",
      "Epoch: 38/40, Batch: 52/62, Discriminator loss: 0.5616172552108765, Generator loss: 0.28319987654685974\n",
      "Epoch: 38/40, Batch: 53/62, Discriminator loss: 0.6292495727539062, Generator loss: 0.292278528213501\n",
      "Epoch: 38/40, Batch: 54/62, Discriminator loss: 0.5771317481994629, Generator loss: 0.2903066575527191\n",
      "Epoch: 38/40, Batch: 55/62, Discriminator loss: 0.6090153455734253, Generator loss: 0.30858004093170166\n",
      "Epoch: 38/40, Batch: 56/62, Discriminator loss: 0.5548725128173828, Generator loss: 0.3123081624507904\n",
      "Epoch: 38/40, Batch: 57/62, Discriminator loss: 0.5596620440483093, Generator loss: 0.3175707757472992\n",
      "Epoch: 38/40, Batch: 58/62, Discriminator loss: 0.6044409871101379, Generator loss: 0.32574519515037537\n",
      "Epoch: 38/40, Batch: 59/62, Discriminator loss: 0.5725948810577393, Generator loss: 0.3310060501098633\n",
      "Epoch: 38/40, Batch: 60/62, Discriminator loss: 0.6191822290420532, Generator loss: 0.33588019013404846\n",
      "Epoch: 38/40, Batch: 61/62, Discriminator loss: 0.590901255607605, Generator loss: 0.3266163766384125\n",
      "Epoch: 38/40, Batch: 62/62, Discriminator loss: 0.5189999341964722, Generator loss: 0.3169766068458557\n",
      "Epoch: 39/40, Batch: 1/62, Discriminator loss: 0.5657589435577393, Generator loss: 0.3289884924888611\n",
      "Epoch: 39/40, Batch: 2/62, Discriminator loss: 0.5840457677841187, Generator loss: 0.30553650856018066\n",
      "Epoch: 39/40, Batch: 3/62, Discriminator loss: 0.4473724365234375, Generator loss: 0.3031651973724365\n",
      "Epoch: 39/40, Batch: 4/62, Discriminator loss: 0.6305663585662842, Generator loss: 0.27820587158203125\n",
      "Epoch: 39/40, Batch: 5/62, Discriminator loss: 0.6249438524246216, Generator loss: 0.283161461353302\n",
      "Epoch: 39/40, Batch: 6/62, Discriminator loss: 0.5991355180740356, Generator loss: 0.2994960844516754\n",
      "Epoch: 39/40, Batch: 7/62, Discriminator loss: 0.5457546710968018, Generator loss: 0.3008798658847809\n",
      "Epoch: 39/40, Batch: 8/62, Discriminator loss: 0.5125672817230225, Generator loss: 0.2906734347343445\n",
      "Epoch: 39/40, Batch: 9/62, Discriminator loss: 0.5886257886886597, Generator loss: 0.29737725853919983\n",
      "Epoch: 39/40, Batch: 10/62, Discriminator loss: 0.5663518309593201, Generator loss: 0.3016815781593323\n",
      "Epoch: 39/40, Batch: 11/62, Discriminator loss: 0.5779682993888855, Generator loss: 0.2975502014160156\n",
      "Epoch: 39/40, Batch: 12/62, Discriminator loss: 0.4211612343788147, Generator loss: 0.28397420048713684\n",
      "Epoch: 39/40, Batch: 13/62, Discriminator loss: 0.5572323799133301, Generator loss: 0.2764194905757904\n",
      "Epoch: 39/40, Batch: 14/62, Discriminator loss: 0.5282497406005859, Generator loss: 0.2811117470264435\n",
      "Epoch: 39/40, Batch: 15/62, Discriminator loss: 0.5169774293899536, Generator loss: 0.2594143748283386\n",
      "Epoch: 39/40, Batch: 16/62, Discriminator loss: 0.41349202394485474, Generator loss: 0.24150817096233368\n",
      "Epoch: 39/40, Batch: 17/62, Discriminator loss: 0.5971773862838745, Generator loss: 0.2481192648410797\n",
      "Epoch: 39/40, Batch: 18/62, Discriminator loss: 0.5827400088310242, Generator loss: 0.23906086385250092\n",
      "Epoch: 39/40, Batch: 19/62, Discriminator loss: 0.5537439584732056, Generator loss: 0.25931301712989807\n",
      "Epoch: 39/40, Batch: 20/62, Discriminator loss: 0.6226857900619507, Generator loss: 0.26652127504348755\n",
      "Epoch: 39/40, Batch: 21/62, Discriminator loss: 0.5693612098693848, Generator loss: 0.2761164605617523\n",
      "Epoch: 39/40, Batch: 22/62, Discriminator loss: 0.6461570262908936, Generator loss: 0.295552521944046\n",
      "Epoch: 39/40, Batch: 23/62, Discriminator loss: 0.568533182144165, Generator loss: 0.30005738139152527\n",
      "Epoch: 39/40, Batch: 24/62, Discriminator loss: 0.444107323884964, Generator loss: 0.28921565413475037\n",
      "Epoch: 39/40, Batch: 25/62, Discriminator loss: 0.6913914084434509, Generator loss: 0.29645833373069763\n",
      "Epoch: 39/40, Batch: 26/62, Discriminator loss: 0.603733479976654, Generator loss: 0.32194751501083374\n",
      "Epoch: 39/40, Batch: 27/62, Discriminator loss: 0.5703021287918091, Generator loss: 0.3236508071422577\n",
      "Epoch: 39/40, Batch: 28/62, Discriminator loss: 0.62090003490448, Generator loss: 0.34468740224838257\n",
      "Epoch: 39/40, Batch: 29/62, Discriminator loss: 0.563452959060669, Generator loss: 0.3449550271034241\n",
      "Epoch: 39/40, Batch: 30/62, Discriminator loss: 0.5190351009368896, Generator loss: 0.3276183009147644\n",
      "Epoch: 39/40, Batch: 31/62, Discriminator loss: 0.5550704002380371, Generator loss: 0.32436081767082214\n",
      "Epoch: 39/40, Batch: 32/62, Discriminator loss: 0.5719745755195618, Generator loss: 0.3159230649471283\n",
      "Epoch: 39/40, Batch: 33/62, Discriminator loss: 0.483042448759079, Generator loss: 0.29362109303474426\n",
      "Epoch: 39/40, Batch: 34/62, Discriminator loss: 0.6805182099342346, Generator loss: 0.2873002886772156\n",
      "Epoch: 39/40, Batch: 35/62, Discriminator loss: 0.5594500303268433, Generator loss: 0.30205050110816956\n",
      "Epoch: 39/40, Batch: 36/62, Discriminator loss: 0.6338195204734802, Generator loss: 0.2920900881290436\n",
      "Epoch: 39/40, Batch: 37/62, Discriminator loss: 0.5652263760566711, Generator loss: 0.27757060527801514\n",
      "Epoch: 39/40, Batch: 38/62, Discriminator loss: 0.5533846616744995, Generator loss: 0.2838842570781708\n",
      "Epoch: 39/40, Batch: 39/62, Discriminator loss: 0.5565109848976135, Generator loss: 0.27878308296203613\n",
      "Epoch: 39/40, Batch: 40/62, Discriminator loss: 0.6568429470062256, Generator loss: 0.28363877534866333\n",
      "Epoch: 39/40, Batch: 41/62, Discriminator loss: 0.606149435043335, Generator loss: 0.27336519956588745\n",
      "Epoch: 39/40, Batch: 42/62, Discriminator loss: 0.5361585021018982, Generator loss: 0.2829909920692444\n",
      "Epoch: 39/40, Batch: 43/62, Discriminator loss: 0.6056342720985413, Generator loss: 0.2796974182128906\n",
      "Epoch: 39/40, Batch: 44/62, Discriminator loss: 0.5145895481109619, Generator loss: 0.26943519711494446\n",
      "Epoch: 39/40, Batch: 45/62, Discriminator loss: 0.6194415092468262, Generator loss: 0.26620736718177795\n",
      "Epoch: 39/40, Batch: 46/62, Discriminator loss: 0.562886118888855, Generator loss: 0.26813721656799316\n",
      "Epoch: 39/40, Batch: 47/62, Discriminator loss: 0.5372028350830078, Generator loss: 0.2670825123786926\n",
      "Epoch: 39/40, Batch: 48/62, Discriminator loss: 0.6579717993736267, Generator loss: 0.2783011794090271\n",
      "Epoch: 39/40, Batch: 49/62, Discriminator loss: 0.5207782983779907, Generator loss: 0.2730012834072113\n",
      "Epoch: 39/40, Batch: 50/62, Discriminator loss: 0.5635849237442017, Generator loss: 0.27489396929740906\n",
      "Epoch: 39/40, Batch: 51/62, Discriminator loss: 0.5988935232162476, Generator loss: 0.26548653841018677\n",
      "Epoch: 39/40, Batch: 52/62, Discriminator loss: 0.5317829251289368, Generator loss: 0.26845088601112366\n",
      "Epoch: 39/40, Batch: 53/62, Discriminator loss: 0.6224480271339417, Generator loss: 0.27467554807662964\n",
      "Epoch: 39/40, Batch: 54/62, Discriminator loss: 0.5780097246170044, Generator loss: 0.2851822078227997\n",
      "Epoch: 39/40, Batch: 55/62, Discriminator loss: 0.6163291931152344, Generator loss: 0.27969324588775635\n",
      "Epoch: 39/40, Batch: 56/62, Discriminator loss: 0.604391872882843, Generator loss: 0.29884591698646545\n",
      "Epoch: 39/40, Batch: 57/62, Discriminator loss: 0.5691542029380798, Generator loss: 0.2962713837623596\n",
      "Epoch: 39/40, Batch: 58/62, Discriminator loss: 0.6266223788261414, Generator loss: 0.3054034113883972\n",
      "Epoch: 39/40, Batch: 59/62, Discriminator loss: 0.6269264221191406, Generator loss: 0.32320520281791687\n",
      "Epoch: 39/40, Batch: 60/62, Discriminator loss: 0.6278780102729797, Generator loss: 0.33659860491752625\n",
      "Epoch: 39/40, Batch: 61/62, Discriminator loss: 0.6320295929908752, Generator loss: 0.346699982881546\n",
      "Epoch: 39/40, Batch: 62/62, Discriminator loss: 0.5283547639846802, Generator loss: 0.3506799042224884\n",
      "Epoch: 40/40, Batch: 1/62, Discriminator loss: 0.5680655241012573, Generator loss: 0.3358652591705322\n",
      "Epoch: 40/40, Batch: 2/62, Discriminator loss: 0.5928661227226257, Generator loss: 0.34501248598098755\n",
      "Epoch: 40/40, Batch: 3/62, Discriminator loss: 0.4385301172733307, Generator loss: 0.3319597542285919\n",
      "Epoch: 40/40, Batch: 4/62, Discriminator loss: 0.6193046569824219, Generator loss: 0.3241969645023346\n",
      "Epoch: 40/40, Batch: 5/62, Discriminator loss: 0.5883123278617859, Generator loss: 0.3254154622554779\n",
      "Epoch: 40/40, Batch: 6/62, Discriminator loss: 0.5819941759109497, Generator loss: 0.3151935040950775\n",
      "Epoch: 40/40, Batch: 7/62, Discriminator loss: 0.5448019504547119, Generator loss: 0.3216628432273865\n",
      "Epoch: 40/40, Batch: 8/62, Discriminator loss: 0.5118236541748047, Generator loss: 0.307331383228302\n",
      "Epoch: 40/40, Batch: 9/62, Discriminator loss: 0.592670738697052, Generator loss: 0.3039973974227905\n",
      "Epoch: 40/40, Batch: 10/62, Discriminator loss: 0.5741318464279175, Generator loss: 0.31177613139152527\n",
      "Epoch: 40/40, Batch: 11/62, Discriminator loss: 0.6009289026260376, Generator loss: 0.3043759763240814\n",
      "Epoch: 40/40, Batch: 12/62, Discriminator loss: 0.4713911712169647, Generator loss: 0.29608795046806335\n",
      "Epoch: 40/40, Batch: 13/62, Discriminator loss: 0.5796535015106201, Generator loss: 0.2824484407901764\n",
      "Epoch: 40/40, Batch: 14/62, Discriminator loss: 0.5677076578140259, Generator loss: 0.28609734773635864\n",
      "Epoch: 40/40, Batch: 15/62, Discriminator loss: 0.5415892601013184, Generator loss: 0.2716844081878662\n",
      "Epoch: 40/40, Batch: 16/62, Discriminator loss: 0.45811256766319275, Generator loss: 0.26305386424064636\n",
      "Epoch: 40/40, Batch: 17/62, Discriminator loss: 0.5719954967498779, Generator loss: 0.2540566325187683\n",
      "Epoch: 40/40, Batch: 18/62, Discriminator loss: 0.5561167001724243, Generator loss: 0.25911590456962585\n",
      "Epoch: 40/40, Batch: 19/62, Discriminator loss: 0.5462711453437805, Generator loss: 0.2572605013847351\n",
      "Epoch: 40/40, Batch: 20/62, Discriminator loss: 0.6246073246002197, Generator loss: 0.2618524432182312\n",
      "Epoch: 40/40, Batch: 21/62, Discriminator loss: 0.543053388595581, Generator loss: 0.2616719901561737\n",
      "Epoch: 40/40, Batch: 22/62, Discriminator loss: 0.6517196893692017, Generator loss: 0.2683640122413635\n",
      "Epoch: 40/40, Batch: 23/62, Discriminator loss: 0.5998210310935974, Generator loss: 0.27656087279319763\n",
      "Epoch: 40/40, Batch: 24/62, Discriminator loss: 0.4637857675552368, Generator loss: 0.2670484781265259\n",
      "Epoch: 40/40, Batch: 25/62, Discriminator loss: 0.718021035194397, Generator loss: 0.2831314504146576\n",
      "Epoch: 40/40, Batch: 26/62, Discriminator loss: 0.6231483221054077, Generator loss: 0.29354286193847656\n",
      "Epoch: 40/40, Batch: 27/62, Discriminator loss: 0.5902122855186462, Generator loss: 0.29985201358795166\n",
      "Epoch: 40/40, Batch: 28/62, Discriminator loss: 0.6268627047538757, Generator loss: 0.3245473802089691\n",
      "Epoch: 40/40, Batch: 29/62, Discriminator loss: 0.5834620594978333, Generator loss: 0.3190697729587555\n",
      "Epoch: 40/40, Batch: 30/62, Discriminator loss: 0.5344415903091431, Generator loss: 0.32680773735046387\n",
      "Epoch: 40/40, Batch: 31/62, Discriminator loss: 0.5653781890869141, Generator loss: 0.3210636377334595\n",
      "Epoch: 40/40, Batch: 32/62, Discriminator loss: 0.5527324080467224, Generator loss: 0.31841549277305603\n",
      "Epoch: 40/40, Batch: 33/62, Discriminator loss: 0.44046276807785034, Generator loss: 0.30834290385246277\n",
      "Epoch: 40/40, Batch: 34/62, Discriminator loss: 0.6600692272186279, Generator loss: 0.3210729658603668\n",
      "Epoch: 40/40, Batch: 35/62, Discriminator loss: 0.533755898475647, Generator loss: 0.3177415728569031\n",
      "Epoch: 40/40, Batch: 36/62, Discriminator loss: 0.6504955291748047, Generator loss: 0.3070600628852844\n",
      "Epoch: 40/40, Batch: 37/62, Discriminator loss: 0.5504636168479919, Generator loss: 0.30919426679611206\n",
      "Epoch: 40/40, Batch: 38/62, Discriminator loss: 0.5470114946365356, Generator loss: 0.3054352402687073\n",
      "Epoch: 40/40, Batch: 39/62, Discriminator loss: 0.5718910694122314, Generator loss: 0.29586341977119446\n",
      "Epoch: 40/40, Batch: 40/62, Discriminator loss: 0.672486424446106, Generator loss: 0.30795732140541077\n",
      "Epoch: 40/40, Batch: 41/62, Discriminator loss: 0.6073600649833679, Generator loss: 0.3204880356788635\n",
      "Epoch: 40/40, Batch: 42/62, Discriminator loss: 0.5375916957855225, Generator loss: 0.3196357488632202\n",
      "Epoch: 40/40, Batch: 43/62, Discriminator loss: 0.5915855169296265, Generator loss: 0.3093292713165283\n",
      "Epoch: 40/40, Batch: 44/62, Discriminator loss: 0.5511931777000427, Generator loss: 0.31779149174690247\n",
      "Epoch: 40/40, Batch: 45/62, Discriminator loss: 0.5928576588630676, Generator loss: 0.31668946146965027\n",
      "Epoch: 40/40, Batch: 46/62, Discriminator loss: 0.5789288878440857, Generator loss: 0.31271687150001526\n",
      "Epoch: 40/40, Batch: 47/62, Discriminator loss: 0.5463835597038269, Generator loss: 0.3037169575691223\n",
      "Epoch: 40/40, Batch: 48/62, Discriminator loss: 0.6321940422058105, Generator loss: 0.3036039471626282\n",
      "Epoch: 40/40, Batch: 49/62, Discriminator loss: 0.5050917863845825, Generator loss: 0.2923300862312317\n",
      "Epoch: 40/40, Batch: 50/62, Discriminator loss: 0.5810785293579102, Generator loss: 0.2799166440963745\n",
      "Epoch: 40/40, Batch: 51/62, Discriminator loss: 0.6016975045204163, Generator loss: 0.2817203998565674\n",
      "Epoch: 40/40, Batch: 52/62, Discriminator loss: 0.5208355188369751, Generator loss: 0.2655462622642517\n",
      "Epoch: 40/40, Batch: 53/62, Discriminator loss: 0.6160247921943665, Generator loss: 0.26091518998146057\n",
      "Epoch: 40/40, Batch: 54/62, Discriminator loss: 0.5747077465057373, Generator loss: 0.27780067920684814\n",
      "Epoch: 40/40, Batch: 55/62, Discriminator loss: 0.6128827333450317, Generator loss: 0.27457907795906067\n",
      "Epoch: 40/40, Batch: 56/62, Discriminator loss: 0.5806026458740234, Generator loss: 0.27420327067375183\n",
      "Epoch: 40/40, Batch: 57/62, Discriminator loss: 0.5882868766784668, Generator loss: 0.2754928171634674\n",
      "Epoch: 40/40, Batch: 58/62, Discriminator loss: 0.6306500434875488, Generator loss: 0.29293516278266907\n",
      "Epoch: 40/40, Batch: 59/62, Discriminator loss: 0.5982372760772705, Generator loss: 0.2919948399066925\n",
      "Epoch: 40/40, Batch: 60/62, Discriminator loss: 0.6471180319786072, Generator loss: 0.3018094301223755\n",
      "Epoch: 40/40, Batch: 61/62, Discriminator loss: 0.5999849438667297, Generator loss: 0.3220922648906708\n",
      "Epoch: 40/40, Batch: 62/62, Discriminator loss: 0.5244742631912231, Generator loss: 0.3273502290248871\n",
      "Accuracy real: 25%, fake: 0%\n"
     ]
    }
   ],
   "source": [
    "# Models inspired by: https://machinelearningmastery.com/how-to-develop-a-generative-adversarial-network-for-an-mnist-handwritten-digits-from-scratch-in-keras/\n",
    "\n",
    "\n",
    "def discriminator():\n",
    "    discriminator_model = tf.keras.models.Sequential(name=\"discriminator\")\n",
    "    discriminator_model.add(tf.keras.layers.Conv2D(64, (3,3), strides=(2, 2), padding='same', input_shape=INPUT_SHAPE))\n",
    "    discriminator_model.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n",
    "    discriminator_model.add(tf.keras.layers.Dropout(0.4))\n",
    "    discriminator_model.add(tf.keras.layers.Conv2D(64, (3,3), strides=(2, 2), padding='same'))\n",
    "    discriminator_model.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n",
    "    discriminator_model.add(tf.keras.layers.Dropout(0.4))\n",
    "    discriminator_model.add(tf.keras.layers.Flatten())\n",
    "    discriminator_model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "    discriminator_model.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(lr=0.0002, beta_1=0.5), metrics=['accuracy'])\n",
    "    return discriminator_model\n",
    " \n",
    "\n",
    "def generator():\n",
    "    generator_model = tf.keras.models.Sequential(name=\"generator\")\n",
    "    # foundation for 8x8 image\n",
    "    n_nodes = 128 * 8 * 8\n",
    "    generator_model.add(tf.keras.layers.Dense(n_nodes, input_dim=LATENT_DIM))\n",
    "    generator_model.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n",
    "    generator_model.add(tf.keras.layers.Reshape((8, 8, 128)))\n",
    "    # Upsample to 16x16\n",
    "    generator_model.add(tf.keras.layers.Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n",
    "    generator_model.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n",
    "    # upsample to 32x32\n",
    "    generator_model.add(tf.keras.layers.Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n",
    "    generator_model.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n",
    "    generator_model.add(tf.keras.layers.Conv2D(3, (7,7), activation='sigmoid', padding='same'))\n",
    "    return generator_model\n",
    "\n",
    "\n",
    "def gan(generator_model, discriminator_model):\n",
    "    discriminator_model.trainable = False # freez discirminator\n",
    "    model = tf.keras.models.Sequential(name=\"GAN\")\n",
    "    model.add(generator_model)\n",
    "    model.add(discriminator_model)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(lr=0.0002, beta_1=0.5))\n",
    "    return model\n",
    "\n",
    "def get_latent_batch(number_of_samples):\n",
    "    return np.random.randn(LATENT_DIM * number_of_samples).reshape(number_of_samples, LATENT_DIM)\n",
    "\n",
    "\n",
    "def generate_fake_batch(generator_model, number_of_samples):\n",
    "    x_input = get_latent_batch(number_of_samples)\n",
    "    X = generator_model.predict(x_input)\n",
    "    # fake class labels (0)\n",
    "    y = np.zeros((number_of_samples, 1))\n",
    "    return X, y\n",
    "\n",
    "def train_discriminator(disc_model, gen_model):\n",
    "    for i, (X_real, _) in enumerate(train_ds):\n",
    "        y_real = np.ones((batch_size, 1))\n",
    "        _, real_acc = disc_model.train_on_batch(np.array(X_real), np.array(y_real))\n",
    "\n",
    "        #X_fake = np.random.rand(batch_size * IMAGE_SHAPE * IMAGE_SHAPE * NUM_PIXEL_CHANNELS).reshape((batch_size, IMAGE_SHAPE, IMAGE_SHAPE, NUM_PIXEL_CHANNELS))\n",
    "        X_fake, _ = generate_fake_batch(gen_model, batch_size)\n",
    "        y_fake = np.zeros((batch_size, 1))\n",
    "        _, fake_acc = disc_model.train_on_batch(np.array(X_fake), np.array(y_fake))\n",
    " \n",
    "        print('>%d real=%.0f%% fake=%.0f%%' % (i+1, real_acc*100, fake_acc*100))\n",
    "    \n",
    "    return disc_model\n",
    "\n",
    "def save_plot(examples, epoch, n=4):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    for i in range(n * n):\n",
    "        plt.subplot(n, n, 1 + i)\n",
    "        plt.axis('off')\n",
    "        # plot raw pixel data\n",
    "        #plt.imshow(examples[i, :, :, 0], cmap='gray_r')\n",
    "        image = examples[i, :, :, :]\n",
    "        if image.max() > 1:\n",
    "            image = image / 255.0\n",
    "        plt.imshow(image)\n",
    "    # save plot to file\n",
    "    file_path = f\"./imgs/generated_plot_e{epoch+1:03d}.png\"\n",
    "    plt.savefig(file_path)\n",
    "    plt.close()\n",
    " \n",
    "\n",
    "def summarize_performance(epoch, g_model, d_model, X_real, y_real):\n",
    "    _, acc_real = d_model.evaluate(np.array(X_real), np.array(y_real), verbose=0)\n",
    "    \n",
    "    x_fake, y_fake = generate_fake_batch(g_model, batch_size)\n",
    " \n",
    "    _, acc_fake = d_model.evaluate(x_fake, y_fake, verbose=0)\n",
    "    \n",
    "    print(f\"Accuracy real: {acc_real*100:.0f}%, fake: {acc_fake*100:.0f}%\")\n",
    "    \n",
    "    save_plot(x_fake, epoch)\n",
    "    \n",
    "    file_path = f\"./models/generator_model_{epoch+1}.h5\"\n",
    "    g_model.save(file_path)\n",
    "\n",
    "\n",
    "\n",
    "VERBOSE_LEVEL = 0\n",
    "\n",
    "gen_model = generator()\n",
    "disc_model = discriminator()\n",
    "if VERBOSE_LEVEL > 0: print(\"Training discriminator...\")\n",
    "train_discriminator(disc_model, gen_model)\n",
    "if VERBOSE_LEVEL > 0: print(\"Done training discriminator\")\n",
    "\n",
    "#raise RuntimeError(\"Stopping execution here for debug reasons...\")\n",
    "\n",
    "gan_model = gan(gen_model, disc_model)\n",
    "\n",
    "if VERBOSE_LEVEL > 1:\n",
    "    disc_model.summary()\n",
    "    gen_model.summary()\n",
    "    gan_model.summary()\n",
    "\n",
    "num_mini_batches = len(train_ds)\n",
    "batch_per_epoch = int(len(train_ds._indices) / batch_size)\n",
    "half_batch = int(num_mini_batches / 2)\n",
    "\n",
    "for i in range(n_epochs):\n",
    "    for j, (X_real, y_real) in enumerate(train_ds):\n",
    "        y_real = np.array(y_real).reshape(batch_size,1)\n",
    "        \n",
    "        X_fake, y_fake = generate_fake_batch(gen_model, batch_size)\n",
    "        \n",
    "        # Create training data set for discriminator\n",
    "        X = np.vstack((X_real, X_fake))\n",
    "        y = np.vstack((y_real, y_fake))\n",
    "\n",
    "        # update discriminator model weights\n",
    "        d_loss, _ = disc_model.train_on_batch(X, y)\n",
    "        # prepare points in latent space as input for the generator\n",
    "        X_gan = get_latent_batch(num_mini_batches)\n",
    "        # create inverted labels for the fake samples\n",
    "        y_gan = np.ones((num_mini_batches, 1))\n",
    "        # update the generator via the discriminator's error\n",
    "        g_loss = gan_model.train_on_batch(X_gan, y_gan)\n",
    "        \n",
    "        print(f\"Epoch: {i+1}/{n_epochs}, Batch: {j+1}/{batch_per_epoch}, Discriminator loss: {d_loss}, Generator loss: {g_loss}\")\n",
    "    \n",
    "    if (i+1) % 5 == 0: summarize_performance(i, gen_model, disc_model, X_real, y_real)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
